{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1W2icmWWyF0b"
      },
      "source": [
        "# **Proyecto - Plant Status**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nppLtvVszXNg"
      },
      "source": [
        "Para este proyecto, se utilizó el dataset disponible en la plataforma Kaggle, específicamente el titulado https://www.kaggle.com/datasets/abdallahalidev/plantvillage-dataset/data Este conjunto de datos contiene imágenes de diversas plantas en diferentes estados de salud, incluyendo tanto condiciones patológicas como muestras saludables.\n",
        "\n",
        "Cabe mencionar que algunas de las clases presentes en el dataset únicamente incluyen imágenes de plantas en estado saludable. A pesar de esta limitación, se decidió continuar trabajando con dichas clases para mantener la diversidad de especies vegetales representadas en el conjunto de datos.\n",
        "\n",
        "Posteriormente, se realizó una reorganización del dataset con el fin de facilitar el procesamiento y la clasificación. Para ello, se agruparon las imágenes según el tipo de planta, creando una estructura de carpetas nombradas con el nombre correspondiente a cada especie. Dentro de cada una de estas carpetas se almacenaron las imágenes clasificadas por su estado, lo que permite una manipulación más ordenada y eficiente durante el desarrollo del modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ***Configuración del entorno y Extracción***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ***Verificación y uso de GPU (CUDA) para el procesamiento de imágenes***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ahora, en el siguiente fragmento de código se realiza una verificación del entorno para comprobar si CUDA está disponible. Esto nos permite utilizar la GPU personal para acelerar el procesamiento de imágenes durante el entrenamiento del modelo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "¿CUDA disponible?: True\n",
            "✅ GPU detectada: NVIDIA GeForce RTX 3050\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "print(\"¿CUDA disponible?:\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"✅ GPU detectada:\", torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print(\"❌ No se detectó GPU\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ***Definición y verificación de la ruta del dataset***\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Antes de cargar las imágenes del dataset, es fundamental asegurarse de que la ruta hacia la carpeta que contiene los datos esté correctamente definida. En el siguiente fragmento de código, se especifica la ruta local donde se encuentra almacenado el dataset y se verifica su existencia en el sistema. Esto permite detectar posibles errores tempranamente si la ruta es incorrecta o si los archivos no se han descargado adecuadamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "¡El dataset se encontró en: C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Definir la ruta del dataset\n",
        "dataset_path = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "\n",
        "# Verificar que la carpeta existe\n",
        "if os.path.exists(dataset_path):\n",
        "    print(f\"¡El dataset se encontró en: {dataset_path}!\")\n",
        "else:\n",
        "    print(f\"Error: No se encontró la carpeta en {dataset_path}. Verifica la ruta.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNanNwDC1bRz"
      },
      "source": [
        "## ***Análisis exploratorio***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3L5-L8Yb1tNW"
      },
      "source": [
        "### ***Estructura del dataset***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMuA6qZE_r_5"
      },
      "source": [
        "Ver con que datos o carpetas se esta trabajando a lo largo de este colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "BMRcX7GQIvG2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📁 plantvillage dataset\n",
            "==================================================\n",
            "\n",
            "COLOR\n",
            "==================================================\n",
            "  🌱 Apple\n",
            "    🍃 Apple___Apple_scab\n",
            "    🍃 Apple___Black_rot\n",
            "    🍃 Apple___Cedar_apple_rust\n",
            "    🍃 Apple___healthy\n",
            "  🌱 Blueberry\n",
            "    🍃 Blueberry___healthy\n",
            "  🌱 Cherry\n",
            "    🍃 Cherry_(including_sour)___Powdery_mildew\n",
            "    🍃 Cherry_(including_sour)___healthy\n",
            "  🌱 Corn\n",
            "    🍃 Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot\n",
            "    🍃 Corn_(maize)___Common_rust_\n",
            "    🍃 Corn_(maize)___Northern_Leaf_Blight\n",
            "    🍃 Corn_(maize)___healthy\n",
            "  🌱 Grape\n",
            "    🍃 Grape___Black_rot\n",
            "    🍃 Grape___Esca_(Black_Measles)\n",
            "    🍃 Grape___Leaf_blight_(Isariopsis_Leaf_Spot)\n",
            "    🍃 Grape___healthy\n",
            "  🌱 Orange\n",
            "    🍃 Orange___Haunglongbing_(Citrus_greening)\n",
            "  🌱 Peach\n",
            "    🍃 Peach___Bacterial_spot\n",
            "    🍃 Peach___healthy\n",
            "  🌱 Pepper\n",
            "    🍃 Pepper,_bell___Bacterial_spot\n",
            "    🍃 Pepper,_bell___healthy\n",
            "  🌱 Potato\n",
            "    🍃 Potato___Early_blight\n",
            "    🍃 Potato___Late_blight\n",
            "    🍃 Potato___healthy\n",
            "  🌱 Raspberry\n",
            "    🍃 Raspberry___healthy\n",
            "  🌱 Soybean\n",
            "    🍃 Soybean___healthy\n",
            "  🌱 Squash\n",
            "    🍃 Squash___Powdery_mildew\n",
            "  🌱 Strawberry\n",
            "    🍃 Strawberry___Leaf_scorch\n",
            "    🍃 Strawberry___healthy\n",
            "  🌱 Tomato\n",
            "    🍃 Tomato___Bacterial_spot\n",
            "    🍃 Tomato___Early_blight\n",
            "    🍃 Tomato___Late_blight\n",
            "    🍃 Tomato___Leaf_Mold\n",
            "    🍃 Tomato___Septoria_leaf_spot\n",
            "    🍃 Tomato___Spider_mites Two-spotted_spider_mite\n",
            "    🍃 Tomato___Target_Spot\n",
            "    🍃 Tomato___Tomato_Yellow_Leaf_Curl_Virus\n",
            "    🍃 Tomato___Tomato_mosaic_virus\n",
            "    🍃 Tomato___healthy\n",
            "\n",
            "GRAYSCALE\n",
            "==================================================\n",
            "  🌱 Apple\n",
            "    🍃 Apple___Apple_scab\n",
            "    🍃 Apple___Black_rot\n",
            "    🍃 Apple___Cedar_apple_rust\n",
            "    🍃 Apple___healthy\n",
            "  🌱 Blueberry\n",
            "    🍃 Blueberry___healthy\n",
            "  🌱 Cherry\n",
            "    🍃 Cherry_(including_sour)___Powdery_mildew\n",
            "    🍃 Cherry_(including_sour)___healthy\n",
            "  🌱 Corn\n",
            "    🍃 Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot\n",
            "    🍃 Corn_(maize)___Common_rust_\n",
            "    🍃 Corn_(maize)___Northern_Leaf_Blight\n",
            "    🍃 Corn_(maize)___healthy\n",
            "  🌱 Grape\n",
            "    🍃 Grape___Black_rot\n",
            "    🍃 Grape___Esca_(Black_Measles)\n",
            "    🍃 Grape___Leaf_blight_(Isariopsis_Leaf_Spot)\n",
            "    🍃 Grape___healthy\n",
            "  🌱 Orange\n",
            "    🍃 Orange___Haunglongbing_(Citrus_greening)\n",
            "  🌱 Peach\n",
            "    🍃 Peach___Bacterial_spot\n",
            "    🍃 Peach___healthy\n",
            "  🌱 Pepper\n",
            "    🍃 Pepper,_bell___Bacterial_spot\n",
            "    🍃 Pepper,_bell___healthy\n",
            "  🌱 Potato\n",
            "    🍃 Potato___Early_blight\n",
            "    🍃 Potato___Late_blight\n",
            "    🍃 Potato___healthy\n",
            "  🌱 Raspberry\n",
            "    🍃 Raspberry___healthy\n",
            "  🌱 Soybean\n",
            "    🍃 Soybean___healthy\n",
            "  🌱 Squash\n",
            "    🍃 Squash___Powdery_mildew\n",
            "  🌱 Strawberry\n",
            "    🍃 Strawberry___Leaf_scorch\n",
            "    🍃 Strawberry___healthy\n",
            "  🌱 Tomato\n",
            "    🍃 Tomato___Bacterial_spot\n",
            "    🍃 Tomato___Early_blight\n",
            "    🍃 Tomato___Late_blight\n",
            "    🍃 Tomato___Leaf_Mold\n",
            "    🍃 Tomato___Septoria_leaf_spot\n",
            "    🍃 Tomato___Spider_mites Two-spotted_spider_mite\n",
            "    🍃 Tomato___Target_Spot\n",
            "    🍃 Tomato___Tomato_Yellow_Leaf_Curl_Virus\n",
            "    🍃 Tomato___Tomato_mosaic_virus\n",
            "    🍃 Tomato___healthy\n",
            "\n",
            "SEGMENTED\n",
            "==================================================\n",
            "  🌱 Apple\n",
            "    🍃 Apple___Apple_scab\n",
            "    🍃 Apple___Black_rot\n",
            "    🍃 Apple___Cedar_apple_rust\n",
            "    🍃 Apple___healthy\n",
            "  🌱 Blueberry\n",
            "    🍃 Blueberry___healthy\n",
            "  🌱 Cherry\n",
            "    🍃 Cherry_(including_sour)___Powdery_mildew\n",
            "    🍃 Cherry_(including_sour)___healthy\n",
            "  🌱 Corn\n",
            "    🍃 Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot\n",
            "    🍃 Corn_(maize)___Common_rust_\n",
            "    🍃 Corn_(maize)___Northern_Leaf_Blight\n",
            "    🍃 Corn_(maize)___healthy\n",
            "  🌱 Grape\n",
            "    🍃 Grape___Black_rot\n",
            "    🍃 Grape___Esca_(Black_Measles)\n",
            "    🍃 Grape___Leaf_blight_(Isariopsis_Leaf_Spot)\n",
            "    🍃 Grape___healthy\n",
            "  🌱 Orange\n",
            "    🍃 Orange___Haunglongbing_(Citrus_greening)\n",
            "  🌱 Peach\n",
            "    🍃 Peach___Bacterial_spot\n",
            "    🍃 Peach___healthy\n",
            "  🌱 Pepper\n",
            "    🍃 Pepper,_bell___Bacterial_spot\n",
            "    🍃 Pepper,_bell___healthy\n",
            "  🌱 Potato\n",
            "    🍃 Potato___Early_blight\n",
            "    🍃 Potato___Late_blight\n",
            "    🍃 Potato___healthy\n",
            "  🌱 Raspberry\n",
            "    🍃 Raspberry___healthy\n",
            "  🌱 Soybean\n",
            "    🍃 Soybean___healthy\n",
            "  🌱 Squash\n",
            "    🍃 Squash___Powdery_mildew\n",
            "  🌱 Strawberry\n",
            "    🍃 Strawberry___Leaf_scorch\n",
            "    🍃 Strawberry___healthy\n",
            "  🌱 Tomato\n",
            "    🍃 Tomato___Bacterial_spot\n",
            "    🍃 Tomato___Early_blight\n",
            "    🍃 Tomato___Late_blight\n",
            "    🍃 Tomato___Leaf_Mold\n",
            "    🍃 Tomato___Septoria_leaf_spot\n",
            "    🍃 Tomato___Spider_mites Two-spotted_spider_mite\n",
            "    🍃 Tomato___Target_Spot\n",
            "    🍃 Tomato___Tomato_Yellow_Leaf_Curl_Virus\n",
            "    🍃 Tomato___Tomato_mosaic_virus\n",
            "    🍃 Tomato___healthy\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Ruta del dataset local\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "\n",
        "def list_folders_clean(directory):\n",
        "    # Verificar que la carpeta existe\n",
        "    if not os.path.exists(directory):\n",
        "        print(f\"Error: No se encontró la carpeta en {directory}.\")\n",
        "        return\n",
        "    \n",
        "    visited = set()\n",
        "    folders_by_origin = {\"color\": [], \"grayscale\": [], \"segmented\": []}\n",
        "    \n",
        "    # Recorrer el directorio\n",
        "    for root, dirs, _ in os.walk(directory):\n",
        "        depth = root[len(directory):].count(os.sep)\n",
        "        folder_name = os.path.basename(root)\n",
        "        if root == directory:\n",
        "            folder_name = \"plantvillage dataset\"\n",
        "        \n",
        "        full_path = os.path.normpath(os.path.join(root))\n",
        "        if full_path not in visited and depth >= 1:\n",
        "            visited.add(full_path)\n",
        "            \n",
        "            # Determinar el tipo (color, grayscale, segmented)\n",
        "            origin = \"\"\n",
        "            parent_path = os.path.dirname(root)\n",
        "            parent_name = os.path.basename(parent_path)\n",
        "            if depth == 1:\n",
        "                origin = folder_name\n",
        "            elif depth >= 2 and parent_name in [\"color\", \"grayscale\", \"segmented\"]:\n",
        "                origin = parent_name\n",
        "            elif depth >= 2:\n",
        "                grandparent_path = os.path.dirname(parent_path)\n",
        "                grandparent_name = os.path.basename(grandparent_path)\n",
        "                if grandparent_name in [\"color\", \"grayscale\", \"segmented\"]:\n",
        "                    origin = grandparent_name\n",
        "            \n",
        "            # Guardar carpetas de nivel 2 o mayor\n",
        "            if depth >= 2 and origin:\n",
        "                is_simple = \"___\" not in folder_name\n",
        "                folders_by_origin[origin].append((depth, folder_name, is_simple))\n",
        "    \n",
        "    # Imprimir carpeta raíz\n",
        "    print(f\"📁 plantvillage dataset\")\n",
        "    print(f\"{'=' * 50}\")\n",
        "    \n",
        "    # Imprimir carpetas por tipo\n",
        "    for origin in [\"color\", \"grayscale\", \"segmented\"]:\n",
        "        if folders_by_origin[origin]:\n",
        "            print(f\"\\n{origin.upper()}\")\n",
        "            print(f\"{'=' * 50}\")\n",
        "            for depth, folder_name, is_simple in sorted(folders_by_origin[origin], key=lambda x: x[1]):\n",
        "                indent = \"  \" * (depth - 1)\n",
        "                icon = \"🌱\" if is_simple else \"🍃\"\n",
        "                print(f\"{indent}{icon} {folder_name}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    list_folders_clean(DATASET_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "El dataset PlantVillage contiene imágenes de múltiples especies de plantas en tres formatos: color, escala de grises y segmentado. Cada especie incluye diferentes estados, que abarcan desde plantas saludables hasta diversas enfermedades comunes.\n",
        "\n",
        "Este conjunto de datos ofrece una amplia variedad de condiciones para el entrenamiento y evaluación de modelos de clasificación y diagnóstico de enfermedades en plantas, lo que lo convierte en un recurso valioso para proyectos de aprendizaje automático en agricultura."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KZITuhg16f_"
      },
      "source": [
        "### ***Formato o extension de las imagenes***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TtC0m_hq_vzK"
      },
      "source": [
        "Se verificó la extensión de las imágenes en el dataset y, para nuestro trabajo, se utilizarán únicamente las imágenes con extensión .jpg."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "nOrKmLSk1k-a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============================\n",
            "Extensiones de Imágenes\n",
            "==============================\n",
            "Extensión      Conteo\n",
            "----------------------\n",
            ".jpeg               2\n",
            ".jpg           162912\n",
            ".png                2\n",
            "\n",
            "Total archivos: 162916\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from collections import defaultdict\n",
        "\n",
        "# Ruta del dataset local\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "\n",
        "def analyze_image_extensions(directory):\n",
        "    # Verificar que la carpeta existe\n",
        "    if not os.path.exists(directory):\n",
        "        print(f\"Error: No se encontró la carpeta en {directory}.\")\n",
        "        return\n",
        "    \n",
        "    # Almacenar conteo de extensiones\n",
        "    ext_counts = defaultdict(int)\n",
        "    total_files = 0\n",
        "    file_extensions = ('.jpg', '.jpeg', '.png', '.bmp', '.gif')\n",
        "    \n",
        "    # Recorrer el directorio\n",
        "    for root, _, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            ext = os.path.splitext(file)[1].lower()\n",
        "            if ext in file_extensions:\n",
        "                ext_counts[ext] += 1\n",
        "                total_files += 1\n",
        "    \n",
        "    # Imprimir resumen\n",
        "    print(f\"{'=' * 30}\")\n",
        "    print(\"Extensiones de Imágenes\")\n",
        "    print(f\"{'=' * 30}\")\n",
        "    print(f\"{'Extensión':<10} {'Conteo':>10}\")\n",
        "    print(\"-\" * 22)\n",
        "    for ext in sorted(ext_counts):\n",
        "        print(f\"{ext:<10} {ext_counts[ext]:>10}\")\n",
        "    print(f\"\\nTotal archivos: {total_files}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    analyze_image_extensions(DATASET_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lpYsjGa0DEa"
      },
      "source": [
        "Se encontró la siguiente distribución de extensiones en las imágenes del dataset:\n",
        "\n",
        "* Archivos con extensión .jpeg: 2\n",
        "\n",
        "* Archivos con extensión .jpg: 162,912\n",
        "\n",
        "* Archivos con extensión .png: 2\n",
        "\n",
        "En total, el dataset contiene 162,916 archivos de imagen.\n",
        "\n",
        "Dado que la gran mayoría de las imágenes utilizan la extensión .jpg, se requerirá unificar todas las extensiones al formato .jpg para facilitar el procesamiento, estandarización y evitar errores por incompatibilidades en la lectura o filtrado por extensión."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAe8jAnq2oY8"
      },
      "source": [
        "### ***Resoluciónes dentro del dataset por planta y tipo de Imagen***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Utilizaremos CUDA para procesar las imágenes directamente en nuestra tarjeta gráfica.\n",
        "A continuación, se muestra un ejemplo de código para verificar que CUDA esté funcionando correctamente:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CUDA version: 12090\n",
            "GPU devices: 1\n"
          ]
        }
      ],
      "source": [
        "import cupy as cp\n",
        "print(f\"CUDA version: {cp.cuda.runtime.runtimeGetVersion()}\")\n",
        "print(f\"GPU devices: {cp.cuda.runtime.getDeviceCount()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ahora analizaremos las dimensiones de las imágenes por cada carpeta (color, grayscale, y segmented) y por cada planta dentro del dataset.\n",
        "Debido a posibles cuellos de botella en el procesamiento, este análisis se realizará planta por planta y carpeta por carpeta, de forma secuencial. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "***Conclusión del análisis de dimensiones de las imágenes***\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Durante el análisis del dataset, se detectaron dimensiones distintas a 256 x 256, particularmente en la carpeta segmented de las plantas Peach, Strawberry y Potato.\n",
        "\n",
        "Sin embargo, para asegurar la compatibilidad con el modelo a utilizar —ResNet, el cual requiere entradas de 224 x 224 píxeles—, será necesario redimensionar todas las imágenes a 224 x 224, sin importar su dimensión original.\n",
        "\n",
        "Esta transformación garantiza una entrada homogénea al modelo, evitando errores durante la etapa de entrenamiento o inferencia."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### ***Color***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ***Apple***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Procesando imágenes: 100%|██████████| 3171/3171 [00:01<00:00, 3091.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============================\n",
            "Dimensiones de Imágenes (Apple - COLOR)\n",
            "==============================\n",
            "Dimensión           Conteo\n",
            "---------------------------\n",
            "256x256               3171\n",
            "\n",
            "Total imágenes procesadas: 3171\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import cupy as cp\n",
        "import numpy as np\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ruta del dataset local\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "# Nombre de la planta a procesar\n",
        "PLANT_NAME = \"Apple\"\n",
        "# Categoría a procesar\n",
        "CATEGORY = \"color\"\n",
        "# Número de hilos para paralelización\n",
        "MAX_WORKERS = 16\n",
        "\n",
        "def collect_image_paths(directory):\n",
        "    file_paths = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        if PLANT_NAME in root:\n",
        "            for file in files:\n",
        "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    file_paths.append(os.path.join(root, file))\n",
        "    return file_paths\n",
        "\n",
        "def process_image(file_path):\n",
        "    try:\n",
        "        with Image.open(file_path) as img:\n",
        "            return (img.size[0], img.size[1])\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def analyze_plant_dimensions():\n",
        "    category_path = os.path.join(DATASET_PATH, CATEGORY, PLANT_NAME)\n",
        "    if not os.path.exists(category_path):\n",
        "        print(f\"Error: No se encontró la carpeta {category_path}.\")\n",
        "        return None, None, 0\n",
        "    \n",
        "    file_paths = collect_image_paths(category_path)\n",
        "    dimensions = []\n",
        "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "        # Usar tqdm para mostrar progreso\n",
        "        with tqdm(total=len(file_paths), desc=\"Procesando imágenes\") as pbar:\n",
        "            for dim in executor.map(process_image, file_paths):\n",
        "                if dim is not None:\n",
        "                    dimensions.append(dim)\n",
        "                pbar.update(1)\n",
        "    \n",
        "    try:\n",
        "        dim_array = cp.array(dimensions, dtype=cp.int32)\n",
        "        unique_dims, counts = np.unique(dim_array.get(), axis=0, return_counts=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error en el cálculo de dimensiones: {e}\")\n",
        "        return None, None, len(dimensions)\n",
        "    \n",
        "    return unique_dims, counts, len(dimensions)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unique_dims, counts, total_dims = analyze_plant_dimensions()\n",
        "    if unique_dims is not None and counts is not None:\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"Dimensiones de Imágenes ({PLANT_NAME} - {CATEGORY.upper()})\")\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"{'Dimensión':<15} {'Conteo':>10}\")\n",
        "        print(\"-\" * 27)\n",
        "        for dim, count in zip(unique_dims, counts):\n",
        "            print(f\"{f'{dim[0]}x{dim[1]}':<15} {count:>10}\")\n",
        "        print(f\"\\nTotal imágenes procesadas: {total_dims}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ***Blueberry***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Procesando imágenes: 100%|██████████| 1502/1502 [00:00<00:00, 5103.20it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============================\n",
            "Dimensiones de Imágenes (Blueberry - COLOR)\n",
            "==============================\n",
            "Dimensión           Conteo\n",
            "---------------------------\n",
            "256x256               1502\n",
            "\n",
            "Total imágenes procesadas: 1502\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import cupy as cp\n",
        "import numpy as np\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ruta del dataset local\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "# Nombre de la planta a procesar\n",
        "PLANT_NAME = \"Blueberry\"\n",
        "# Categoría a procesar\n",
        "CATEGORY = \"color\"\n",
        "# Número de hilos para paralelización\n",
        "MAX_WORKERS = 16\n",
        "\n",
        "def collect_image_paths(directory):\n",
        "    file_paths = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        if PLANT_NAME in root:\n",
        "            for file in files:\n",
        "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    file_paths.append(os.path.join(root, file))\n",
        "    return file_paths\n",
        "\n",
        "def process_image(file_path):\n",
        "    try:\n",
        "        with Image.open(file_path) as img:\n",
        "            return (img.size[0], img.size[1])\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def analyze_plant_dimensions():\n",
        "    category_path = os.path.join(DATASET_PATH, CATEGORY, PLANT_NAME)\n",
        "    if not os.path.exists(category_path):\n",
        "        print(f\"Error: No se encontró la carpeta {category_path}.\")\n",
        "        return None, None, 0\n",
        "    \n",
        "    file_paths = collect_image_paths(category_path)\n",
        "    dimensions = []\n",
        "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "        # Usar tqdm para mostrar progreso\n",
        "        with tqdm(total=len(file_paths), desc=\"Procesando imágenes\") as pbar:\n",
        "            for dim in executor.map(process_image, file_paths):\n",
        "                if dim is not None:\n",
        "                    dimensions.append(dim)\n",
        "                pbar.update(1)\n",
        "    \n",
        "    try:\n",
        "        dim_array = cp.array(dimensions, dtype=cp.int32)\n",
        "        unique_dims, counts = np.unique(dim_array.get(), axis=0, return_counts=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error en el cálculo de dimensiones: {e}\")\n",
        "        return None, None, len(dimensions)\n",
        "    \n",
        "    return unique_dims, counts, len(dimensions)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unique_dims, counts, total_dims = analyze_plant_dimensions()\n",
        "    if unique_dims is not None and counts is not None:\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"Dimensiones de Imágenes ({PLANT_NAME} - {CATEGORY.upper()})\")\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"{'Dimensión':<15} {'Conteo':>10}\")\n",
        "        print(\"-\" * 27)\n",
        "        for dim, count in zip(unique_dims, counts):\n",
        "            print(f\"{f'{dim[0]}x{dim[1]}':<15} {count:>10}\")\n",
        "        print(f\"\\nTotal imágenes procesadas: {total_dims}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ***Cherry***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Procesando imágenes: 100%|██████████| 1906/1906 [00:00<00:00, 4925.06it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============================\n",
            "Dimensiones de Imágenes (Cherry - COLOR)\n",
            "==============================\n",
            "Dimensión           Conteo\n",
            "---------------------------\n",
            "256x256               1906\n",
            "\n",
            "Total imágenes procesadas: 1906\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import cupy as cp\n",
        "import numpy as np\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ruta del dataset local\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "# Nombre de la planta a procesar\n",
        "PLANT_NAME = \"Cherry\"\n",
        "# Categoría a procesar\n",
        "CATEGORY = \"color\"\n",
        "# Número de hilos para paralelización\n",
        "MAX_WORKERS = 16\n",
        "\n",
        "def collect_image_paths(directory):\n",
        "    file_paths = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        if PLANT_NAME in root:\n",
        "            for file in files:\n",
        "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    file_paths.append(os.path.join(root, file))\n",
        "    return file_paths\n",
        "\n",
        "def process_image(file_path):\n",
        "    try:\n",
        "        with Image.open(file_path) as img:\n",
        "            return (img.size[0], img.size[1])\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def analyze_plant_dimensions():\n",
        "    category_path = os.path.join(DATASET_PATH, CATEGORY, PLANT_NAME)\n",
        "    if not os.path.exists(category_path):\n",
        "        print(f\"Error: No se encontró la carpeta {category_path}.\")\n",
        "        return None, None, 0\n",
        "    \n",
        "    file_paths = collect_image_paths(category_path)\n",
        "    dimensions = []\n",
        "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "        # Usar tqdm para mostrar progreso\n",
        "        with tqdm(total=len(file_paths), desc=\"Procesando imágenes\") as pbar:\n",
        "            for dim in executor.map(process_image, file_paths):\n",
        "                if dim is not None:\n",
        "                    dimensions.append(dim)\n",
        "                pbar.update(1)\n",
        "    \n",
        "    try:\n",
        "        dim_array = cp.array(dimensions, dtype=cp.int32)\n",
        "        unique_dims, counts = np.unique(dim_array.get(), axis=0, return_counts=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error en el cálculo de dimensiones: {e}\")\n",
        "        return None, None, len(dimensions)\n",
        "    \n",
        "    return unique_dims, counts, len(dimensions)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unique_dims, counts, total_dims = analyze_plant_dimensions()\n",
        "    if unique_dims is not None and counts is not None:\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"Dimensiones de Imágenes ({PLANT_NAME} - {CATEGORY.upper()})\")\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"{'Dimensión':<15} {'Conteo':>10}\")\n",
        "        print(\"-\" * 27)\n",
        "        for dim, count in zip(unique_dims, counts):\n",
        "            print(f\"{f'{dim[0]}x{dim[1]}':<15} {count:>10}\")\n",
        "        print(f\"\\nTotal imágenes procesadas: {total_dims}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ***Corn***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Procesando imágenes: 100%|██████████| 3852/3852 [00:00<00:00, 4767.34it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============================\n",
            "Dimensiones de Imágenes (Corn - COLOR)\n",
            "==============================\n",
            "Dimensión           Conteo\n",
            "---------------------------\n",
            "256x256               3852\n",
            "\n",
            "Total imágenes procesadas: 3852\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import cupy as cp\n",
        "import numpy as np\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ruta del dataset local\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "# Nombre de la planta a procesar\n",
        "PLANT_NAME = \"Corn\"\n",
        "# Categoría a procesar\n",
        "CATEGORY = \"color\"\n",
        "# Número de hilos para paralelización\n",
        "MAX_WORKERS = 16\n",
        "\n",
        "def collect_image_paths(directory):\n",
        "    file_paths = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        if PLANT_NAME in root:\n",
        "            for file in files:\n",
        "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    file_paths.append(os.path.join(root, file))\n",
        "    return file_paths\n",
        "\n",
        "def process_image(file_path):\n",
        "    try:\n",
        "        with Image.open(file_path) as img:\n",
        "            return (img.size[0], img.size[1])\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def analyze_plant_dimensions():\n",
        "    category_path = os.path.join(DATASET_PATH, CATEGORY, PLANT_NAME)\n",
        "    if not os.path.exists(category_path):\n",
        "        print(f\"Error: No se encontró la carpeta {category_path}.\")\n",
        "        return None, None, 0\n",
        "    \n",
        "    file_paths = collect_image_paths(category_path)\n",
        "    dimensions = []\n",
        "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "        # Usar tqdm para mostrar progreso\n",
        "        with tqdm(total=len(file_paths), desc=\"Procesando imágenes\") as pbar:\n",
        "            for dim in executor.map(process_image, file_paths):\n",
        "                if dim is not None:\n",
        "                    dimensions.append(dim)\n",
        "                pbar.update(1)\n",
        "    \n",
        "    try:\n",
        "        dim_array = cp.array(dimensions, dtype=cp.int32)\n",
        "        unique_dims, counts = np.unique(dim_array.get(), axis=0, return_counts=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error en el cálculo de dimensiones: {e}\")\n",
        "        return None, None, len(dimensions)\n",
        "    \n",
        "    return unique_dims, counts, len(dimensions)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unique_dims, counts, total_dims = analyze_plant_dimensions()\n",
        "    if unique_dims is not None and counts is not None:\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"Dimensiones de Imágenes ({PLANT_NAME} - {CATEGORY.upper()})\")\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"{'Dimensión':<15} {'Conteo':>10}\")\n",
        "        print(\"-\" * 27)\n",
        "        for dim, count in zip(unique_dims, counts):\n",
        "            print(f\"{f'{dim[0]}x{dim[1]}':<15} {count:>10}\")\n",
        "        print(f\"\\nTotal imágenes procesadas: {total_dims}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ***Grape***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Procesando imágenes: 100%|██████████| 4062/4062 [00:00<00:00, 4864.67it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============================\n",
            "Dimensiones de Imágenes (Grape - COLOR)\n",
            "==============================\n",
            "Dimensión           Conteo\n",
            "---------------------------\n",
            "256x256               4062\n",
            "\n",
            "Total imágenes procesadas: 4062\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import cupy as cp\n",
        "import numpy as np\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ruta del dataset local\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "# Nombre de la planta a procesar\n",
        "PLANT_NAME = \"Grape\"\n",
        "# Categoría a procesar\n",
        "CATEGORY = \"color\"\n",
        "# Número de hilos para paralelización\n",
        "MAX_WORKERS = 16\n",
        "\n",
        "def collect_image_paths(directory):\n",
        "    file_paths = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        if PLANT_NAME in root:\n",
        "            for file in files:\n",
        "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    file_paths.append(os.path.join(root, file))\n",
        "    return file_paths\n",
        "\n",
        "def process_image(file_path):\n",
        "    try:\n",
        "        with Image.open(file_path) as img:\n",
        "            return (img.size[0], img.size[1])\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def analyze_plant_dimensions():\n",
        "    category_path = os.path.join(DATASET_PATH, CATEGORY, PLANT_NAME)\n",
        "    if not os.path.exists(category_path):\n",
        "        print(f\"Error: No se encontró la carpeta {category_path}.\")\n",
        "        return None, None, 0\n",
        "    \n",
        "    file_paths = collect_image_paths(category_path)\n",
        "    dimensions = []\n",
        "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "        # Usar tqdm para mostrar progreso\n",
        "        with tqdm(total=len(file_paths), desc=\"Procesando imágenes\") as pbar:\n",
        "            for dim in executor.map(process_image, file_paths):\n",
        "                if dim is not None:\n",
        "                    dimensions.append(dim)\n",
        "                pbar.update(1)\n",
        "    \n",
        "    try:\n",
        "        dim_array = cp.array(dimensions, dtype=cp.int32)\n",
        "        unique_dims, counts = np.unique(dim_array.get(), axis=0, return_counts=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error en el cálculo de dimensiones: {e}\")\n",
        "        return None, None, len(dimensions)\n",
        "    \n",
        "    return unique_dims, counts, len(dimensions)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unique_dims, counts, total_dims = analyze_plant_dimensions()\n",
        "    if unique_dims is not None and counts is not None:\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"Dimensiones de Imágenes ({PLANT_NAME} - {CATEGORY.upper()})\")\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"{'Dimensión':<15} {'Conteo':>10}\")\n",
        "        print(\"-\" * 27)\n",
        "        for dim, count in zip(unique_dims, counts):\n",
        "            print(f\"{f'{dim[0]}x{dim[1]}':<15} {count:>10}\")\n",
        "        print(f\"\\nTotal imágenes procesadas: {total_dims}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ***Orange***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Procesando imágenes: 100%|██████████| 5507/5507 [00:01<00:00, 3979.02it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============================\n",
            "Dimensiones de Imágenes (Orange - COLOR)\n",
            "==============================\n",
            "Dimensión           Conteo\n",
            "---------------------------\n",
            "256x256               5507\n",
            "\n",
            "Total imágenes procesadas: 5507\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import cupy as cp\n",
        "import numpy as np\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ruta del dataset local\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "# Nombre de la planta a procesar\n",
        "PLANT_NAME = \"Orange\"\n",
        "# Categoría a procesar\n",
        "CATEGORY = \"color\"\n",
        "# Número de hilos para paralelización\n",
        "MAX_WORKERS = 16\n",
        "\n",
        "def collect_image_paths(directory):\n",
        "    file_paths = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        if PLANT_NAME in root:\n",
        "            for file in files:\n",
        "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    file_paths.append(os.path.join(root, file))\n",
        "    return file_paths\n",
        "\n",
        "def process_image(file_path):\n",
        "    try:\n",
        "        with Image.open(file_path) as img:\n",
        "            return (img.size[0], img.size[1])\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def analyze_plant_dimensions():\n",
        "    category_path = os.path.join(DATASET_PATH, CATEGORY, PLANT_NAME)\n",
        "    if not os.path.exists(category_path):\n",
        "        print(f\"Error: No se encontró la carpeta {category_path}.\")\n",
        "        return None, None, 0\n",
        "    \n",
        "    file_paths = collect_image_paths(category_path)\n",
        "    dimensions = []\n",
        "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "        # Usar tqdm para mostrar progreso\n",
        "        with tqdm(total=len(file_paths), desc=\"Procesando imágenes\") as pbar:\n",
        "            for dim in executor.map(process_image, file_paths):\n",
        "                if dim is not None:\n",
        "                    dimensions.append(dim)\n",
        "                pbar.update(1)\n",
        "    \n",
        "    try:\n",
        "        dim_array = cp.array(dimensions, dtype=cp.int32)\n",
        "        unique_dims, counts = np.unique(dim_array.get(), axis=0, return_counts=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error en el cálculo de dimensiones: {e}\")\n",
        "        return None, None, len(dimensions)\n",
        "    \n",
        "    return unique_dims, counts, len(dimensions)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unique_dims, counts, total_dims = analyze_plant_dimensions()\n",
        "    if unique_dims is not None and counts is not None:\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"Dimensiones de Imágenes ({PLANT_NAME} - {CATEGORY.upper()})\")\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"{'Dimensión':<15} {'Conteo':>10}\")\n",
        "        print(\"-\" * 27)\n",
        "        for dim, count in zip(unique_dims, counts):\n",
        "            print(f\"{f'{dim[0]}x{dim[1]}':<15} {count:>10}\")\n",
        "        print(f\"\\nTotal imágenes procesadas: {total_dims}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ***Peach***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Procesando imágenes: 100%|██████████| 2657/2657 [00:00<00:00, 4653.24it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============================\n",
            "Dimensiones de Imágenes (Peach - COLOR)\n",
            "==============================\n",
            "Dimensión           Conteo\n",
            "---------------------------\n",
            "256x256               2657\n",
            "\n",
            "Total imágenes procesadas: 2657\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import cupy as cp\n",
        "import numpy as np\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ruta del dataset local\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "# Nombre de la planta a procesar\n",
        "PLANT_NAME = \"Peach\"\n",
        "# Categoría a procesar\n",
        "CATEGORY = \"color\"\n",
        "# Número de hilos para paralelización\n",
        "MAX_WORKERS = 16\n",
        "\n",
        "def collect_image_paths(directory):\n",
        "    file_paths = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        if PLANT_NAME in root:\n",
        "            for file in files:\n",
        "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    file_paths.append(os.path.join(root, file))\n",
        "    return file_paths\n",
        "\n",
        "def process_image(file_path):\n",
        "    try:\n",
        "        with Image.open(file_path) as img:\n",
        "            return (img.size[0], img.size[1])\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def analyze_plant_dimensions():\n",
        "    category_path = os.path.join(DATASET_PATH, CATEGORY, PLANT_NAME)\n",
        "    if not os.path.exists(category_path):\n",
        "        print(f\"Error: No se encontró la carpeta {category_path}.\")\n",
        "        return None, None, 0\n",
        "    \n",
        "    file_paths = collect_image_paths(category_path)\n",
        "    dimensions = []\n",
        "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "        # Usar tqdm para mostrar progreso\n",
        "        with tqdm(total=len(file_paths), desc=\"Procesando imágenes\") as pbar:\n",
        "            for dim in executor.map(process_image, file_paths):\n",
        "                if dim is not None:\n",
        "                    dimensions.append(dim)\n",
        "                pbar.update(1)\n",
        "    \n",
        "    try:\n",
        "        dim_array = cp.array(dimensions, dtype=cp.int32)\n",
        "        unique_dims, counts = np.unique(dim_array.get(), axis=0, return_counts=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error en el cálculo de dimensiones: {e}\")\n",
        "        return None, None, len(dimensions)\n",
        "    \n",
        "    return unique_dims, counts, len(dimensions)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unique_dims, counts, total_dims = analyze_plant_dimensions()\n",
        "    if unique_dims is not None and counts is not None:\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"Dimensiones de Imágenes ({PLANT_NAME} - {CATEGORY.upper()})\")\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"{'Dimensión':<15} {'Conteo':>10}\")\n",
        "        print(\"-\" * 27)\n",
        "        for dim, count in zip(unique_dims, counts):\n",
        "            print(f\"{f'{dim[0]}x{dim[1]}':<15} {count:>10}\")\n",
        "        print(f\"\\nTotal imágenes procesadas: {total_dims}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ***Pepper***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Procesando imágenes: 100%|██████████| 2475/2475 [00:00<00:00, 5195.23it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============================\n",
            "Dimensiones de Imágenes (Pepper - COLOR)\n",
            "==============================\n",
            "Dimensión           Conteo\n",
            "---------------------------\n",
            "256x256               2475\n",
            "\n",
            "Total imágenes procesadas: 2475\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import cupy as cp\n",
        "import numpy as np\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ruta del dataset local\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "# Nombre de la planta a procesar\n",
        "PLANT_NAME = \"Pepper\"\n",
        "# Categoría a procesar\n",
        "CATEGORY = \"color\"\n",
        "# Número de hilos para paralelización\n",
        "MAX_WORKERS = 16\n",
        "\n",
        "def collect_image_paths(directory):\n",
        "    file_paths = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        if PLANT_NAME in root:\n",
        "            for file in files:\n",
        "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    file_paths.append(os.path.join(root, file))\n",
        "    return file_paths\n",
        "\n",
        "def process_image(file_path):\n",
        "    try:\n",
        "        with Image.open(file_path) as img:\n",
        "            return (img.size[0], img.size[1])\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def analyze_plant_dimensions():\n",
        "    category_path = os.path.join(DATASET_PATH, CATEGORY, PLANT_NAME)\n",
        "    if not os.path.exists(category_path):\n",
        "        print(f\"Error: No se encontró la carpeta {category_path}.\")\n",
        "        return None, None, 0\n",
        "    \n",
        "    file_paths = collect_image_paths(category_path)\n",
        "    dimensions = []\n",
        "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "        # Usar tqdm para mostrar progreso\n",
        "        with tqdm(total=len(file_paths), desc=\"Procesando imágenes\") as pbar:\n",
        "            for dim in executor.map(process_image, file_paths):\n",
        "                if dim is not None:\n",
        "                    dimensions.append(dim)\n",
        "                pbar.update(1)\n",
        "    \n",
        "    try:\n",
        "        dim_array = cp.array(dimensions, dtype=cp.int32)\n",
        "        unique_dims, counts = np.unique(dim_array.get(), axis=0, return_counts=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error en el cálculo de dimensiones: {e}\")\n",
        "        return None, None, len(dimensions)\n",
        "    \n",
        "    return unique_dims, counts, len(dimensions)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unique_dims, counts, total_dims = analyze_plant_dimensions()\n",
        "    if unique_dims is not None and counts is not None:\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"Dimensiones de Imágenes ({PLANT_NAME} - {CATEGORY.upper()})\")\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"{'Dimensión':<15} {'Conteo':>10}\")\n",
        "        print(\"-\" * 27)\n",
        "        for dim, count in zip(unique_dims, counts):\n",
        "            print(f\"{f'{dim[0]}x{dim[1]}':<15} {count:>10}\")\n",
        "        print(f\"\\nTotal imágenes procesadas: {total_dims}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ***Potato***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Procesando imágenes:   0%|          | 0/2152 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Procesando imágenes: 100%|██████████| 2152/2152 [00:00<00:00, 4981.51it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============================\n",
            "Dimensiones de Imágenes (Potato - COLOR)\n",
            "==============================\n",
            "Dimensión           Conteo\n",
            "---------------------------\n",
            "256x256               2152\n",
            "\n",
            "Total imágenes procesadas: 2152\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import cupy as cp\n",
        "import numpy as np\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ruta del dataset local\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "# Nombre de la planta a procesar\n",
        "PLANT_NAME = \"Potato\"\n",
        "# Categoría a procesar\n",
        "CATEGORY = \"color\"\n",
        "# Número de hilos para paralelización\n",
        "MAX_WORKERS = 16\n",
        "\n",
        "def collect_image_paths(directory):\n",
        "    file_paths = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        if PLANT_NAME in root:\n",
        "            for file in files:\n",
        "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    file_paths.append(os.path.join(root, file))\n",
        "    return file_paths\n",
        "\n",
        "def process_image(file_path):\n",
        "    try:\n",
        "        with Image.open(file_path) as img:\n",
        "            return (img.size[0], img.size[1])\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def analyze_plant_dimensions():\n",
        "    category_path = os.path.join(DATASET_PATH, CATEGORY, PLANT_NAME)\n",
        "    if not os.path.exists(category_path):\n",
        "        print(f\"Error: No se encontró la carpeta {category_path}.\")\n",
        "        return None, None, 0\n",
        "    \n",
        "    file_paths = collect_image_paths(category_path)\n",
        "    dimensions = []\n",
        "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "        # Usar tqdm para mostrar progreso\n",
        "        with tqdm(total=len(file_paths), desc=\"Procesando imágenes\") as pbar:\n",
        "            for dim in executor.map(process_image, file_paths):\n",
        "                if dim is not None:\n",
        "                    dimensions.append(dim)\n",
        "                pbar.update(1)\n",
        "    \n",
        "    try:\n",
        "        dim_array = cp.array(dimensions, dtype=cp.int32)\n",
        "        unique_dims, counts = np.unique(dim_array.get(), axis=0, return_counts=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error en el cálculo de dimensiones: {e}\")\n",
        "        return None, None, len(dimensions)\n",
        "    \n",
        "    return unique_dims, counts, len(dimensions)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unique_dims, counts, total_dims = analyze_plant_dimensions()\n",
        "    if unique_dims is not None and counts is not None:\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"Dimensiones de Imágenes ({PLANT_NAME} - {CATEGORY.upper()})\")\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"{'Dimensión':<15} {'Conteo':>10}\")\n",
        "        print(\"-\" * 27)\n",
        "        for dim, count in zip(unique_dims, counts):\n",
        "            print(f\"{f'{dim[0]}x{dim[1]}':<15} {count:>10}\")\n",
        "        print(f\"\\nTotal imágenes procesadas: {total_dims}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ***Raspberry***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Procesando imágenes: 100%|██████████| 371/371 [00:00<00:00, 4818.16it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============================\n",
            "Dimensiones de Imágenes (Raspberry - COLOR)\n",
            "==============================\n",
            "Dimensión           Conteo\n",
            "---------------------------\n",
            "256x256                371\n",
            "\n",
            "Total imágenes procesadas: 371\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import cupy as cp\n",
        "import numpy as np\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ruta del dataset local\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "# Nombre de la planta a procesar\n",
        "PLANT_NAME = \"Raspberry\"\n",
        "# Categoría a procesar\n",
        "CATEGORY = \"color\"\n",
        "# Número de hilos para paralelización\n",
        "MAX_WORKERS = 16\n",
        "\n",
        "def collect_image_paths(directory):\n",
        "    file_paths = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        if PLANT_NAME in root:\n",
        "            for file in files:\n",
        "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    file_paths.append(os.path.join(root, file))\n",
        "    return file_paths\n",
        "\n",
        "def process_image(file_path):\n",
        "    try:\n",
        "        with Image.open(file_path) as img:\n",
        "            return (img.size[0], img.size[1])\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def analyze_plant_dimensions():\n",
        "    category_path = os.path.join(DATASET_PATH, CATEGORY, PLANT_NAME)\n",
        "    if not os.path.exists(category_path):\n",
        "        print(f\"Error: No se encontró la carpeta {category_path}.\")\n",
        "        return None, None, 0\n",
        "    \n",
        "    file_paths = collect_image_paths(category_path)\n",
        "    dimensions = []\n",
        "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "        # Usar tqdm para mostrar progreso\n",
        "        with tqdm(total=len(file_paths), desc=\"Procesando imágenes\") as pbar:\n",
        "            for dim in executor.map(process_image, file_paths):\n",
        "                if dim is not None:\n",
        "                    dimensions.append(dim)\n",
        "                pbar.update(1)\n",
        "    \n",
        "    try:\n",
        "        dim_array = cp.array(dimensions, dtype=cp.int32)\n",
        "        unique_dims, counts = np.unique(dim_array.get(), axis=0, return_counts=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error en el cálculo de dimensiones: {e}\")\n",
        "        return None, None, len(dimensions)\n",
        "    \n",
        "    return unique_dims, counts, len(dimensions)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unique_dims, counts, total_dims = analyze_plant_dimensions()\n",
        "    if unique_dims is not None and counts is not None:\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"Dimensiones de Imágenes ({PLANT_NAME} - {CATEGORY.upper()})\")\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"{'Dimensión':<15} {'Conteo':>10}\")\n",
        "        print(\"-\" * 27)\n",
        "        for dim, count in zip(unique_dims, counts):\n",
        "            print(f\"{f'{dim[0]}x{dim[1]}':<15} {count:>10}\")\n",
        "        print(f\"\\nTotal imágenes procesadas: {total_dims}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ***Soybean***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Procesando imágenes: 100%|██████████| 5090/5090 [00:01<00:00, 4975.56it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============================\n",
            "Dimensiones de Imágenes (Soybean - COLOR)\n",
            "==============================\n",
            "Dimensión           Conteo\n",
            "---------------------------\n",
            "256x256               5090\n",
            "\n",
            "Total imágenes procesadas: 5090\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import cupy as cp\n",
        "import numpy as np\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ruta del dataset local\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "# Nombre de la planta a procesar\n",
        "PLANT_NAME = \"Soybean\"\n",
        "# Categoría a procesar\n",
        "CATEGORY = \"color\"\n",
        "# Número de hilos para paralelización\n",
        "MAX_WORKERS = 16\n",
        "\n",
        "def collect_image_paths(directory):\n",
        "    file_paths = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        if PLANT_NAME in root:\n",
        "            for file in files:\n",
        "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    file_paths.append(os.path.join(root, file))\n",
        "    return file_paths\n",
        "\n",
        "def process_image(file_path):\n",
        "    try:\n",
        "        with Image.open(file_path) as img:\n",
        "            return (img.size[0], img.size[1])\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def analyze_plant_dimensions():\n",
        "    category_path = os.path.join(DATASET_PATH, CATEGORY, PLANT_NAME)\n",
        "    if not os.path.exists(category_path):\n",
        "        print(f\"Error: No se encontró la carpeta {category_path}.\")\n",
        "        return None, None, 0\n",
        "    \n",
        "    file_paths = collect_image_paths(category_path)\n",
        "    dimensions = []\n",
        "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "        # Usar tqdm para mostrar progreso\n",
        "        with tqdm(total=len(file_paths), desc=\"Procesando imágenes\") as pbar:\n",
        "            for dim in executor.map(process_image, file_paths):\n",
        "                if dim is not None:\n",
        "                    dimensions.append(dim)\n",
        "                pbar.update(1)\n",
        "    \n",
        "    try:\n",
        "        dim_array = cp.array(dimensions, dtype=cp.int32)\n",
        "        unique_dims, counts = np.unique(dim_array.get(), axis=0, return_counts=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error en el cálculo de dimensiones: {e}\")\n",
        "        return None, None, len(dimensions)\n",
        "    \n",
        "    return unique_dims, counts, len(dimensions)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unique_dims, counts, total_dims = analyze_plant_dimensions()\n",
        "    if unique_dims is not None and counts is not None:\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"Dimensiones de Imágenes ({PLANT_NAME} - {CATEGORY.upper()})\")\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"{'Dimensión':<15} {'Conteo':>10}\")\n",
        "        print(\"-\" * 27)\n",
        "        for dim, count in zip(unique_dims, counts):\n",
        "            print(f\"{f'{dim[0]}x{dim[1]}':<15} {count:>10}\")\n",
        "        print(f\"\\nTotal imágenes procesadas: {total_dims}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ***Squash***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Procesando imágenes: 100%|██████████| 1835/1835 [00:00<00:00, 3553.04it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============================\n",
            "Dimensiones de Imágenes (Squash - COLOR)\n",
            "==============================\n",
            "Dimensión           Conteo\n",
            "---------------------------\n",
            "256x256               1835\n",
            "\n",
            "Total imágenes procesadas: 1835\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import cupy as cp\n",
        "import numpy as np\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ruta del dataset local\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "# Nombre de la planta a procesar\n",
        "PLANT_NAME = \"Squash\"\n",
        "# Categoría a procesar\n",
        "CATEGORY = \"color\"\n",
        "# Número de hilos para paralelización\n",
        "MAX_WORKERS = 16\n",
        "\n",
        "def collect_image_paths(directory):\n",
        "    file_paths = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        if PLANT_NAME in root:\n",
        "            for file in files:\n",
        "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    file_paths.append(os.path.join(root, file))\n",
        "    return file_paths\n",
        "\n",
        "def process_image(file_path):\n",
        "    try:\n",
        "        with Image.open(file_path) as img:\n",
        "            return (img.size[0], img.size[1])\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def analyze_plant_dimensions():\n",
        "    category_path = os.path.join(DATASET_PATH, CATEGORY, PLANT_NAME)\n",
        "    if not os.path.exists(category_path):\n",
        "        print(f\"Error: No se encontró la carpeta {category_path}.\")\n",
        "        return None, None, 0\n",
        "    \n",
        "    file_paths = collect_image_paths(category_path)\n",
        "    dimensions = []\n",
        "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "        # Usar tqdm para mostrar progreso\n",
        "        with tqdm(total=len(file_paths), desc=\"Procesando imágenes\") as pbar:\n",
        "            for dim in executor.map(process_image, file_paths):\n",
        "                if dim is not None:\n",
        "                    dimensions.append(dim)\n",
        "                pbar.update(1)\n",
        "    \n",
        "    try:\n",
        "        dim_array = cp.array(dimensions, dtype=cp.int32)\n",
        "        unique_dims, counts = np.unique(dim_array.get(), axis=0, return_counts=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error en el cálculo de dimensiones: {e}\")\n",
        "        return None, None, len(dimensions)\n",
        "    \n",
        "    return unique_dims, counts, len(dimensions)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unique_dims, counts, total_dims = analyze_plant_dimensions()\n",
        "    if unique_dims is not None and counts is not None:\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"Dimensiones de Imágenes ({PLANT_NAME} - {CATEGORY.upper()})\")\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"{'Dimensión':<15} {'Conteo':>10}\")\n",
        "        print(\"-\" * 27)\n",
        "        for dim, count in zip(unique_dims, counts):\n",
        "            print(f\"{f'{dim[0]}x{dim[1]}':<15} {count:>10}\")\n",
        "        print(f\"\\nTotal imágenes procesadas: {total_dims}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ***Strawberry***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Procesando imágenes: 100%|██████████| 1565/1565 [00:00<00:00, 5212.53it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============================\n",
            "Dimensiones de Imágenes (Strawberry - COLOR)\n",
            "==============================\n",
            "Dimensión           Conteo\n",
            "---------------------------\n",
            "256x256               1565\n",
            "\n",
            "Total imágenes procesadas: 1565\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import cupy as cp\n",
        "import numpy as np\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ruta del dataset local\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "# Nombre de la planta a procesar\n",
        "PLANT_NAME = \"Strawberry\"\n",
        "# Categoría a procesar\n",
        "CATEGORY = \"color\"\n",
        "# Número de hilos para paralelización\n",
        "MAX_WORKERS = 16\n",
        "\n",
        "def collect_image_paths(directory):\n",
        "    file_paths = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        if PLANT_NAME in root:\n",
        "            for file in files:\n",
        "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    file_paths.append(os.path.join(root, file))\n",
        "    return file_paths\n",
        "\n",
        "def process_image(file_path):\n",
        "    try:\n",
        "        with Image.open(file_path) as img:\n",
        "            return (img.size[0], img.size[1])\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def analyze_plant_dimensions():\n",
        "    category_path = os.path.join(DATASET_PATH, CATEGORY, PLANT_NAME)\n",
        "    if not os.path.exists(category_path):\n",
        "        print(f\"Error: No se encontró la carpeta {category_path}.\")\n",
        "        return None, None, 0\n",
        "    \n",
        "    file_paths = collect_image_paths(category_path)\n",
        "    dimensions = []\n",
        "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "        # Usar tqdm para mostrar progreso\n",
        "        with tqdm(total=len(file_paths), desc=\"Procesando imágenes\") as pbar:\n",
        "            for dim in executor.map(process_image, file_paths):\n",
        "                if dim is not None:\n",
        "                    dimensions.append(dim)\n",
        "                pbar.update(1)\n",
        "    \n",
        "    try:\n",
        "        dim_array = cp.array(dimensions, dtype=cp.int32)\n",
        "        unique_dims, counts = np.unique(dim_array.get(), axis=0, return_counts=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error en el cálculo de dimensiones: {e}\")\n",
        "        return None, None, len(dimensions)\n",
        "    \n",
        "    return unique_dims, counts, len(dimensions)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unique_dims, counts, total_dims = analyze_plant_dimensions()\n",
        "    if unique_dims is not None and counts is not None:\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"Dimensiones de Imágenes ({PLANT_NAME} - {CATEGORY.upper()})\")\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"{'Dimensión':<15} {'Conteo':>10}\")\n",
        "        print(\"-\" * 27)\n",
        "        for dim, count in zip(unique_dims, counts):\n",
        "            print(f\"{f'{dim[0]}x{dim[1]}':<15} {count:>10}\")\n",
        "        print(f\"\\nTotal imágenes procesadas: {total_dims}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ***Tomato***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Procesando imágenes: 100%|██████████| 18160/18160 [00:03<00:00, 4927.47it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============================\n",
            "Dimensiones de Imágenes (Tomato - COLOR)\n",
            "==============================\n",
            "Dimensión           Conteo\n",
            "---------------------------\n",
            "256x256              18160\n",
            "\n",
            "Total imágenes procesadas: 18160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import cupy as cp\n",
        "import numpy as np\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ruta del dataset local\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "# Nombre de la planta a procesar\n",
        "PLANT_NAME = \"Tomato\"\n",
        "# Categoría a procesar\n",
        "CATEGORY = \"color\"\n",
        "# Número de hilos para paralelización\n",
        "MAX_WORKERS = 16\n",
        "\n",
        "def collect_image_paths(directory):\n",
        "    file_paths = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        if PLANT_NAME in root:\n",
        "            for file in files:\n",
        "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    file_paths.append(os.path.join(root, file))\n",
        "    return file_paths\n",
        "\n",
        "def process_image(file_path):\n",
        "    try:\n",
        "        with Image.open(file_path) as img:\n",
        "            return (img.size[0], img.size[1])\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def analyze_plant_dimensions():\n",
        "    category_path = os.path.join(DATASET_PATH, CATEGORY, PLANT_NAME)\n",
        "    if not os.path.exists(category_path):\n",
        "        print(f\"Error: No se encontró la carpeta {category_path}.\")\n",
        "        return None, None, 0\n",
        "    \n",
        "    file_paths = collect_image_paths(category_path)\n",
        "    dimensions = []\n",
        "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "        # Usar tqdm para mostrar progreso\n",
        "        with tqdm(total=len(file_paths), desc=\"Procesando imágenes\") as pbar:\n",
        "            for dim in executor.map(process_image, file_paths):\n",
        "                if dim is not None:\n",
        "                    dimensions.append(dim)\n",
        "                pbar.update(1)\n",
        "    \n",
        "    try:\n",
        "        dim_array = cp.array(dimensions, dtype=cp.int32)\n",
        "        unique_dims, counts = np.unique(dim_array.get(), axis=0, return_counts=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error en el cálculo de dimensiones: {e}\")\n",
        "        return None, None, len(dimensions)\n",
        "    \n",
        "    return unique_dims, counts, len(dimensions)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unique_dims, counts, total_dims = analyze_plant_dimensions()\n",
        "    if unique_dims is not None and counts is not None:\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"Dimensiones de Imágenes ({PLANT_NAME} - {CATEGORY.upper()})\")\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"{'Dimensión':<15} {'Conteo':>10}\")\n",
        "        print(\"-\" * 27)\n",
        "        for dim, count in zip(unique_dims, counts):\n",
        "            print(f\"{f'{dim[0]}x{dim[1]}':<15} {count:>10}\")\n",
        "        print(f\"\\nTotal imágenes procesadas: {total_dims}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### ***Grayscale***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ***Apple***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Procesando imágenes: 100%|██████████| 3171/3171 [00:00<00:00, 4704.76it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============================\n",
            "Dimensiones de Imágenes (Apple - GRAYSCALE)\n",
            "==============================\n",
            "Dimensión           Conteo\n",
            "---------------------------\n",
            "256x256               3171\n",
            "\n",
            "Total imágenes procesadas: 3171\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import cupy as cp\n",
        "import numpy as np\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ruta del dataset local\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "# Nombre de la planta a procesar\n",
        "PLANT_NAME = \"Apple\"\n",
        "# Categoría a procesar\n",
        "CATEGORY = \"grayscale\"\n",
        "# Número de hilos para paralelización\n",
        "MAX_WORKERS = 16\n",
        "\n",
        "def collect_image_paths(directory):\n",
        "    file_paths = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        if PLANT_NAME in root:\n",
        "            for file in files:\n",
        "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    file_paths.append(os.path.join(root, file))\n",
        "    return file_paths\n",
        "\n",
        "def process_image(file_path):\n",
        "    try:\n",
        "        with Image.open(file_path) as img:\n",
        "            return (img.size[0], img.size[1])\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def analyze_plant_dimensions():\n",
        "    category_path = os.path.join(DATASET_PATH, CATEGORY, PLANT_NAME)\n",
        "    if not os.path.exists(category_path):\n",
        "        print(f\"Error: No se encontró la carpeta {category_path}.\")\n",
        "        return None, None, 0\n",
        "    \n",
        "    file_paths = collect_image_paths(category_path)\n",
        "    dimensions = []\n",
        "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "        # Usar tqdm para mostrar progreso\n",
        "        with tqdm(total=len(file_paths), desc=\"Procesando imágenes\") as pbar:\n",
        "            for dim in executor.map(process_image, file_paths):\n",
        "                if dim is not None:\n",
        "                    dimensions.append(dim)\n",
        "                pbar.update(1)\n",
        "    \n",
        "    try:\n",
        "        dim_array = cp.array(dimensions, dtype=cp.int32)\n",
        "        unique_dims, counts = np.unique(dim_array.get(), axis=0, return_counts=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error en el cálculo de dimensiones: {e}\")\n",
        "        return None, None, len(dimensions)\n",
        "    \n",
        "    return unique_dims, counts, len(dimensions)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unique_dims, counts, total_dims = analyze_plant_dimensions()\n",
        "    if unique_dims is not None and counts is not None:\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"Dimensiones de Imágenes ({PLANT_NAME} - {CATEGORY.upper()})\")\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"{'Dimensión':<15} {'Conteo':>10}\")\n",
        "        print(\"-\" * 27)\n",
        "        for dim, count in zip(unique_dims, counts):\n",
        "            print(f\"{f'{dim[0]}x{dim[1]}':<15} {count:>10}\")\n",
        "        print(f\"\\nTotal imágenes procesadas: {total_dims}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ***Blueberry***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Procesando imágenes: 100%|██████████| 1502/1502 [00:00<00:00, 5900.12it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============================\n",
            "Dimensiones de Imágenes (Blueberry - GRAYSCALE)\n",
            "==============================\n",
            "Dimensión           Conteo\n",
            "---------------------------\n",
            "256x256               1502\n",
            "\n",
            "Total imágenes procesadas: 1502\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import cupy as cp\n",
        "import numpy as np\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ruta del dataset local\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "# Nombre de la planta a procesar\n",
        "PLANT_NAME = \"Blueberry\"\n",
        "# Categoría a procesar\n",
        "CATEGORY = \"grayscale\"\n",
        "# Número de hilos para paralelización\n",
        "MAX_WORKERS = 16\n",
        "\n",
        "def collect_image_paths(directory):\n",
        "    file_paths = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        if PLANT_NAME in root:\n",
        "            for file in files:\n",
        "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    file_paths.append(os.path.join(root, file))\n",
        "    return file_paths\n",
        "\n",
        "def process_image(file_path):\n",
        "    try:\n",
        "        with Image.open(file_path) as img:\n",
        "            return (img.size[0], img.size[1])\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def analyze_plant_dimensions():\n",
        "    category_path = os.path.join(DATASET_PATH, CATEGORY, PLANT_NAME)\n",
        "    if not os.path.exists(category_path):\n",
        "        print(f\"Error: No se encontró la carpeta {category_path}.\")\n",
        "        return None, None, 0\n",
        "    \n",
        "    file_paths = collect_image_paths(category_path)\n",
        "    dimensions = []\n",
        "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "        # Usar tqdm para mostrar progreso\n",
        "        with tqdm(total=len(file_paths), desc=\"Procesando imágenes\") as pbar:\n",
        "            for dim in executor.map(process_image, file_paths):\n",
        "                if dim is not None:\n",
        "                    dimensions.append(dim)\n",
        "                pbar.update(1)\n",
        "    \n",
        "    try:\n",
        "        dim_array = cp.array(dimensions, dtype=cp.int32)\n",
        "        unique_dims, counts = np.unique(dim_array.get(), axis=0, return_counts=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error en el cálculo de dimensiones: {e}\")\n",
        "        return None, None, len(dimensions)\n",
        "    \n",
        "    return unique_dims, counts, len(dimensions)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unique_dims, counts, total_dims = analyze_plant_dimensions()\n",
        "    if unique_dims is not None and counts is not None:\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"Dimensiones de Imágenes ({PLANT_NAME} - {CATEGORY.upper()})\")\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"{'Dimensión':<15} {'Conteo':>10}\")\n",
        "        print(\"-\" * 27)\n",
        "        for dim, count in zip(unique_dims, counts):\n",
        "            print(f\"{f'{dim[0]}x{dim[1]}':<15} {count:>10}\")\n",
        "        print(f\"\\nTotal imágenes procesadas: {total_dims}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ***Cherry***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Procesando imágenes: 100%|██████████| 1906/1906 [00:00<00:00, 4933.46it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============================\n",
            "Dimensiones de Imágenes (Cherry - GRAYSCALE)\n",
            "==============================\n",
            "Dimensión           Conteo\n",
            "---------------------------\n",
            "256x256               1906\n",
            "\n",
            "Total imágenes procesadas: 1906\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import cupy as cp\n",
        "import numpy as np\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ruta del dataset local\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "# Nombre de la planta a procesar\n",
        "PLANT_NAME = \"Cherry\"\n",
        "# Categoría a procesar\n",
        "CATEGORY = \"grayscale\"\n",
        "# Número de hilos para paralelización\n",
        "MAX_WORKERS = 16\n",
        "\n",
        "def collect_image_paths(directory):\n",
        "    file_paths = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        if PLANT_NAME in root:\n",
        "            for file in files:\n",
        "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    file_paths.append(os.path.join(root, file))\n",
        "    return file_paths\n",
        "\n",
        "def process_image(file_path):\n",
        "    try:\n",
        "        with Image.open(file_path) as img:\n",
        "            return (img.size[0], img.size[1])\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def analyze_plant_dimensions():\n",
        "    category_path = os.path.join(DATASET_PATH, CATEGORY, PLANT_NAME)\n",
        "    if not os.path.exists(category_path):\n",
        "        print(f\"Error: No se encontró la carpeta {category_path}.\")\n",
        "        return None, None, 0\n",
        "    \n",
        "    file_paths = collect_image_paths(category_path)\n",
        "    dimensions = []\n",
        "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "        # Usar tqdm para mostrar progreso\n",
        "        with tqdm(total=len(file_paths), desc=\"Procesando imágenes\") as pbar:\n",
        "            for dim in executor.map(process_image, file_paths):\n",
        "                if dim is not None:\n",
        "                    dimensions.append(dim)\n",
        "                pbar.update(1)\n",
        "    \n",
        "    try:\n",
        "        dim_array = cp.array(dimensions, dtype=cp.int32)\n",
        "        unique_dims, counts = np.unique(dim_array.get(), axis=0, return_counts=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error en el cálculo de dimensiones: {e}\")\n",
        "        return None, None, len(dimensions)\n",
        "    \n",
        "    return unique_dims, counts, len(dimensions)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unique_dims, counts, total_dims = analyze_plant_dimensions()\n",
        "    if unique_dims is not None and counts is not None:\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"Dimensiones de Imágenes ({PLANT_NAME} - {CATEGORY.upper()})\")\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"{'Dimensión':<15} {'Conteo':>10}\")\n",
        "        print(\"-\" * 27)\n",
        "        for dim, count in zip(unique_dims, counts):\n",
        "            print(f\"{f'{dim[0]}x{dim[1]}':<15} {count:>10}\")\n",
        "        print(f\"\\nTotal imágenes procesadas: {total_dims}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ***Corn***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Procesando imágenes: 100%|██████████| 3852/3852 [00:00<00:00, 5632.23it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============================\n",
            "Dimensiones de Imágenes (Corn - GRAYSCALE)\n",
            "==============================\n",
            "Dimensión           Conteo\n",
            "---------------------------\n",
            "256x256               3852\n",
            "\n",
            "Total imágenes procesadas: 3852\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import cupy as cp\n",
        "import numpy as np\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ruta del dataset local\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "# Nombre de la planta a procesar\n",
        "PLANT_NAME = \"Corn\"\n",
        "# Categoría a procesar\n",
        "CATEGORY = \"grayscale\"\n",
        "# Número de hilos para paralelización\n",
        "MAX_WORKERS = 16\n",
        "\n",
        "def collect_image_paths(directory):\n",
        "    file_paths = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        if PLANT_NAME in root:\n",
        "            for file in files:\n",
        "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    file_paths.append(os.path.join(root, file))\n",
        "    return file_paths\n",
        "\n",
        "def process_image(file_path):\n",
        "    try:\n",
        "        with Image.open(file_path) as img:\n",
        "            return (img.size[0], img.size[1])\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def analyze_plant_dimensions():\n",
        "    category_path = os.path.join(DATASET_PATH, CATEGORY, PLANT_NAME)\n",
        "    if not os.path.exists(category_path):\n",
        "        print(f\"Error: No se encontró la carpeta {category_path}.\")\n",
        "        return None, None, 0\n",
        "    \n",
        "    file_paths = collect_image_paths(category_path)\n",
        "    dimensions = []\n",
        "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "        # Usar tqdm para mostrar progreso\n",
        "        with tqdm(total=len(file_paths), desc=\"Procesando imágenes\") as pbar:\n",
        "            for dim in executor.map(process_image, file_paths):\n",
        "                if dim is not None:\n",
        "                    dimensions.append(dim)\n",
        "                pbar.update(1)\n",
        "    \n",
        "    try:\n",
        "        dim_array = cp.array(dimensions, dtype=cp.int32)\n",
        "        unique_dims, counts = np.unique(dim_array.get(), axis=0, return_counts=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error en el cálculo de dimensiones: {e}\")\n",
        "        return None, None, len(dimensions)\n",
        "    \n",
        "    return unique_dims, counts, len(dimensions)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unique_dims, counts, total_dims = analyze_plant_dimensions()\n",
        "    if unique_dims is not None and counts is not None:\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"Dimensiones de Imágenes ({PLANT_NAME} - {CATEGORY.upper()})\")\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"{'Dimensión':<15} {'Conteo':>10}\")\n",
        "        print(\"-\" * 27)\n",
        "        for dim, count in zip(unique_dims, counts):\n",
        "            print(f\"{f'{dim[0]}x{dim[1]}':<15} {count:>10}\")\n",
        "        print(f\"\\nTotal imágenes procesadas: {total_dims}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ***Grape***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Procesando imágenes: 100%|██████████| 4062/4062 [00:00<00:00, 5439.98it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============================\n",
            "Dimensiones de Imágenes (Grape - GRAYSCALE)\n",
            "==============================\n",
            "Dimensión           Conteo\n",
            "---------------------------\n",
            "256x256               4062\n",
            "\n",
            "Total imágenes procesadas: 4062\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import cupy as cp\n",
        "import numpy as np\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ruta del dataset local\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "# Nombre de la planta a procesar\n",
        "PLANT_NAME = \"Grape\"\n",
        "# Categoría a procesar\n",
        "CATEGORY = \"grayscale\"\n",
        "# Número de hilos para paralelización\n",
        "MAX_WORKERS = 16\n",
        "\n",
        "def collect_image_paths(directory):\n",
        "    file_paths = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        if PLANT_NAME in root:\n",
        "            for file in files:\n",
        "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    file_paths.append(os.path.join(root, file))\n",
        "    return file_paths\n",
        "\n",
        "def process_image(file_path):\n",
        "    try:\n",
        "        with Image.open(file_path) as img:\n",
        "            return (img.size[0], img.size[1])\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def analyze_plant_dimensions():\n",
        "    category_path = os.path.join(DATASET_PATH, CATEGORY, PLANT_NAME)\n",
        "    if not os.path.exists(category_path):\n",
        "        print(f\"Error: No se encontró la carpeta {category_path}.\")\n",
        "        return None, None, 0\n",
        "    \n",
        "    file_paths = collect_image_paths(category_path)\n",
        "    dimensions = []\n",
        "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "        # Usar tqdm para mostrar progreso\n",
        "        with tqdm(total=len(file_paths), desc=\"Procesando imágenes\") as pbar:\n",
        "            for dim in executor.map(process_image, file_paths):\n",
        "                if dim is not None:\n",
        "                    dimensions.append(dim)\n",
        "                pbar.update(1)\n",
        "    \n",
        "    try:\n",
        "        dim_array = cp.array(dimensions, dtype=cp.int32)\n",
        "        unique_dims, counts = np.unique(dim_array.get(), axis=0, return_counts=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error en el cálculo de dimensiones: {e}\")\n",
        "        return None, None, len(dimensions)\n",
        "    \n",
        "    return unique_dims, counts, len(dimensions)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unique_dims, counts, total_dims = analyze_plant_dimensions()\n",
        "    if unique_dims is not None and counts is not None:\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"Dimensiones de Imágenes ({PLANT_NAME} - {CATEGORY.upper()})\")\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"{'Dimensión':<15} {'Conteo':>10}\")\n",
        "        print(\"-\" * 27)\n",
        "        for dim, count in zip(unique_dims, counts):\n",
        "            print(f\"{f'{dim[0]}x{dim[1]}':<15} {count:>10}\")\n",
        "        print(f\"\\nTotal imágenes procesadas: {total_dims}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ***Orange***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Procesando imágenes: 100%|██████████| 5507/5507 [00:01<00:00, 5465.90it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============================\n",
            "Dimensiones de Imágenes (Orange - GRAYSCALE)\n",
            "==============================\n",
            "Dimensión           Conteo\n",
            "---------------------------\n",
            "256x256               5507\n",
            "\n",
            "Total imágenes procesadas: 5507\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import cupy as cp\n",
        "import numpy as np\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ruta del dataset local\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "# Nombre de la planta a procesar\n",
        "PLANT_NAME = \"Orange\"\n",
        "# Categoría a procesar\n",
        "CATEGORY = \"grayscale\"\n",
        "# Número de hilos para paralelización\n",
        "MAX_WORKERS = 16\n",
        "\n",
        "def collect_image_paths(directory):\n",
        "    file_paths = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        if PLANT_NAME in root:\n",
        "            for file in files:\n",
        "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    file_paths.append(os.path.join(root, file))\n",
        "    return file_paths\n",
        "\n",
        "def process_image(file_path):\n",
        "    try:\n",
        "        with Image.open(file_path) as img:\n",
        "            return (img.size[0], img.size[1])\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def analyze_plant_dimensions():\n",
        "    category_path = os.path.join(DATASET_PATH, CATEGORY, PLANT_NAME)\n",
        "    if not os.path.exists(category_path):\n",
        "        print(f\"Error: No se encontró la carpeta {category_path}.\")\n",
        "        return None, None, 0\n",
        "    \n",
        "    file_paths = collect_image_paths(category_path)\n",
        "    dimensions = []\n",
        "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "        # Usar tqdm para mostrar progreso\n",
        "        with tqdm(total=len(file_paths), desc=\"Procesando imágenes\") as pbar:\n",
        "            for dim in executor.map(process_image, file_paths):\n",
        "                if dim is not None:\n",
        "                    dimensions.append(dim)\n",
        "                pbar.update(1)\n",
        "    \n",
        "    try:\n",
        "        dim_array = cp.array(dimensions, dtype=cp.int32)\n",
        "        unique_dims, counts = np.unique(dim_array.get(), axis=0, return_counts=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error en el cálculo de dimensiones: {e}\")\n",
        "        return None, None, len(dimensions)\n",
        "    \n",
        "    return unique_dims, counts, len(dimensions)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unique_dims, counts, total_dims = analyze_plant_dimensions()\n",
        "    if unique_dims is not None and counts is not None:\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"Dimensiones de Imágenes ({PLANT_NAME} - {CATEGORY.upper()})\")\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"{'Dimensión':<15} {'Conteo':>10}\")\n",
        "        print(\"-\" * 27)\n",
        "        for dim, count in zip(unique_dims, counts):\n",
        "            print(f\"{f'{dim[0]}x{dim[1]}':<15} {count:>10}\")\n",
        "        print(f\"\\nTotal imágenes procesadas: {total_dims}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ***Peach***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Procesando imágenes: 100%|██████████| 2657/2657 [00:00<00:00, 5805.21it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============================\n",
            "Dimensiones de Imágenes (Peach - GRAYSCALE)\n",
            "==============================\n",
            "Dimensión           Conteo\n",
            "---------------------------\n",
            "256x256               2657\n",
            "\n",
            "Total imágenes procesadas: 2657\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import cupy as cp\n",
        "import numpy as np\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ruta del dataset local\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "# Nombre de la planta a procesar\n",
        "PLANT_NAME = \"Peach\"\n",
        "# Categoría a procesar\n",
        "CATEGORY = \"grayscale\"\n",
        "# Número de hilos para paralelización\n",
        "MAX_WORKERS = 16\n",
        "\n",
        "def collect_image_paths(directory):\n",
        "    file_paths = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        if PLANT_NAME in root:\n",
        "            for file in files:\n",
        "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    file_paths.append(os.path.join(root, file))\n",
        "    return file_paths\n",
        "\n",
        "def process_image(file_path):\n",
        "    try:\n",
        "        with Image.open(file_path) as img:\n",
        "            return (img.size[0], img.size[1])\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def analyze_plant_dimensions():\n",
        "    category_path = os.path.join(DATASET_PATH, CATEGORY, PLANT_NAME)\n",
        "    if not os.path.exists(category_path):\n",
        "        print(f\"Error: No se encontró la carpeta {category_path}.\")\n",
        "        return None, None, 0\n",
        "    \n",
        "    file_paths = collect_image_paths(category_path)\n",
        "    dimensions = []\n",
        "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "        # Usar tqdm para mostrar progreso\n",
        "        with tqdm(total=len(file_paths), desc=\"Procesando imágenes\") as pbar:\n",
        "            for dim in executor.map(process_image, file_paths):\n",
        "                if dim is not None:\n",
        "                    dimensions.append(dim)\n",
        "                pbar.update(1)\n",
        "    \n",
        "    try:\n",
        "        dim_array = cp.array(dimensions, dtype=cp.int32)\n",
        "        unique_dims, counts = np.unique(dim_array.get(), axis=0, return_counts=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error en el cálculo de dimensiones: {e}\")\n",
        "        return None, None, len(dimensions)\n",
        "    \n",
        "    return unique_dims, counts, len(dimensions)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unique_dims, counts, total_dims = analyze_plant_dimensions()\n",
        "    if unique_dims is not None and counts is not None:\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"Dimensiones de Imágenes ({PLANT_NAME} - {CATEGORY.upper()})\")\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"{'Dimensión':<15} {'Conteo':>10}\")\n",
        "        print(\"-\" * 27)\n",
        "        for dim, count in zip(unique_dims, counts):\n",
        "            print(f\"{f'{dim[0]}x{dim[1]}':<15} {count:>10}\")\n",
        "        print(f\"\\nTotal imágenes procesadas: {total_dims}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ***Pepper***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Procesando imágenes: 100%|██████████| 2475/2475 [00:00<00:00, 5093.92it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============================\n",
            "Dimensiones de Imágenes (Pepper - GRAYSCALE)\n",
            "==============================\n",
            "Dimensión           Conteo\n",
            "---------------------------\n",
            "256x256               2475\n",
            "\n",
            "Total imágenes procesadas: 2475\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import cupy as cp\n",
        "import numpy as np\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ruta del dataset local\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "# Nombre de la planta a procesar\n",
        "PLANT_NAME = \"Pepper\"\n",
        "# Categoría a procesar\n",
        "CATEGORY = \"grayscale\"\n",
        "# Número de hilos para paralelización\n",
        "MAX_WORKERS = 16\n",
        "\n",
        "def collect_image_paths(directory):\n",
        "    file_paths = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        if PLANT_NAME in root:\n",
        "            for file in files:\n",
        "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    file_paths.append(os.path.join(root, file))\n",
        "    return file_paths\n",
        "\n",
        "def process_image(file_path):\n",
        "    try:\n",
        "        with Image.open(file_path) as img:\n",
        "            return (img.size[0], img.size[1])\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def analyze_plant_dimensions():\n",
        "    category_path = os.path.join(DATASET_PATH, CATEGORY, PLANT_NAME)\n",
        "    if not os.path.exists(category_path):\n",
        "        print(f\"Error: No se encontró la carpeta {category_path}.\")\n",
        "        return None, None, 0\n",
        "    \n",
        "    file_paths = collect_image_paths(category_path)\n",
        "    dimensions = []\n",
        "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "        # Usar tqdm para mostrar progreso\n",
        "        with tqdm(total=len(file_paths), desc=\"Procesando imágenes\") as pbar:\n",
        "            for dim in executor.map(process_image, file_paths):\n",
        "                if dim is not None:\n",
        "                    dimensions.append(dim)\n",
        "                pbar.update(1)\n",
        "    \n",
        "    try:\n",
        "        dim_array = cp.array(dimensions, dtype=cp.int32)\n",
        "        unique_dims, counts = np.unique(dim_array.get(), axis=0, return_counts=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error en el cálculo de dimensiones: {e}\")\n",
        "        return None, None, len(dimensions)\n",
        "    \n",
        "    return unique_dims, counts, len(dimensions)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unique_dims, counts, total_dims = analyze_plant_dimensions()\n",
        "    if unique_dims is not None and counts is not None:\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"Dimensiones de Imágenes ({PLANT_NAME} - {CATEGORY.upper()})\")\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"{'Dimensión':<15} {'Conteo':>10}\")\n",
        "        print(\"-\" * 27)\n",
        "        for dim, count in zip(unique_dims, counts):\n",
        "            print(f\"{f'{dim[0]}x{dim[1]}':<15} {count:>10}\")\n",
        "        print(f\"\\nTotal imágenes procesadas: {total_dims}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ***Potato***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Procesando imágenes: 100%|██████████| 2152/2152 [00:00<00:00, 5764.15it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============================\n",
            "Dimensiones de Imágenes (Potato - GRAYSCALE)\n",
            "==============================\n",
            "Dimensión           Conteo\n",
            "---------------------------\n",
            "256x256               2152\n",
            "\n",
            "Total imágenes procesadas: 2152\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import cupy as cp\n",
        "import numpy as np\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ruta del dataset local\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "# Nombre de la planta a procesar\n",
        "PLANT_NAME = \"Potato\"\n",
        "# Categoría a procesar\n",
        "CATEGORY = \"grayscale\"\n",
        "# Número de hilos para paralelización\n",
        "MAX_WORKERS = 16\n",
        "\n",
        "def collect_image_paths(directory):\n",
        "    file_paths = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        if PLANT_NAME in root:\n",
        "            for file in files:\n",
        "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    file_paths.append(os.path.join(root, file))\n",
        "    return file_paths\n",
        "\n",
        "def process_image(file_path):\n",
        "    try:\n",
        "        with Image.open(file_path) as img:\n",
        "            return (img.size[0], img.size[1])\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def analyze_plant_dimensions():\n",
        "    category_path = os.path.join(DATASET_PATH, CATEGORY, PLANT_NAME)\n",
        "    if not os.path.exists(category_path):\n",
        "        print(f\"Error: No se encontró la carpeta {category_path}.\")\n",
        "        return None, None, 0\n",
        "    \n",
        "    file_paths = collect_image_paths(category_path)\n",
        "    dimensions = []\n",
        "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "        # Usar tqdm para mostrar progreso\n",
        "        with tqdm(total=len(file_paths), desc=\"Procesando imágenes\") as pbar:\n",
        "            for dim in executor.map(process_image, file_paths):\n",
        "                if dim is not None:\n",
        "                    dimensions.append(dim)\n",
        "                pbar.update(1)\n",
        "    \n",
        "    try:\n",
        "        dim_array = cp.array(dimensions, dtype=cp.int32)\n",
        "        unique_dims, counts = np.unique(dim_array.get(), axis=0, return_counts=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error en el cálculo de dimensiones: {e}\")\n",
        "        return None, None, len(dimensions)\n",
        "    \n",
        "    return unique_dims, counts, len(dimensions)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unique_dims, counts, total_dims = analyze_plant_dimensions()\n",
        "    if unique_dims is not None and counts is not None:\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"Dimensiones de Imágenes ({PLANT_NAME} - {CATEGORY.upper()})\")\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"{'Dimensión':<15} {'Conteo':>10}\")\n",
        "        print(\"-\" * 27)\n",
        "        for dim, count in zip(unique_dims, counts):\n",
        "            print(f\"{f'{dim[0]}x{dim[1]}':<15} {count:>10}\")\n",
        "        print(f\"\\nTotal imágenes procesadas: {total_dims}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ***Raspberry***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Procesando imágenes: 100%|██████████| 371/371 [00:00<00:00, 5640.02it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============================\n",
            "Dimensiones de Imágenes (Raspberry - GRAYSCALE)\n",
            "==============================\n",
            "Dimensión           Conteo\n",
            "---------------------------\n",
            "256x256                371\n",
            "\n",
            "Total imágenes procesadas: 371\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import cupy as cp\n",
        "import numpy as np\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ruta del dataset local\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "# Nombre de la planta a procesar\n",
        "PLANT_NAME = \"Raspberry\"\n",
        "# Categoría a procesar\n",
        "CATEGORY = \"grayscale\"\n",
        "# Número de hilos para paralelización\n",
        "MAX_WORKERS = 16\n",
        "\n",
        "def collect_image_paths(directory):\n",
        "    file_paths = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        if PLANT_NAME in root:\n",
        "            for file in files:\n",
        "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    file_paths.append(os.path.join(root, file))\n",
        "    return file_paths\n",
        "\n",
        "def process_image(file_path):\n",
        "    try:\n",
        "        with Image.open(file_path) as img:\n",
        "            return (img.size[0], img.size[1])\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def analyze_plant_dimensions():\n",
        "    category_path = os.path.join(DATASET_PATH, CATEGORY, PLANT_NAME)\n",
        "    if not os.path.exists(category_path):\n",
        "        print(f\"Error: No se encontró la carpeta {category_path}.\")\n",
        "        return None, None, 0\n",
        "    \n",
        "    file_paths = collect_image_paths(category_path)\n",
        "    dimensions = []\n",
        "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "        # Usar tqdm para mostrar progreso\n",
        "        with tqdm(total=len(file_paths), desc=\"Procesando imágenes\") as pbar:\n",
        "            for dim in executor.map(process_image, file_paths):\n",
        "                if dim is not None:\n",
        "                    dimensions.append(dim)\n",
        "                pbar.update(1)\n",
        "    \n",
        "    try:\n",
        "        dim_array = cp.array(dimensions, dtype=cp.int32)\n",
        "        unique_dims, counts = np.unique(dim_array.get(), axis=0, return_counts=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error en el cálculo de dimensiones: {e}\")\n",
        "        return None, None, len(dimensions)\n",
        "    \n",
        "    return unique_dims, counts, len(dimensions)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unique_dims, counts, total_dims = analyze_plant_dimensions()\n",
        "    if unique_dims is not None and counts is not None:\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"Dimensiones de Imágenes ({PLANT_NAME} - {CATEGORY.upper()})\")\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"{'Dimensión':<15} {'Conteo':>10}\")\n",
        "        print(\"-\" * 27)\n",
        "        for dim, count in zip(unique_dims, counts):\n",
        "            print(f\"{f'{dim[0]}x{dim[1]}':<15} {count:>10}\")\n",
        "        print(f\"\\nTotal imágenes procesadas: {total_dims}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ***Soybean***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Procesando imágenes: 100%|██████████| 5090/5090 [00:00<00:00, 5485.34it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============================\n",
            "Dimensiones de Imágenes (Soybean - GRAYSCALE)\n",
            "==============================\n",
            "Dimensión           Conteo\n",
            "---------------------------\n",
            "256x256               5090\n",
            "\n",
            "Total imágenes procesadas: 5090\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import cupy as cp\n",
        "import numpy as np\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ruta del dataset local\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "# Nombre de la planta a procesar\n",
        "PLANT_NAME = \"Soybean\"\n",
        "# Categoría a procesar\n",
        "CATEGORY = \"grayscale\"\n",
        "# Número de hilos para paralelización\n",
        "MAX_WORKERS = 16\n",
        "\n",
        "def collect_image_paths(directory):\n",
        "    file_paths = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        if PLANT_NAME in root:\n",
        "            for file in files:\n",
        "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    file_paths.append(os.path.join(root, file))\n",
        "    return file_paths\n",
        "\n",
        "def process_image(file_path):\n",
        "    try:\n",
        "        with Image.open(file_path) as img:\n",
        "            return (img.size[0], img.size[1])\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def analyze_plant_dimensions():\n",
        "    category_path = os.path.join(DATASET_PATH, CATEGORY, PLANT_NAME)\n",
        "    if not os.path.exists(category_path):\n",
        "        print(f\"Error: No se encontró la carpeta {category_path}.\")\n",
        "        return None, None, 0\n",
        "    \n",
        "    file_paths = collect_image_paths(category_path)\n",
        "    dimensions = []\n",
        "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "        # Usar tqdm para mostrar progreso\n",
        "        with tqdm(total=len(file_paths), desc=\"Procesando imágenes\") as pbar:\n",
        "            for dim in executor.map(process_image, file_paths):\n",
        "                if dim is not None:\n",
        "                    dimensions.append(dim)\n",
        "                pbar.update(1)\n",
        "    \n",
        "    try:\n",
        "        dim_array = cp.array(dimensions, dtype=cp.int32)\n",
        "        unique_dims, counts = np.unique(dim_array.get(), axis=0, return_counts=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error en el cálculo de dimensiones: {e}\")\n",
        "        return None, None, len(dimensions)\n",
        "    \n",
        "    return unique_dims, counts, len(dimensions)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unique_dims, counts, total_dims = analyze_plant_dimensions()\n",
        "    if unique_dims is not None and counts is not None:\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"Dimensiones de Imágenes ({PLANT_NAME} - {CATEGORY.upper()})\")\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"{'Dimensión':<15} {'Conteo':>10}\")\n",
        "        print(\"-\" * 27)\n",
        "        for dim, count in zip(unique_dims, counts):\n",
        "            print(f\"{f'{dim[0]}x{dim[1]}':<15} {count:>10}\")\n",
        "        print(f\"\\nTotal imágenes procesadas: {total_dims}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ***Squash***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Procesando imágenes: 100%|██████████| 1835/1835 [00:00<00:00, 5462.27it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============================\n",
            "Dimensiones de Imágenes (Squash - GRAYSCALE)\n",
            "==============================\n",
            "Dimensión           Conteo\n",
            "---------------------------\n",
            "256x256               1835\n",
            "\n",
            "Total imágenes procesadas: 1835\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import cupy as cp\n",
        "import numpy as np\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ruta del dataset local\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "# Nombre de la planta a procesar\n",
        "PLANT_NAME = \"Squash\"\n",
        "# Categoría a procesar\n",
        "CATEGORY = \"grayscale\"\n",
        "# Número de hilos para paralelización\n",
        "MAX_WORKERS = 16\n",
        "\n",
        "def collect_image_paths(directory):\n",
        "    file_paths = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        if PLANT_NAME in root:\n",
        "            for file in files:\n",
        "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    file_paths.append(os.path.join(root, file))\n",
        "    return file_paths\n",
        "\n",
        "def process_image(file_path):\n",
        "    try:\n",
        "        with Image.open(file_path) as img:\n",
        "            return (img.size[0], img.size[1])\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def analyze_plant_dimensions():\n",
        "    category_path = os.path.join(DATASET_PATH, CATEGORY, PLANT_NAME)\n",
        "    if not os.path.exists(category_path):\n",
        "        print(f\"Error: No se encontró la carpeta {category_path}.\")\n",
        "        return None, None, 0\n",
        "    \n",
        "    file_paths = collect_image_paths(category_path)\n",
        "    dimensions = []\n",
        "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "        # Usar tqdm para mostrar progreso\n",
        "        with tqdm(total=len(file_paths), desc=\"Procesando imágenes\") as pbar:\n",
        "            for dim in executor.map(process_image, file_paths):\n",
        "                if dim is not None:\n",
        "                    dimensions.append(dim)\n",
        "                pbar.update(1)\n",
        "    \n",
        "    try:\n",
        "        dim_array = cp.array(dimensions, dtype=cp.int32)\n",
        "        unique_dims, counts = np.unique(dim_array.get(), axis=0, return_counts=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error en el cálculo de dimensiones: {e}\")\n",
        "        return None, None, len(dimensions)\n",
        "    \n",
        "    return unique_dims, counts, len(dimensions)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unique_dims, counts, total_dims = analyze_plant_dimensions()\n",
        "    if unique_dims is not None and counts is not None:\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"Dimensiones de Imágenes ({PLANT_NAME} - {CATEGORY.upper()})\")\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"{'Dimensión':<15} {'Conteo':>10}\")\n",
        "        print(\"-\" * 27)\n",
        "        for dim, count in zip(unique_dims, counts):\n",
        "            print(f\"{f'{dim[0]}x{dim[1]}':<15} {count:>10}\")\n",
        "        print(f\"\\nTotal imágenes procesadas: {total_dims}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ***Strawberry***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Procesando imágenes: 100%|██████████| 1565/1565 [00:00<00:00, 4875.42it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============================\n",
            "Dimensiones de Imágenes (Strawberry - GRAYSCALE)\n",
            "==============================\n",
            "Dimensión           Conteo\n",
            "---------------------------\n",
            "256x256               1565\n",
            "\n",
            "Total imágenes procesadas: 1565\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import cupy as cp\n",
        "import numpy as np\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ruta del dataset local\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "# Nombre de la planta a procesar\n",
        "PLANT_NAME = \"Strawberry\"\n",
        "# Categoría a procesar\n",
        "CATEGORY = \"grayscale\"\n",
        "# Número de hilos para paralelización\n",
        "MAX_WORKERS = 16\n",
        "\n",
        "def collect_image_paths(directory):\n",
        "    file_paths = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        if PLANT_NAME in root:\n",
        "            for file in files:\n",
        "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    file_paths.append(os.path.join(root, file))\n",
        "    return file_paths\n",
        "\n",
        "def process_image(file_path):\n",
        "    try:\n",
        "        with Image.open(file_path) as img:\n",
        "            return (img.size[0], img.size[1])\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def analyze_plant_dimensions():\n",
        "    category_path = os.path.join(DATASET_PATH, CATEGORY, PLANT_NAME)\n",
        "    if not os.path.exists(category_path):\n",
        "        print(f\"Error: No se encontró la carpeta {category_path}.\")\n",
        "        return None, None, 0\n",
        "    \n",
        "    file_paths = collect_image_paths(category_path)\n",
        "    dimensions = []\n",
        "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "        # Usar tqdm para mostrar progreso\n",
        "        with tqdm(total=len(file_paths), desc=\"Procesando imágenes\") as pbar:\n",
        "            for dim in executor.map(process_image, file_paths):\n",
        "                if dim is not None:\n",
        "                    dimensions.append(dim)\n",
        "                pbar.update(1)\n",
        "    \n",
        "    try:\n",
        "        dim_array = cp.array(dimensions, dtype=cp.int32)\n",
        "        unique_dims, counts = np.unique(dim_array.get(), axis=0, return_counts=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error en el cálculo de dimensiones: {e}\")\n",
        "        return None, None, len(dimensions)\n",
        "    \n",
        "    return unique_dims, counts, len(dimensions)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unique_dims, counts, total_dims = analyze_plant_dimensions()\n",
        "    if unique_dims is not None and counts is not None:\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"Dimensiones de Imágenes ({PLANT_NAME} - {CATEGORY.upper()})\")\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"{'Dimensión':<15} {'Conteo':>10}\")\n",
        "        print(\"-\" * 27)\n",
        "        for dim, count in zip(unique_dims, counts):\n",
        "            print(f\"{f'{dim[0]}x{dim[1]}':<15} {count:>10}\")\n",
        "        print(f\"\\nTotal imágenes procesadas: {total_dims}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ***Tomato***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Procesando imágenes: 100%|██████████| 18160/18160 [00:03<00:00, 5530.09it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============================\n",
            "Dimensiones de Imágenes (Tomato - GRAYSCALE)\n",
            "==============================\n",
            "Dimensión           Conteo\n",
            "---------------------------\n",
            "256x256              18160\n",
            "\n",
            "Total imágenes procesadas: 18160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import cupy as cp\n",
        "import numpy as np\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ruta del dataset local\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "# Nombre de la planta a procesar\n",
        "PLANT_NAME = \"Tomato\"\n",
        "# Categoría a procesar\n",
        "CATEGORY = \"grayscale\"\n",
        "# Número de hilos para paralelización\n",
        "MAX_WORKERS = 16\n",
        "\n",
        "def collect_image_paths(directory):\n",
        "    file_paths = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        if PLANT_NAME in root:\n",
        "            for file in files:\n",
        "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    file_paths.append(os.path.join(root, file))\n",
        "    return file_paths\n",
        "\n",
        "def process_image(file_path):\n",
        "    try:\n",
        "        with Image.open(file_path) as img:\n",
        "            return (img.size[0], img.size[1])\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def analyze_plant_dimensions():\n",
        "    category_path = os.path.join(DATASET_PATH, CATEGORY, PLANT_NAME)\n",
        "    if not os.path.exists(category_path):\n",
        "        print(f\"Error: No se encontró la carpeta {category_path}.\")\n",
        "        return None, None, 0\n",
        "    \n",
        "    file_paths = collect_image_paths(category_path)\n",
        "    dimensions = []\n",
        "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "        # Usar tqdm para mostrar progreso\n",
        "        with tqdm(total=len(file_paths), desc=\"Procesando imágenes\") as pbar:\n",
        "            for dim in executor.map(process_image, file_paths):\n",
        "                if dim is not None:\n",
        "                    dimensions.append(dim)\n",
        "                pbar.update(1)\n",
        "    \n",
        "    try:\n",
        "        dim_array = cp.array(dimensions, dtype=cp.int32)\n",
        "        unique_dims, counts = np.unique(dim_array.get(), axis=0, return_counts=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error en el cálculo de dimensiones: {e}\")\n",
        "        return None, None, len(dimensions)\n",
        "    \n",
        "    return unique_dims, counts, len(dimensions)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unique_dims, counts, total_dims = analyze_plant_dimensions()\n",
        "    if unique_dims is not None and counts is not None:\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"Dimensiones de Imágenes ({PLANT_NAME} - {CATEGORY.upper()})\")\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"{'Dimensión':<15} {'Conteo':>10}\")\n",
        "        print(\"-\" * 27)\n",
        "        for dim, count in zip(unique_dims, counts):\n",
        "            print(f\"{f'{dim[0]}x{dim[1]}':<15} {count:>10}\")\n",
        "        print(f\"\\nTotal imágenes procesadas: {total_dims}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### ***Segmented***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ***Apple***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Procesando imágenes: 100%|██████████| 3171/3171 [00:00<00:00, 4925.75it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============================\n",
            "Dimensiones de Imágenes (Apple - SEGMENTED)\n",
            "==============================\n",
            "Dimensión           Conteo\n",
            "---------------------------\n",
            "256x256               3171\n",
            "\n",
            "Total imágenes procesadas: 3171\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import cupy as cp\n",
        "import numpy as np\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ruta del dataset local\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "# Nombre de la planta a procesar\n",
        "PLANT_NAME = \"Apple\"\n",
        "# Categoría a procesar\n",
        "CATEGORY = \"segmented\"\n",
        "# Número de hilos para paralelización\n",
        "MAX_WORKERS = 16\n",
        "\n",
        "def collect_image_paths(directory):\n",
        "    file_paths = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        if PLANT_NAME in root:\n",
        "            for file in files:\n",
        "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    file_paths.append(os.path.join(root, file))\n",
        "    return file_paths\n",
        "\n",
        "def process_image(file_path):\n",
        "    try:\n",
        "        with Image.open(file_path) as img:\n",
        "            return (img.size[0], img.size[1])\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def analyze_plant_dimensions():\n",
        "    category_path = os.path.join(DATASET_PATH, CATEGORY, PLANT_NAME)\n",
        "    if not os.path.exists(category_path):\n",
        "        print(f\"Error: No se encontró la carpeta {category_path}.\")\n",
        "        return None, None, 0\n",
        "    \n",
        "    file_paths = collect_image_paths(category_path)\n",
        "    dimensions = []\n",
        "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "        # Usar tqdm para mostrar progreso\n",
        "        with tqdm(total=len(file_paths), desc=\"Procesando imágenes\") as pbar:\n",
        "            for dim in executor.map(process_image, file_paths):\n",
        "                if dim is not None:\n",
        "                    dimensions.append(dim)\n",
        "                pbar.update(1)\n",
        "    \n",
        "    try:\n",
        "        dim_array = cp.array(dimensions, dtype=cp.int32)\n",
        "        unique_dims, counts = np.unique(dim_array.get(), axis=0, return_counts=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error en el cálculo de dimensiones: {e}\")\n",
        "        return None, None, len(dimensions)\n",
        "    \n",
        "    return unique_dims, counts, len(dimensions)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unique_dims, counts, total_dims = analyze_plant_dimensions()\n",
        "    if unique_dims is not None and counts is not None:\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"Dimensiones de Imágenes ({PLANT_NAME} - {CATEGORY.upper()})\")\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"{'Dimensión':<15} {'Conteo':>10}\")\n",
        "        print(\"-\" * 27)\n",
        "        for dim, count in zip(unique_dims, counts):\n",
        "            print(f\"{f'{dim[0]}x{dim[1]}':<15} {count:>10}\")\n",
        "        print(f\"\\nTotal imágenes procesadas: {total_dims}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ***Blueberry***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Procesando imágenes: 100%|██████████| 1502/1502 [00:00<00:00, 4747.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============================\n",
            "Dimensiones de Imágenes (Blueberry - SEGMENTED)\n",
            "==============================\n",
            "Dimensión           Conteo\n",
            "---------------------------\n",
            "256x256               1502\n",
            "\n",
            "Total imágenes procesadas: 1502\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import cupy as cp\n",
        "import numpy as np\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ruta del dataset local\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "# Nombre de la planta a procesar\n",
        "PLANT_NAME = \"Blueberry\"\n",
        "# Categoría a procesar\n",
        "CATEGORY = \"segmented\"\n",
        "# Número de hilos para paralelización\n",
        "MAX_WORKERS = 16\n",
        "\n",
        "def collect_image_paths(directory):\n",
        "    file_paths = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        if PLANT_NAME in root:\n",
        "            for file in files:\n",
        "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    file_paths.append(os.path.join(root, file))\n",
        "    return file_paths\n",
        "\n",
        "def process_image(file_path):\n",
        "    try:\n",
        "        with Image.open(file_path) as img:\n",
        "            return (img.size[0], img.size[1])\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def analyze_plant_dimensions():\n",
        "    category_path = os.path.join(DATASET_PATH, CATEGORY, PLANT_NAME)\n",
        "    if not os.path.exists(category_path):\n",
        "        print(f\"Error: No se encontró la carpeta {category_path}.\")\n",
        "        return None, None, 0\n",
        "    \n",
        "    file_paths = collect_image_paths(category_path)\n",
        "    dimensions = []\n",
        "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "        # Usar tqdm para mostrar progreso\n",
        "        with tqdm(total=len(file_paths), desc=\"Procesando imágenes\") as pbar:\n",
        "            for dim in executor.map(process_image, file_paths):\n",
        "                if dim is not None:\n",
        "                    dimensions.append(dim)\n",
        "                pbar.update(1)\n",
        "    \n",
        "    try:\n",
        "        dim_array = cp.array(dimensions, dtype=cp.int32)\n",
        "        unique_dims, counts = np.unique(dim_array.get(), axis=0, return_counts=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error en el cálculo de dimensiones: {e}\")\n",
        "        return None, None, len(dimensions)\n",
        "    \n",
        "    return unique_dims, counts, len(dimensions)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unique_dims, counts, total_dims = analyze_plant_dimensions()\n",
        "    if unique_dims is not None and counts is not None:\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"Dimensiones de Imágenes ({PLANT_NAME} - {CATEGORY.upper()})\")\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"{'Dimensión':<15} {'Conteo':>10}\")\n",
        "        print(\"-\" * 27)\n",
        "        for dim, count in zip(unique_dims, counts):\n",
        "            print(f\"{f'{dim[0]}x{dim[1]}':<15} {count:>10}\")\n",
        "        print(f\"\\nTotal imágenes procesadas: {total_dims}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ***Cherry***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Procesando imágenes: 100%|██████████| 1906/1906 [00:00<00:00, 5193.47it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============================\n",
            "Dimensiones de Imágenes (Cherry - SEGMENTED)\n",
            "==============================\n",
            "Dimensión           Conteo\n",
            "---------------------------\n",
            "256x256               1906\n",
            "\n",
            "Total imágenes procesadas: 1906\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import cupy as cp\n",
        "import numpy as np\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ruta del dataset local\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "# Nombre de la planta a procesar\n",
        "PLANT_NAME = \"Cherry\"\n",
        "# Categoría a procesar\n",
        "CATEGORY = \"segmented\"\n",
        "# Número de hilos para paralelización\n",
        "MAX_WORKERS = 16\n",
        "\n",
        "def collect_image_paths(directory):\n",
        "    file_paths = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        if PLANT_NAME in root:\n",
        "            for file in files:\n",
        "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    file_paths.append(os.path.join(root, file))\n",
        "    return file_paths\n",
        "\n",
        "def process_image(file_path):\n",
        "    try:\n",
        "        with Image.open(file_path) as img:\n",
        "            return (img.size[0], img.size[1])\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def analyze_plant_dimensions():\n",
        "    category_path = os.path.join(DATASET_PATH, CATEGORY, PLANT_NAME)\n",
        "    if not os.path.exists(category_path):\n",
        "        print(f\"Error: No se encontró la carpeta {category_path}.\")\n",
        "        return None, None, 0\n",
        "    \n",
        "    file_paths = collect_image_paths(category_path)\n",
        "    dimensions = []\n",
        "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "        # Usar tqdm para mostrar progreso\n",
        "        with tqdm(total=len(file_paths), desc=\"Procesando imágenes\") as pbar:\n",
        "            for dim in executor.map(process_image, file_paths):\n",
        "                if dim is not None:\n",
        "                    dimensions.append(dim)\n",
        "                pbar.update(1)\n",
        "    \n",
        "    try:\n",
        "        dim_array = cp.array(dimensions, dtype=cp.int32)\n",
        "        unique_dims, counts = np.unique(dim_array.get(), axis=0, return_counts=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error en el cálculo de dimensiones: {e}\")\n",
        "        return None, None, len(dimensions)\n",
        "    \n",
        "    return unique_dims, counts, len(dimensions)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unique_dims, counts, total_dims = analyze_plant_dimensions()\n",
        "    if unique_dims is not None and counts is not None:\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"Dimensiones de Imágenes ({PLANT_NAME} - {CATEGORY.upper()})\")\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"{'Dimensión':<15} {'Conteo':>10}\")\n",
        "        print(\"-\" * 27)\n",
        "        for dim, count in zip(unique_dims, counts):\n",
        "            print(f\"{f'{dim[0]}x{dim[1]}':<15} {count:>10}\")\n",
        "        print(f\"\\nTotal imágenes procesadas: {total_dims}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ***Corn***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Procesando imágenes: 100%|██████████| 3852/3852 [00:01<00:00, 3468.22it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============================\n",
            "Dimensiones de Imágenes (Corn - SEGMENTED)\n",
            "==============================\n",
            "Dimensión           Conteo\n",
            "---------------------------\n",
            "256x256               3852\n",
            "\n",
            "Total imágenes procesadas: 3852\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import cupy as cp\n",
        "import numpy as np\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ruta del dataset local\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "# Nombre de la planta a procesar\n",
        "PLANT_NAME = \"Corn\"\n",
        "# Categoría a procesar\n",
        "CATEGORY = \"segmented\"\n",
        "# Número de hilos para paralelización\n",
        "MAX_WORKERS = 16\n",
        "\n",
        "def collect_image_paths(directory):\n",
        "    file_paths = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        if PLANT_NAME in root:\n",
        "            for file in files:\n",
        "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    file_paths.append(os.path.join(root, file))\n",
        "    return file_paths\n",
        "\n",
        "def process_image(file_path):\n",
        "    try:\n",
        "        with Image.open(file_path) as img:\n",
        "            return (img.size[0], img.size[1])\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def analyze_plant_dimensions():\n",
        "    category_path = os.path.join(DATASET_PATH, CATEGORY, PLANT_NAME)\n",
        "    if not os.path.exists(category_path):\n",
        "        print(f\"Error: No se encontró la carpeta {category_path}.\")\n",
        "        return None, None, 0\n",
        "    \n",
        "    file_paths = collect_image_paths(category_path)\n",
        "    dimensions = []\n",
        "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "        # Usar tqdm para mostrar progreso\n",
        "        with tqdm(total=len(file_paths), desc=\"Procesando imágenes\") as pbar:\n",
        "            for dim in executor.map(process_image, file_paths):\n",
        "                if dim is not None:\n",
        "                    dimensions.append(dim)\n",
        "                pbar.update(1)\n",
        "    \n",
        "    try:\n",
        "        dim_array = cp.array(dimensions, dtype=cp.int32)\n",
        "        unique_dims, counts = np.unique(dim_array.get(), axis=0, return_counts=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error en el cálculo de dimensiones: {e}\")\n",
        "        return None, None, len(dimensions)\n",
        "    \n",
        "    return unique_dims, counts, len(dimensions)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unique_dims, counts, total_dims = analyze_plant_dimensions()\n",
        "    if unique_dims is not None and counts is not None:\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"Dimensiones de Imágenes ({PLANT_NAME} - {CATEGORY.upper()})\")\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"{'Dimensión':<15} {'Conteo':>10}\")\n",
        "        print(\"-\" * 27)\n",
        "        for dim, count in zip(unique_dims, counts):\n",
        "            print(f\"{f'{dim[0]}x{dim[1]}':<15} {count:>10}\")\n",
        "        print(f\"\\nTotal imágenes procesadas: {total_dims}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ***Grape***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Procesando imágenes: 100%|██████████| 4063/4063 [00:00<00:00, 4969.45it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============================\n",
            "Dimensiones de Imágenes (Grape - SEGMENTED)\n",
            "==============================\n",
            "Dimensión           Conteo\n",
            "---------------------------\n",
            "256x256               4063\n",
            "\n",
            "Total imágenes procesadas: 4063\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import cupy as cp\n",
        "import numpy as np\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ruta del dataset local\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "# Nombre de la planta a procesar\n",
        "PLANT_NAME = \"Grape\"\n",
        "# Categoría a procesar\n",
        "CATEGORY = \"segmented\"\n",
        "# Número de hilos para paralelización\n",
        "MAX_WORKERS = 16\n",
        "\n",
        "def collect_image_paths(directory):\n",
        "    file_paths = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        if PLANT_NAME in root:\n",
        "            for file in files:\n",
        "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    file_paths.append(os.path.join(root, file))\n",
        "    return file_paths\n",
        "\n",
        "def process_image(file_path):\n",
        "    try:\n",
        "        with Image.open(file_path) as img:\n",
        "            return (img.size[0], img.size[1])\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def analyze_plant_dimensions():\n",
        "    category_path = os.path.join(DATASET_PATH, CATEGORY, PLANT_NAME)\n",
        "    if not os.path.exists(category_path):\n",
        "        print(f\"Error: No se encontró la carpeta {category_path}.\")\n",
        "        return None, None, 0\n",
        "    \n",
        "    file_paths = collect_image_paths(category_path)\n",
        "    dimensions = []\n",
        "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "        # Usar tqdm para mostrar progreso\n",
        "        with tqdm(total=len(file_paths), desc=\"Procesando imágenes\") as pbar:\n",
        "            for dim in executor.map(process_image, file_paths):\n",
        "                if dim is not None:\n",
        "                    dimensions.append(dim)\n",
        "                pbar.update(1)\n",
        "    \n",
        "    try:\n",
        "        dim_array = cp.array(dimensions, dtype=cp.int32)\n",
        "        unique_dims, counts = np.unique(dim_array.get(), axis=0, return_counts=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error en el cálculo de dimensiones: {e}\")\n",
        "        return None, None, len(dimensions)\n",
        "    \n",
        "    return unique_dims, counts, len(dimensions)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unique_dims, counts, total_dims = analyze_plant_dimensions()\n",
        "    if unique_dims is not None and counts is not None:\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"Dimensiones de Imágenes ({PLANT_NAME} - {CATEGORY.upper()})\")\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"{'Dimensión':<15} {'Conteo':>10}\")\n",
        "        print(\"-\" * 27)\n",
        "        for dim, count in zip(unique_dims, counts):\n",
        "            print(f\"{f'{dim[0]}x{dim[1]}':<15} {count:>10}\")\n",
        "        print(f\"\\nTotal imágenes procesadas: {total_dims}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ***Orange***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Procesando imágenes: 100%|██████████| 5507/5507 [00:01<00:00, 5067.89it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============================\n",
            "Dimensiones de Imágenes (Orange - SEGMENTED)\n",
            "==============================\n",
            "Dimensión           Conteo\n",
            "---------------------------\n",
            "256x256               5507\n",
            "\n",
            "Total imágenes procesadas: 5507\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import cupy as cp\n",
        "import numpy as np\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ruta del dataset local\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "# Nombre de la planta a procesar\n",
        "PLANT_NAME = \"Orange\"\n",
        "# Categoría a procesar\n",
        "CATEGORY = \"segmented\"\n",
        "# Número de hilos para paralelización\n",
        "MAX_WORKERS = 16\n",
        "\n",
        "def collect_image_paths(directory):\n",
        "    file_paths = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        if PLANT_NAME in root:\n",
        "            for file in files:\n",
        "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    file_paths.append(os.path.join(root, file))\n",
        "    return file_paths\n",
        "\n",
        "def process_image(file_path):\n",
        "    try:\n",
        "        with Image.open(file_path) as img:\n",
        "            return (img.size[0], img.size[1])\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def analyze_plant_dimensions():\n",
        "    category_path = os.path.join(DATASET_PATH, CATEGORY, PLANT_NAME)\n",
        "    if not os.path.exists(category_path):\n",
        "        print(f\"Error: No se encontró la carpeta {category_path}.\")\n",
        "        return None, None, 0\n",
        "    \n",
        "    file_paths = collect_image_paths(category_path)\n",
        "    dimensions = []\n",
        "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "        # Usar tqdm para mostrar progreso\n",
        "        with tqdm(total=len(file_paths), desc=\"Procesando imágenes\") as pbar:\n",
        "            for dim in executor.map(process_image, file_paths):\n",
        "                if dim is not None:\n",
        "                    dimensions.append(dim)\n",
        "                pbar.update(1)\n",
        "    \n",
        "    try:\n",
        "        dim_array = cp.array(dimensions, dtype=cp.int32)\n",
        "        unique_dims, counts = np.unique(dim_array.get(), axis=0, return_counts=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error en el cálculo de dimensiones: {e}\")\n",
        "        return None, None, len(dimensions)\n",
        "    \n",
        "    return unique_dims, counts, len(dimensions)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unique_dims, counts, total_dims = analyze_plant_dimensions()\n",
        "    if unique_dims is not None and counts is not None:\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"Dimensiones de Imágenes ({PLANT_NAME} - {CATEGORY.upper()})\")\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"{'Dimensión':<15} {'Conteo':>10}\")\n",
        "        print(\"-\" * 27)\n",
        "        for dim, count in zip(unique_dims, counts):\n",
        "            print(f\"{f'{dim[0]}x{dim[1]}':<15} {count:>10}\")\n",
        "        print(f\"\\nTotal imágenes procesadas: {total_dims}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ***Peach***\n",
        "(Otras dimensiones aparte de: 256x 256)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Procesando imágenes: 100%|██████████| 2657/2657 [00:00<00:00, 5261.41it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============================\n",
            "Dimensiones de Imágenes (Peach - SEGMENTED)\n",
            "==============================\n",
            "Dimensión           Conteo\n",
            "---------------------------\n",
            "256x256               2655\n",
            "324x512                  1\n",
            "466x512                  1\n",
            "\n",
            "Total imágenes procesadas: 2657\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import cupy as cp\n",
        "import numpy as np\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ruta del dataset local\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "# Nombre de la planta a procesar\n",
        "PLANT_NAME = \"Peach\"\n",
        "# Categoría a procesar\n",
        "CATEGORY = \"segmented\"\n",
        "# Número de hilos para paralelización\n",
        "MAX_WORKERS = 16\n",
        "\n",
        "def collect_image_paths(directory):\n",
        "    file_paths = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        if PLANT_NAME in root:\n",
        "            for file in files:\n",
        "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    file_paths.append(os.path.join(root, file))\n",
        "    return file_paths\n",
        "\n",
        "def process_image(file_path):\n",
        "    try:\n",
        "        with Image.open(file_path) as img:\n",
        "            return (img.size[0], img.size[1])\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def analyze_plant_dimensions():\n",
        "    category_path = os.path.join(DATASET_PATH, CATEGORY, PLANT_NAME)\n",
        "    if not os.path.exists(category_path):\n",
        "        print(f\"Error: No se encontró la carpeta {category_path}.\")\n",
        "        return None, None, 0\n",
        "    \n",
        "    file_paths = collect_image_paths(category_path)\n",
        "    dimensions = []\n",
        "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "        # Usar tqdm para mostrar progreso\n",
        "        with tqdm(total=len(file_paths), desc=\"Procesando imágenes\") as pbar:\n",
        "            for dim in executor.map(process_image, file_paths):\n",
        "                if dim is not None:\n",
        "                    dimensions.append(dim)\n",
        "                pbar.update(1)\n",
        "    \n",
        "    try:\n",
        "        dim_array = cp.array(dimensions, dtype=cp.int32)\n",
        "        unique_dims, counts = np.unique(dim_array.get(), axis=0, return_counts=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error en el cálculo de dimensiones: {e}\")\n",
        "        return None, None, len(dimensions)\n",
        "    \n",
        "    return unique_dims, counts, len(dimensions)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unique_dims, counts, total_dims = analyze_plant_dimensions()\n",
        "    if unique_dims is not None and counts is not None:\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"Dimensiones de Imágenes ({PLANT_NAME} - {CATEGORY.upper()})\")\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"{'Dimensión':<15} {'Conteo':>10}\")\n",
        "        print(\"-\" * 27)\n",
        "        for dim, count in zip(unique_dims, counts):\n",
        "            print(f\"{f'{dim[0]}x{dim[1]}':<15} {count:>10}\")\n",
        "        print(f\"\\nTotal imágenes procesadas: {total_dims}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ***Pepper***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Procesando imágenes: 100%|██████████| 2475/2475 [00:00<00:00, 5333.59it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============================\n",
            "Dimensiones de Imágenes (Pepper - SEGMENTED)\n",
            "==============================\n",
            "Dimensión           Conteo\n",
            "---------------------------\n",
            "256x256               2475\n",
            "\n",
            "Total imágenes procesadas: 2475\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import cupy as cp\n",
        "import numpy as np\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ruta del dataset local\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "# Nombre de la planta a procesar\n",
        "PLANT_NAME = \"Pepper\"\n",
        "# Categoría a procesar\n",
        "CATEGORY = \"segmented\"\n",
        "# Número de hilos para paralelización\n",
        "MAX_WORKERS = 16\n",
        "\n",
        "def collect_image_paths(directory):\n",
        "    file_paths = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        if PLANT_NAME in root:\n",
        "            for file in files:\n",
        "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    file_paths.append(os.path.join(root, file))\n",
        "    return file_paths\n",
        "\n",
        "def process_image(file_path):\n",
        "    try:\n",
        "        with Image.open(file_path) as img:\n",
        "            return (img.size[0], img.size[1])\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def analyze_plant_dimensions():\n",
        "    category_path = os.path.join(DATASET_PATH, CATEGORY, PLANT_NAME)\n",
        "    if not os.path.exists(category_path):\n",
        "        print(f\"Error: No se encontró la carpeta {category_path}.\")\n",
        "        return None, None, 0\n",
        "    \n",
        "    file_paths = collect_image_paths(category_path)\n",
        "    dimensions = []\n",
        "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "        # Usar tqdm para mostrar progreso\n",
        "        with tqdm(total=len(file_paths), desc=\"Procesando imágenes\") as pbar:\n",
        "            for dim in executor.map(process_image, file_paths):\n",
        "                if dim is not None:\n",
        "                    dimensions.append(dim)\n",
        "                pbar.update(1)\n",
        "    \n",
        "    try:\n",
        "        dim_array = cp.array(dimensions, dtype=cp.int32)\n",
        "        unique_dims, counts = np.unique(dim_array.get(), axis=0, return_counts=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error en el cálculo de dimensiones: {e}\")\n",
        "        return None, None, len(dimensions)\n",
        "    \n",
        "    return unique_dims, counts, len(dimensions)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unique_dims, counts, total_dims = analyze_plant_dimensions()\n",
        "    if unique_dims is not None and counts is not None:\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"Dimensiones de Imágenes ({PLANT_NAME} - {CATEGORY.upper()})\")\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"{'Dimensión':<15} {'Conteo':>10}\")\n",
        "        print(\"-\" * 27)\n",
        "        for dim, count in zip(unique_dims, counts):\n",
        "            print(f\"{f'{dim[0]}x{dim[1]}':<15} {count:>10}\")\n",
        "        print(f\"\\nTotal imágenes procesadas: {total_dims}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ***Potato***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Procesando imágenes: 100%|██████████| 2152/2152 [00:00<00:00, 5096.48it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============================\n",
            "Dimensiones de Imágenes (Potato - SEGMENTED)\n",
            "==============================\n",
            "Dimensión           Conteo\n",
            "---------------------------\n",
            "256x256               2152\n",
            "\n",
            "Total imágenes procesadas: 2152\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import cupy as cp\n",
        "import numpy as np\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ruta del dataset local\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "# Nombre de la planta a procesar\n",
        "PLANT_NAME = \"Potato\"\n",
        "# Categoría a procesar\n",
        "CATEGORY = \"segmented\"\n",
        "# Número de hilos para paralelización\n",
        "MAX_WORKERS = 16\n",
        "\n",
        "def collect_image_paths(directory):\n",
        "    file_paths = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        if PLANT_NAME in root:\n",
        "            for file in files:\n",
        "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    file_paths.append(os.path.join(root, file))\n",
        "    return file_paths\n",
        "\n",
        "def process_image(file_path):\n",
        "    try:\n",
        "        with Image.open(file_path) as img:\n",
        "            return (img.size[0], img.size[1])\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def analyze_plant_dimensions():\n",
        "    category_path = os.path.join(DATASET_PATH, CATEGORY, PLANT_NAME)\n",
        "    if not os.path.exists(category_path):\n",
        "        print(f\"Error: No se encontró la carpeta {category_path}.\")\n",
        "        return None, None, 0\n",
        "    \n",
        "    file_paths = collect_image_paths(category_path)\n",
        "    dimensions = []\n",
        "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "        # Usar tqdm para mostrar progreso\n",
        "        with tqdm(total=len(file_paths), desc=\"Procesando imágenes\") as pbar:\n",
        "            for dim in executor.map(process_image, file_paths):\n",
        "                if dim is not None:\n",
        "                    dimensions.append(dim)\n",
        "                pbar.update(1)\n",
        "    \n",
        "    try:\n",
        "        dim_array = cp.array(dimensions, dtype=cp.int32)\n",
        "        unique_dims, counts = np.unique(dim_array.get(), axis=0, return_counts=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error en el cálculo de dimensiones: {e}\")\n",
        "        return None, None, len(dimensions)\n",
        "    \n",
        "    return unique_dims, counts, len(dimensions)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unique_dims, counts, total_dims = analyze_plant_dimensions()\n",
        "    if unique_dims is not None and counts is not None:\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"Dimensiones de Imágenes ({PLANT_NAME} - {CATEGORY.upper()})\")\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"{'Dimensión':<15} {'Conteo':>10}\")\n",
        "        print(\"-\" * 27)\n",
        "        for dim, count in zip(unique_dims, counts):\n",
        "            print(f\"{f'{dim[0]}x{dim[1]}':<15} {count:>10}\")\n",
        "        print(f\"\\nTotal imágenes procesadas: {total_dims}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ***Raspberry***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Procesando imágenes: 100%|██████████| 371/371 [00:00<00:00, 4685.99it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============================\n",
            "Dimensiones de Imágenes (Raspberry - SEGMENTED)\n",
            "==============================\n",
            "Dimensión           Conteo\n",
            "---------------------------\n",
            "256x256                371\n",
            "\n",
            "Total imágenes procesadas: 371\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import cupy as cp\n",
        "import numpy as np\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ruta del dataset local\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "# Nombre de la planta a procesar\n",
        "PLANT_NAME = \"Raspberry\"\n",
        "# Categoría a procesar\n",
        "CATEGORY = \"segmented\"\n",
        "# Número de hilos para paralelización\n",
        "MAX_WORKERS = 16\n",
        "\n",
        "def collect_image_paths(directory):\n",
        "    file_paths = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        if PLANT_NAME in root:\n",
        "            for file in files:\n",
        "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    file_paths.append(os.path.join(root, file))\n",
        "    return file_paths\n",
        "\n",
        "def process_image(file_path):\n",
        "    try:\n",
        "        with Image.open(file_path) as img:\n",
        "            return (img.size[0], img.size[1])\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def analyze_plant_dimensions():\n",
        "    category_path = os.path.join(DATASET_PATH, CATEGORY, PLANT_NAME)\n",
        "    if not os.path.exists(category_path):\n",
        "        print(f\"Error: No se encontró la carpeta {category_path}.\")\n",
        "        return None, None, 0\n",
        "    \n",
        "    file_paths = collect_image_paths(category_path)\n",
        "    dimensions = []\n",
        "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "        # Usar tqdm para mostrar progreso\n",
        "        with tqdm(total=len(file_paths), desc=\"Procesando imágenes\") as pbar:\n",
        "            for dim in executor.map(process_image, file_paths):\n",
        "                if dim is not None:\n",
        "                    dimensions.append(dim)\n",
        "                pbar.update(1)\n",
        "    \n",
        "    try:\n",
        "        dim_array = cp.array(dimensions, dtype=cp.int32)\n",
        "        unique_dims, counts = np.unique(dim_array.get(), axis=0, return_counts=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error en el cálculo de dimensiones: {e}\")\n",
        "        return None, None, len(dimensions)\n",
        "    \n",
        "    return unique_dims, counts, len(dimensions)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unique_dims, counts, total_dims = analyze_plant_dimensions()\n",
        "    if unique_dims is not None and counts is not None:\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"Dimensiones de Imágenes ({PLANT_NAME} - {CATEGORY.upper()})\")\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"{'Dimensión':<15} {'Conteo':>10}\")\n",
        "        print(\"-\" * 27)\n",
        "        for dim, count in zip(unique_dims, counts):\n",
        "            print(f\"{f'{dim[0]}x{dim[1]}':<15} {count:>10}\")\n",
        "        print(f\"\\nTotal imágenes procesadas: {total_dims}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ***Soybean***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Procesando imágenes: 100%|██████████| 5090/5090 [00:00<00:00, 5365.50it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============================\n",
            "Dimensiones de Imágenes (Soybean - SEGMENTED)\n",
            "==============================\n",
            "Dimensión           Conteo\n",
            "---------------------------\n",
            "256x256               5090\n",
            "\n",
            "Total imágenes procesadas: 5090\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import cupy as cp\n",
        "import numpy as np\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ruta del dataset local\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "# Nombre de la planta a procesar\n",
        "PLANT_NAME = \"Soybean\"\n",
        "# Categoría a procesar\n",
        "CATEGORY = \"segmented\"\n",
        "# Número de hilos para paralelización\n",
        "MAX_WORKERS = 16\n",
        "\n",
        "def collect_image_paths(directory):\n",
        "    file_paths = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        if PLANT_NAME in root:\n",
        "            for file in files:\n",
        "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    file_paths.append(os.path.join(root, file))\n",
        "    return file_paths\n",
        "\n",
        "def process_image(file_path):\n",
        "    try:\n",
        "        with Image.open(file_path) as img:\n",
        "            return (img.size[0], img.size[1])\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def analyze_plant_dimensions():\n",
        "    category_path = os.path.join(DATASET_PATH, CATEGORY, PLANT_NAME)\n",
        "    if not os.path.exists(category_path):\n",
        "        print(f\"Error: No se encontró la carpeta {category_path}.\")\n",
        "        return None, None, 0\n",
        "    \n",
        "    file_paths = collect_image_paths(category_path)\n",
        "    dimensions = []\n",
        "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "        # Usar tqdm para mostrar progreso\n",
        "        with tqdm(total=len(file_paths), desc=\"Procesando imágenes\") as pbar:\n",
        "            for dim in executor.map(process_image, file_paths):\n",
        "                if dim is not None:\n",
        "                    dimensions.append(dim)\n",
        "                pbar.update(1)\n",
        "    \n",
        "    try:\n",
        "        dim_array = cp.array(dimensions, dtype=cp.int32)\n",
        "        unique_dims, counts = np.unique(dim_array.get(), axis=0, return_counts=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error en el cálculo de dimensiones: {e}\")\n",
        "        return None, None, len(dimensions)\n",
        "    \n",
        "    return unique_dims, counts, len(dimensions)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unique_dims, counts, total_dims = analyze_plant_dimensions()\n",
        "    if unique_dims is not None and counts is not None:\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"Dimensiones de Imágenes ({PLANT_NAME} - {CATEGORY.upper()})\")\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"{'Dimensión':<15} {'Conteo':>10}\")\n",
        "        print(\"-\" * 27)\n",
        "        for dim, count in zip(unique_dims, counts):\n",
        "            print(f\"{f'{dim[0]}x{dim[1]}':<15} {count:>10}\")\n",
        "        print(f\"\\nTotal imágenes procesadas: {total_dims}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ***Squash***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Procesando imágenes: 100%|██████████| 1835/1835 [00:00<00:00, 4558.84it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============================\n",
            "Dimensiones de Imágenes (Squash - SEGMENTED)\n",
            "==============================\n",
            "Dimensión           Conteo\n",
            "---------------------------\n",
            "256x256               1835\n",
            "\n",
            "Total imágenes procesadas: 1835\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import cupy as cp\n",
        "import numpy as np\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ruta del dataset local\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "# Nombre de la planta a procesar\n",
        "PLANT_NAME = \"Squash\"\n",
        "# Categoría a procesar\n",
        "CATEGORY = \"segmented\"\n",
        "# Número de hilos para paralelización\n",
        "MAX_WORKERS = 16\n",
        "\n",
        "def collect_image_paths(directory):\n",
        "    file_paths = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        if PLANT_NAME in root:\n",
        "            for file in files:\n",
        "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    file_paths.append(os.path.join(root, file))\n",
        "    return file_paths\n",
        "\n",
        "def process_image(file_path):\n",
        "    try:\n",
        "        with Image.open(file_path) as img:\n",
        "            return (img.size[0], img.size[1])\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def analyze_plant_dimensions():\n",
        "    category_path = os.path.join(DATASET_PATH, CATEGORY, PLANT_NAME)\n",
        "    if not os.path.exists(category_path):\n",
        "        print(f\"Error: No se encontró la carpeta {category_path}.\")\n",
        "        return None, None, 0\n",
        "    \n",
        "    file_paths = collect_image_paths(category_path)\n",
        "    dimensions = []\n",
        "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "        # Usar tqdm para mostrar progreso\n",
        "        with tqdm(total=len(file_paths), desc=\"Procesando imágenes\") as pbar:\n",
        "            for dim in executor.map(process_image, file_paths):\n",
        "                if dim is not None:\n",
        "                    dimensions.append(dim)\n",
        "                pbar.update(1)\n",
        "    \n",
        "    try:\n",
        "        dim_array = cp.array(dimensions, dtype=cp.int32)\n",
        "        unique_dims, counts = np.unique(dim_array.get(), axis=0, return_counts=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error en el cálculo de dimensiones: {e}\")\n",
        "        return None, None, len(dimensions)\n",
        "    \n",
        "    return unique_dims, counts, len(dimensions)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unique_dims, counts, total_dims = analyze_plant_dimensions()\n",
        "    if unique_dims is not None and counts is not None:\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"Dimensiones de Imágenes ({PLANT_NAME} - {CATEGORY.upper()})\")\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"{'Dimensión':<15} {'Conteo':>10}\")\n",
        "        print(\"-\" * 27)\n",
        "        for dim, count in zip(unique_dims, counts):\n",
        "            print(f\"{f'{dim[0]}x{dim[1]}':<15} {count:>10}\")\n",
        "        print(f\"\\nTotal imágenes procesadas: {total_dims}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ***Strawberry***\n",
        "(Otras dimensiones aparte de: 256x 256)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Procesando imágenes: 100%|██████████| 1565/1565 [00:00<00:00, 5115.83it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============================\n",
            "Dimensiones de Imágenes (Strawberry - SEGMENTED)\n",
            "==============================\n",
            "Dimensión           Conteo\n",
            "---------------------------\n",
            "256x256               1564\n",
            "470x512                  1\n",
            "\n",
            "Total imágenes procesadas: 1565\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import cupy as cp\n",
        "import numpy as np\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ruta del dataset local\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "# Nombre de la planta a procesar\n",
        "PLANT_NAME = \"Strawberry\"\n",
        "# Categoría a procesar\n",
        "CATEGORY = \"segmented\"\n",
        "# Número de hilos para paralelización\n",
        "MAX_WORKERS = 16\n",
        "\n",
        "def collect_image_paths(directory):\n",
        "    file_paths = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        if PLANT_NAME in root:\n",
        "            for file in files:\n",
        "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    file_paths.append(os.path.join(root, file))\n",
        "    return file_paths\n",
        "\n",
        "def process_image(file_path):\n",
        "    try:\n",
        "        with Image.open(file_path) as img:\n",
        "            return (img.size[0], img.size[1])\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def analyze_plant_dimensions():\n",
        "    category_path = os.path.join(DATASET_PATH, CATEGORY, PLANT_NAME)\n",
        "    if not os.path.exists(category_path):\n",
        "        print(f\"Error: No se encontró la carpeta {category_path}.\")\n",
        "        return None, None, 0\n",
        "    \n",
        "    file_paths = collect_image_paths(category_path)\n",
        "    dimensions = []\n",
        "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "        # Usar tqdm para mostrar progreso\n",
        "        with tqdm(total=len(file_paths), desc=\"Procesando imágenes\") as pbar:\n",
        "            for dim in executor.map(process_image, file_paths):\n",
        "                if dim is not None:\n",
        "                    dimensions.append(dim)\n",
        "                pbar.update(1)\n",
        "    \n",
        "    try:\n",
        "        dim_array = cp.array(dimensions, dtype=cp.int32)\n",
        "        unique_dims, counts = np.unique(dim_array.get(), axis=0, return_counts=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error en el cálculo de dimensiones: {e}\")\n",
        "        return None, None, len(dimensions)\n",
        "    \n",
        "    return unique_dims, counts, len(dimensions)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unique_dims, counts, total_dims = analyze_plant_dimensions()\n",
        "    if unique_dims is not None and counts is not None:\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"Dimensiones de Imágenes ({PLANT_NAME} - {CATEGORY.upper()})\")\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"{'Dimensión':<15} {'Conteo':>10}\")\n",
        "        print(\"-\" * 27)\n",
        "        for dim, count in zip(unique_dims, counts):\n",
        "            print(f\"{f'{dim[0]}x{dim[1]}':<15} {count:>10}\")\n",
        "        print(f\"\\nTotal imágenes procesadas: {total_dims}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ***Tomato***\n",
        "(Otras dimensiones aparte de: 256x 256)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Procesando imágenes: 100%|██████████| 18160/18160 [00:03<00:00, 5134.67it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============================\n",
            "Dimensiones de Imágenes (Tomato - SEGMENTED)\n",
            "==============================\n",
            "Dimensión           Conteo\n",
            "---------------------------\n",
            "256x256              18159\n",
            "335x512                  1\n",
            "\n",
            "Total imágenes procesadas: 18160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import cupy as cp\n",
        "import numpy as np\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ruta del dataset local\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "# Nombre de la planta a procesar\n",
        "PLANT_NAME = \"Tomato\"\n",
        "# Categoría a procesar\n",
        "CATEGORY = \"segmented\"\n",
        "# Número de hilos para paralelización\n",
        "MAX_WORKERS = 16\n",
        "\n",
        "def collect_image_paths(directory):\n",
        "    file_paths = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        if PLANT_NAME in root:\n",
        "            for file in files:\n",
        "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    file_paths.append(os.path.join(root, file))\n",
        "    return file_paths\n",
        "\n",
        "def process_image(file_path):\n",
        "    try:\n",
        "        with Image.open(file_path) as img:\n",
        "            return (img.size[0], img.size[1])\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def analyze_plant_dimensions():\n",
        "    category_path = os.path.join(DATASET_PATH, CATEGORY, PLANT_NAME)\n",
        "    if not os.path.exists(category_path):\n",
        "        print(f\"Error: No se encontró la carpeta {category_path}.\")\n",
        "        return None, None, 0\n",
        "    \n",
        "    file_paths = collect_image_paths(category_path)\n",
        "    dimensions = []\n",
        "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "        # Usar tqdm para mostrar progreso\n",
        "        with tqdm(total=len(file_paths), desc=\"Procesando imágenes\") as pbar:\n",
        "            for dim in executor.map(process_image, file_paths):\n",
        "                if dim is not None:\n",
        "                    dimensions.append(dim)\n",
        "                pbar.update(1)\n",
        "    \n",
        "    try:\n",
        "        dim_array = cp.array(dimensions, dtype=cp.int32)\n",
        "        unique_dims, counts = np.unique(dim_array.get(), axis=0, return_counts=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error en el cálculo de dimensiones: {e}\")\n",
        "        return None, None, len(dimensions)\n",
        "    \n",
        "    return unique_dims, counts, len(dimensions)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unique_dims, counts, total_dims = analyze_plant_dimensions()\n",
        "    if unique_dims is not None and counts is not None:\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"Dimensiones de Imágenes ({PLANT_NAME} - {CATEGORY.upper()})\")\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"{'Dimensión':<15} {'Conteo':>10}\")\n",
        "        print(\"-\" * 27)\n",
        "        for dim, count in zip(unique_dims, counts):\n",
        "            print(f\"{f'{dim[0]}x{dim[1]}':<15} {count:>10}\")\n",
        "        print(f\"\\nTotal imágenes procesadas: {total_dims}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GinG_RKWsu7i"
      },
      "source": [
        "### ***Detección de imágenes corruptas o vacías***\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADSdPZmkvFkX"
      },
      "source": [
        "Se realizará una revisión del dataset para identificar imágenes corruptas o vacías, con el objetivo de determinar si es necesario eliminarlas o corregirlas antes de continuar con el preprocesamiento y entrenamiento del modelo. Esta validación es fundamental para garantizar la calidad y consistencia de los datos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jKQC_HICs7uJ",
        "outputId": "d47c7f98-4541-4acc-c944-ad6239d765db"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Recolectando imágenes: 160it [00:00, 332.28it/s]\n",
            "Verificando imágenes: 100%|██████████| 162916/162916 [01:04<00:00, 2527.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "====================\n",
            "Total imágenes: 162916\n",
            "Imágenes corruptas: 0\n",
            "✅ No se encontraron imágenes corruptas.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Configuración\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "MAX_WORKERS = 16\n",
        "\n",
        "def collect_image_paths(input_dir):\n",
        "    \"\"\"Recolecta rutas de imágenes .jpg, .jpeg y .png con barra de progreso.\"\"\"\n",
        "    file_paths = []\n",
        "    for root, _, files in tqdm(os.walk(input_dir), desc=\"Recolectando imágenes\"):\n",
        "        for file in files:\n",
        "            if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                file_paths.append(os.path.join(root, file))\n",
        "    return file_paths\n",
        "\n",
        "def check_image(file_path):\n",
        "    \"\"\"Verifica si una imagen es válida o está corrupta.\"\"\"\n",
        "    try:\n",
        "        if os.path.getsize(file_path) == 0:\n",
        "            return file_path, \"Archivo vacío (0 bytes)\"\n",
        "        with Image.open(file_path) as img:\n",
        "            img.verify()\n",
        "            img = Image.open(file_path)\n",
        "            img.load()\n",
        "            if img.size[0] == 0 or img.size[1] == 0:\n",
        "                return file_path, \"Dimensiones inválidas\"\n",
        "        return file_path, None\n",
        "    except Exception as e:\n",
        "        return file_path, f\"Error: {str(e)}\"\n",
        "\n",
        "def check_dataset(input_dir, max_workers=MAX_WORKERS):\n",
        "    \"\"\"Verifica imágenes en paralelo y genera informe.\"\"\"\n",
        "    file_paths = collect_image_paths(input_dir)\n",
        "    corrupted_images = []\n",
        "\n",
        "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
        "        future_to_file = {executor.submit(check_image, path): path for path in file_paths}\n",
        "        for future in tqdm(as_completed(future_to_file), total=len(file_paths), desc=\"Verificando imágenes\"):\n",
        "            file_path, error = future.result()\n",
        "            if error:\n",
        "                corrupted_images.append((file_path, error))\n",
        "\n",
        "    # Resumen\n",
        "    print(f\"\\n{'=' * 20}\")\n",
        "    print(f\"Total imágenes: {len(file_paths)}\")\n",
        "    print(f\"Imágenes corruptas: {len(corrupted_images)}\")\n",
        "    if corrupted_images:\n",
        "        print(\"\\nImágenes con problemas:\")\n",
        "        for file_path, error in corrupted_images:\n",
        "            print(f\"  {file_path}: {error}\")\n",
        "        output_file = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\corrupted_images.txt\"\n",
        "        with open(output_file, 'w') as f:\n",
        "            for file_path, _ in corrupted_images:\n",
        "                f.write(f\"{file_path}\\n\")\n",
        "        print(f\"\\nLista de imágenes corruptas guardada en: {output_file}\")\n",
        "    else:\n",
        "        print(\"✅ No se encontraron imágenes corruptas.\")\n",
        "\n",
        "    return corrupted_images\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    check_dataset(DATASET_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLmw-dlbwf4u"
      },
      "source": [
        "### ***Buscar balanceo entre clases***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se analizará la distribución de imágenes entre las distintas clases —o en este caso, entre los diferentes estados de salud de las plantas— con el objetivo de verificar si existe un balance adecuado.\n",
        "Este análisis permitirá identificar posibles desbalances que, en etapas posteriores, podrían requerir técnicas de reajuste de cantidades o asignación de pesos por clase durante el entrenamiento del modelo, para evitar sesgos y mejorar el rendimiento general."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "***Conclusión del análisis***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tras el análisis realizado, se llegó a las siguientes conclusiones:\n",
        "\n",
        "Balance entre clases:\n",
        "Se observó un desbalance significativo en la cantidad de imágenes entre distintas clases (estados de salud de las plantas). Esto indica que será necesario aplicar técnicas de balanceo, ya sea ajustando la cantidad de muestras por clase o utilizando pesos diferenciados durante el entrenamiento del modelo. Esta medida es crucial para evitar sesgos que afecten negativamente la capacidad de generalización del modelo, especialmente al emplear arquitecturas como ResNet.\n",
        "\n",
        "Verificación de imágenes corruptas o vacías:\n",
        "Se ejecutó un script para identificar imágenes que presentaran errores como archivos vacíos, daños en la codificación o dimensiones inválidas.\n",
        "El resultado mostró que existen imágenes corruptas en el dataset, por lo que será necesario eliminarlas o corregirlas antes de continuar con el preprocesamiento.\n",
        "Se generó un archivo con la lista de imágenes problemáticas para facilitar su depuración:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Nk-NcmgYwkXP",
        "outputId": "2de07558-24aa-493e-add5-24c00363a9da"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Procesando subdirectorios: 100%|██████████| 3/3 [00:00<00:00, 15.46it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "====================\n",
            "Total imágenes: 162916\n",
            "Total clases: 114\n",
            "Media de imágenes por clase: 1429.09\n",
            "Desviación estándar: 1260.43\n",
            "Mínimo: 152 (color_Potato_Potato___healthy)\n",
            "Máximo: 5507 (color_Orange_Orange___Haunglongbing_(Citrus_greening))\n",
            "Relación de desbalance: 36.23\n",
            "⚠️ Dataset desbalanceado. Considera balancear las clases.\n",
            "Conteo guardado en: C:\\Users\\Arys\\Desktop\\Proyecto - 2\\class_counts.csv\n",
            "\n",
            "Clases con más imágenes:\n",
            "                                                    Class  Count\n",
            "    color_Orange_Orange___Haunglongbing_(Citrus_greening)   5507\n",
            "grayscale_Orange_Orange___Haunglongbing_(Citrus_greening)   5507\n",
            "segmented_Orange_Orange___Haunglongbing_(Citrus_greening)   5507\n",
            "  segmented_Tomato_Tomato___Tomato_Yellow_Leaf_Curl_Virus   5357\n",
            "  grayscale_Tomato_Tomato___Tomato_Yellow_Leaf_Curl_Virus   5357\n",
            "\n",
            "Clases con menos imágenes:\n",
            "                                   Class  Count\n",
            "grayscale_Apple_Apple___Cedar_apple_rust    275\n",
            "segmented_Apple_Apple___Cedar_apple_rust    275\n",
            "           color_Potato_Potato___healthy    152\n",
            "       grayscale_Potato_Potato___healthy    152\n",
            "       segmented_Potato_Potato___healthy    152\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Configuración\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "MAX_WORKERS = 16\n",
        "OUTPUT_CSV = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\class_counts.csv\"\n",
        "\n",
        "def collect_class_counts(input_dir):\n",
        "    \"\"\"Recolecta conteos de imágenes .jpg, .jpeg y .png por clase con barra de progreso.\"\"\"\n",
        "    class_counts = {}\n",
        "    subdirs = ['color', 'grayscale', 'segmented']\n",
        "\n",
        "    for subdir in tqdm(subdirs, desc=\"Procesando subdirectorios\"):\n",
        "        subdir_path = os.path.join(input_dir, subdir)\n",
        "        if not os.path.exists(subdir_path):\n",
        "            continue\n",
        "\n",
        "        for plant in os.listdir(subdir_path):\n",
        "            plant_path = os.path.join(subdir_path, plant)\n",
        "            if not os.path.isdir(plant_path):\n",
        "                continue\n",
        "\n",
        "            for state in os.listdir(plant_path):\n",
        "                state_path = os.path.join(plant_path, state)\n",
        "                if not os.path.isdir(state_path):\n",
        "                    continue\n",
        "\n",
        "                images = [f for f in os.listdir(state_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "                if images:\n",
        "                    class_name = f\"{subdir}_{plant}_{state}\"\n",
        "                    class_counts[class_name] = len(images)\n",
        "\n",
        "    return class_counts\n",
        "\n",
        "def generate_balance_report(class_counts):\n",
        "    \"\"\"Genera informe de balance de clases.\"\"\"\n",
        "    if not class_counts:\n",
        "        print(\"Error: No se encontraron clases con imágenes.\")\n",
        "        return\n",
        "\n",
        "    # Convertir a DataFrame y ordenar\n",
        "    df = pd.DataFrame(list(class_counts.items()), columns=['Class', 'Count']).sort_values(by='Count', ascending=False)\n",
        "\n",
        "    # Estadísticas\n",
        "    total_images = df['Count'].sum()\n",
        "    num_classes = len(df)\n",
        "    mean_count = df['Count'].mean()\n",
        "    std_count = df['Count'].std() if len(df['Count']) > 1 else 0\n",
        "    min_count = df['Count'].min()\n",
        "    max_count = df['Count'].max()\n",
        "\n",
        "    # Imprimir resumen\n",
        "    print(f\"\\n{'=' * 20}\")\n",
        "    print(f\"Total imágenes: {total_images}\")\n",
        "    print(f\"Total clases: {num_classes}\")\n",
        "    print(f\"Media de imágenes por clase: {mean_count:.2f}\")\n",
        "    print(f\"Desviación estándar: {std_count:.2f}\")\n",
        "    print(f\"Mínimo: {min_count} ({df.loc[df['Count'].idxmin(), 'Class']})\")\n",
        "    print(f\"Máximo: {max_count} ({df.loc[df['Count'].idxmax(), 'Class']})\")\n",
        "\n",
        "    # Evaluar balance\n",
        "    imbalance_ratio = max_count / min_count if min_count > 0 else float('inf')\n",
        "    print(f\"Relación de desbalance: {imbalance_ratio:.2f}\")\n",
        "    print(\"⚠️ Dataset desbalanceado. Considera balancear las clases.\" if imbalance_ratio > 2 and num_classes > 1 else \"✅ Dataset razonablemente balanceado.\")\n",
        "\n",
        "    # Guardar conteos en CSV\n",
        "    df.to_csv(OUTPUT_CSV, index=False)\n",
        "    print(f\"Conteo guardado en: {OUTPUT_CSV}\")\n",
        "\n",
        "    # Mostrar clases extremas\n",
        "    print(\"\\nClases con más imágenes:\")\n",
        "    print(df.head(5)[['Class', 'Count']].to_string(index=False) if len(df) >= 5 else \"No hay datos suficientes.\")\n",
        "    print(\"\\nClases con menos imágenes:\")\n",
        "    print(df.tail(5)[['Class', 'Count']].to_string(index=False) if len(df) >= 5 else \"No hay datos suficientes.\")\n",
        "\n",
        "def main():\n",
        "    \"\"\"Ejecuta el análisis de balance de clases.\"\"\"\n",
        "    class_counts = collect_class_counts(DATASET_PATH)\n",
        "    generate_balance_report(class_counts)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RipfOhdz2FMR"
      },
      "source": [
        "## ***Preprocesamiento***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gw6NOop2Mxo"
      },
      "source": [
        "### ***Conversión de formatos de imagen***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvXDCXZ5_z-V"
      },
      "source": [
        "Se identificaron 2 archivos con extensión .jpeg y 2 archivos con extensión .png dentro del dataset.\n",
        "Para mantener la uniformidad en el preprocesamiento, todas estas imágenes fueron convertidas al formato .jpg, eliminando las versiones originales con extensiones distintas. Esto garantiza una estructura de datos homogénea para las etapas posteriores del flujo de trabajo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "Fm5YVMWA7mV4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Procesando directorios: 160it [00:00, 218.58it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "====================\n",
            "Imágenes .jpeg convertidas: 0\n",
            "Imágenes .png convertidas: 0\n",
            "Total archivos procesados: 0\n",
            "No se encontraron imágenes .png o .jpeg.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ruta del dataset local\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "\n",
        "def convert_only_png_jpeg_to_jpg_replace(input_dir):\n",
        "    \"\"\"Convierte imágenes .png y .jpeg a .jpg en el mismo directorio, eliminando los originales.\"\"\"\n",
        "    target_extensions = ('.png', '.jpeg')\n",
        "    converted_count = {'jpeg': 0, 'png': 0}\n",
        "    total_files_processed = 0\n",
        "\n",
        "    # Recorre directorios y busca imágenes .png y .jpeg\n",
        "    for root, _, files in tqdm(os.walk(input_dir), desc=\"Procesando directorios\"):\n",
        "        for file in files:\n",
        "            ext = os.path.splitext(file)[1].lower()\n",
        "            if ext in target_extensions:\n",
        "                input_path = os.path.join(root, file)\n",
        "                output_path = os.path.join(root, os.path.splitext(file)[0] + '.jpg')\n",
        "\n",
        "                try:\n",
        "                    # Convierte la imagen a RGB y guarda como .jpg\n",
        "                    with Image.open(input_path) as img:\n",
        "                        if img.mode != 'RGB':\n",
        "                            img = img.convert('RGB')\n",
        "                        img.save(output_path, 'JPEG', quality=95)\n",
        "                    converted_count[ext[1:]] += 1\n",
        "                    total_files_processed += 1\n",
        "                    # Elimina el archivo original\n",
        "                    os.remove(input_path)\n",
        "                except Exception as e:\n",
        "                    print(f\"Error al procesar {input_path}: {e}\")\n",
        "\n",
        "    # Imprime resumen de conversiones\n",
        "    print(f\"\\n{'=' * 20}\")\n",
        "    print(f\"Imágenes .jpeg convertidas: {converted_count['jpeg']}\")\n",
        "    print(f\"Imágenes .png convertidas: {converted_count['png']}\")\n",
        "    print(f\"Total archivos procesados: {total_files_processed}\")\n",
        "    if total_files_processed == 0:\n",
        "        print(\"No se encontraron imágenes .png o .jpeg.\")\n",
        "\n",
        "    return converted_count\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    convert_only_png_jpeg_to_jpg_replace(DATASET_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cbZoQCe3TmB"
      },
      "source": [
        "### ***Redimenzionamiento de imagenes a 224***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qv3eCNbjr5fJ"
      },
      "source": [
        "Se redimensionaron todas las imágenes a 224 x 224 píxeles, ya que la mayoría se encontraba en dimensiones como 256 x 256 u otras variantes. Esta estandarización es necesaria para asegurar la compatibilidad con el modelo ResNet, que requiere una entrada fija de dicha dimensión."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "l5o92UfBUFIX"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Recolectando imágenes: 160it [00:01, 137.58it/s]\n",
            "Redimensionando imágenes: 100%|██████████| 162916/162916 [04:07<00:00, 658.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "====================\n",
            "Imágenes redimensionadas: 162916\n",
            "Errores: 0\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Configuración\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "OUTPUT_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset_resized\"\n",
        "TARGET_SIZE = (224, 224)\n",
        "MAX_WORKERS = 16\n",
        "\n",
        "def collect_image_paths(input_dir):\n",
        "    \"\"\"Recolecta rutas de imágenes .jpg.\"\"\"\n",
        "    file_paths = []\n",
        "    # Recorre directorios y recolecta imágenes .jpg\n",
        "    for root, _, files in tqdm(os.walk(input_dir), desc=\"Recolectando imágenes\"):\n",
        "        for file in files:\n",
        "            if file.lower().endswith('.jpg'):\n",
        "                file_paths.append(os.path.join(root, file))\n",
        "    return file_paths\n",
        "\n",
        "def resize_image(file_path, output_dir, target_size):\n",
        "    \"\"\"Redimensiona una imagen .jpg y la guarda en el directorio de salida.\"\"\"\n",
        "    try:\n",
        "        # Crea subdirectorio de salida manteniendo la estructura\n",
        "        relative_path = os.path.relpath(os.path.dirname(file_path), DATASET_PATH)\n",
        "        output_subdir = os.path.join(output_dir, relative_path)\n",
        "        os.makedirs(output_subdir, exist_ok=True)\n",
        "        output_path = os.path.join(output_subdir, os.path.basename(file_path))\n",
        "\n",
        "        # Abre, convierte a RGB si es necesario, redimensiona y guarda\n",
        "        with Image.open(file_path) as img:\n",
        "            if img.mode != 'RGB':\n",
        "                img = img.convert('RGB')\n",
        "            img_resized = img.resize(target_size, Image.LANCZOS)\n",
        "            img_resized.save(output_path, 'JPEG', quality=95)\n",
        "        return file_path, output_path, None\n",
        "    except Exception as e:\n",
        "        return file_path, None, str(e)\n",
        "\n",
        "def resize_images(input_dir, output_dir, target_size, max_workers=MAX_WORKERS):\n",
        "    \"\"\"Redimensiona imágenes .jpg en paralelo y genera informe.\"\"\"\n",
        "    file_paths = collect_image_paths(input_dir)\n",
        "    resized_count = 0\n",
        "    errors = []\n",
        "\n",
        "    # Procesa imágenes en paralelo\n",
        "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
        "        future_to_file = {executor.submit(resize_image, path, output_dir, target_size): path for path in file_paths}\n",
        "        for future in tqdm(as_completed(future_to_file), total=len(file_paths), desc=\"Redimensionando imágenes\"):\n",
        "            input_path, output_path, error = future.result()\n",
        "            if error:\n",
        "                errors.append((input_path, error))\n",
        "            else:\n",
        "                resized_count += 1\n",
        "\n",
        "    # Imprime resumen\n",
        "    print(f\"\\n{'=' * 20}\")\n",
        "    print(f\"Imágenes redimensionadas: {resized_count}\")\n",
        "    print(f\"Errores: {len(errors)}\")\n",
        "    if errors:\n",
        "        print(\"\\nArchivos con errores:\")\n",
        "        for path, error in errors:\n",
        "            print(f\"  {path}: {error}\")\n",
        "    if resized_count == 0:\n",
        "        print(\"No se encontraron imágenes .jpg.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    resize_images(DATASET_PATH, OUTPUT_PATH, TARGET_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7ovtr_IXo5p"
      },
      "source": [
        "### ***Balanceo de clases por cada planta y estado***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CM8UgMp9X1zZ",
        "outputId": "d4e2ea61-e843-48e5-9c14-9497793ffc3b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Balanceando plantas: 100%|██████████| 14/14 [00:00<00:00, 21.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "====================\n",
            "Total imágenes balanceadas: 162916\n",
            "Clases procesadas: 114\n",
            "Pesos guardados en: C:\\Users\\Arys\\Desktop\\Proyecto - 2\\balanced_weights\\plant_weights.csv\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Configuración\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset_resized\"\n",
        "OUTPUT_WEIGHTS_DIR = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\balanced_weights\"\n",
        "OUTPUT_WEIGHTS = os.path.join(OUTPUT_WEIGHTS_DIR, \"plant_weights.csv\")\n",
        "os.makedirs(OUTPUT_WEIGHTS_DIR, exist_ok=True)\n",
        "\n",
        "def apply_plant_balancing(class_counts):\n",
        "    \"\"\"Aplica balanceo por planta con ponderación inversa.\"\"\"\n",
        "    # Extrae plantas únicas\n",
        "    plants = set('_'.join(cls.split('_')[1:2]) for cls in class_counts['Class'])\n",
        "    balanced_data = []\n",
        "\n",
        "    # Procesa cada planta\n",
        "    for plant in tqdm(plants, desc=\"Balanceando plantas\"):\n",
        "        # Filtra clases de la planta actual\n",
        "        plant_classes = [cls for cls in class_counts['Class'] if f\"_{plant}_\" in cls]\n",
        "        plant_data = class_counts[class_counts['Class'].isin(plant_classes)].copy()\n",
        "\n",
        "        if plant_data.empty:\n",
        "            continue\n",
        "\n",
        "        # Calcula pesos inversos para balanceo\n",
        "        total_images = plant_data['Count'].sum()\n",
        "        if total_images == 0:\n",
        "            continue\n",
        "        plant_data['Weight'] = total_images / plant_data['Count']\n",
        "        weight_sum = plant_data['Weight'].sum()\n",
        "        plant_data['Weight'] = plant_data['Weight'] / weight_sum\n",
        "\n",
        "        # Genera lista de imágenes por clase\n",
        "        for _, row in plant_data.iterrows():\n",
        "            img_parts = row['Class'].split('_')\n",
        "            img_type = img_parts[0]\n",
        "            plant_name = img_parts[1]\n",
        "            state = '_'.join(img_parts[2:])\n",
        "            state_path = os.path.join(DATASET_PATH, img_type, plant_name, state)\n",
        "\n",
        "            if os.path.exists(state_path):\n",
        "                images = [f for f in os.listdir(state_path) if f.lower().endswith('.jpg')]\n",
        "                for img in images[:min(len(images), row['Count'])]:\n",
        "                    balanced_data.append([row['Class'], img, row['Weight']])\n",
        "\n",
        "    # Guarda datos balanceados en CSV\n",
        "    if balanced_data:\n",
        "        balanced_df = pd.DataFrame(balanced_data, columns=['Class', 'Image', 'Weight'])\n",
        "        balanced_df.to_csv(OUTPUT_WEIGHTS, index=False)\n",
        "        print(f\"\\n{'=' * 20}\")\n",
        "        print(f\"Total imágenes balanceadas: {len(balanced_df)}\")\n",
        "        print(f\"Clases procesadas: {len(balanced_df['Class'].unique())}\")\n",
        "        print(f\"Pesos guardados en: {OUTPUT_WEIGHTS}\")\n",
        "    else:\n",
        "        print(\"Error: No se generaron datos balanceados. Verifica las rutas y el CSV.\")\n",
        "\n",
        "# Carga conteos y aplica balanceo\n",
        "if __name__ == \"__main__\":\n",
        "    class_counts = pd.read_csv(r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\class_counts.csv\")\n",
        "    apply_plant_balancing(class_counts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5E_lv8lcR_w"
      },
      "source": [
        "### ***Cargamos los pesos***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPPQDfSTcPNw",
        "outputId": "6a7b2beb-dc9e-474e-95b4-13b230916d67"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Configurando DataLoader: 100%|██████████| 1/1 [00:00<00:00,  4.85it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "====================\n",
            "Imágenes cargadas: 162916\n",
            "Clases únicas: 114\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "from torchvision import transforms\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Configuración\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset_resized\"\n",
        "WEIGHTS_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\balanced_weights\\plant_weights.csv\"\n",
        "BATCH_SIZE = 32\n",
        "NUM_WORKERS = 4\n",
        "\n",
        "# Transformaciones para entrenamiento\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "class PlantDataset(Dataset):\n",
        "    \"\"\"Carga imágenes .jpg con pesos para balanceo.\"\"\"\n",
        "    def __init__(self, weights_df, root_dir, transform=None):\n",
        "        self.data = weights_df\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.class_to_idx = {cls: idx for idx, cls in enumerate(weights_df['Class'].unique())}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"Obtiene imagen, etiqueta y peso.\"\"\"\n",
        "        row = self.data.iloc[idx]\n",
        "        img_parts = row['Class'].split('_')\n",
        "        img_path = f\"{self.root_dir}/{img_parts[0]}/{img_parts[1]}/{'_'.join(img_parts[2:])}/{row['Image']}\"\n",
        "\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        label = self.class_to_idx[row['Class']]\n",
        "        weight = row['Weight']\n",
        "        return image, label, weight\n",
        "\n",
        "def create_weighted_dataloader(weights_path, root_dir, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS):\n",
        "    \"\"\"Crea DataLoader con muestreo ponderado.\"\"\"\n",
        "    # Carga datos balanceados\n",
        "    weights_df = pd.read_csv(weights_path)\n",
        "    \n",
        "    # Crea dataset con barra de progreso\n",
        "    dataset = PlantDataset(weights_df, root_dir, transform=train_transforms)\n",
        "    \n",
        "    # Configura WeightedRandomSampler\n",
        "    weights = torch.tensor(weights_df['Weight'].values, dtype=torch.float)\n",
        "    sampler = WeightedRandomSampler(weights, num_samples=len(weights), replacement=True)\n",
        "\n",
        "    # Crea DataLoader\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, sampler=sampler, num_workers=num_workers)\n",
        "    \n",
        "    # Imprime resumen\n",
        "    print(f\"\\n{'=' * 20}\")\n",
        "    print(f\"Imágenes cargadas: {len(dataset)}\")\n",
        "    print(f\"Clases únicas: {len(dataset.class_to_idx)}\")\n",
        "    \n",
        "    return dataloader\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Configura DataLoader con barra de progreso\n",
        "    with tqdm(total=1, desc=\"Configurando DataLoader\") as pbar:\n",
        "        dataloader = create_weighted_dataloader(WEIGHTS_PATH, DATASET_PATH)\n",
        "        pbar.update(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUfIwJFGdDLZ"
      },
      "source": [
        "## ***División del dataset***\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3uYFljCudRNv",
        "outputId": "90692c31-2670-4d28-a939-79c445336484"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Clases encontradas: 114\n",
            "\n",
            "====================\n",
            "Total imágenes: 162916\n",
            "Entrenamiento: 114041 imágenes (114 clases)\n",
            "Validación: 24437 imágenes (114 clases)\n",
            "Prueba: 24438 imágenes (114 clases)\n",
            "CSVs guardados en: C:\\Users\\Arys\\Desktop\\Proyecto - 2\\balanced_weights\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Configuración\n",
        "WEIGHTS_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\balanced_weights\\plant_weights.csv\"\n",
        "OUTPUT_WEIGHTS_DIR = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\balanced_weights\"\n",
        "TRAIN_WEIGHTS = os.path.join(OUTPUT_WEIGHTS_DIR, \"train_weights.csv\")\n",
        "VAL_WEIGHTS = os.path.join(OUTPUT_WEIGHTS_DIR, \"val_weights.csv\")\n",
        "TEST_WEIGHTS = os.path.join(OUTPUT_WEIGHTS_DIR, \"test_weights.csv\")\n",
        "os.makedirs(OUTPUT_WEIGHTS_DIR, exist_ok=True)\n",
        "\n",
        "def split_dataset(weights_path, train_ratio=0.7, val_ratio=0.15):\n",
        "    \"\"\"Divide el dataset en conjuntos de entrenamiento, validación y prueba.\"\"\"\n",
        "    if not os.path.exists(weights_path):\n",
        "        raise FileNotFoundError(f\"No se encontró {weights_path}\")\n",
        "    \n",
        "    df = pd.read_csv(weights_path)\n",
        "    if not all(col in df.columns for col in ['Class', 'Image', 'Weight']):\n",
        "        raise ValueError(\"El CSV debe contener 'Class', 'Image' y 'Weight'\")\n",
        "    \n",
        "    if len(df) < 10:  # Validación mínima\n",
        "        raise ValueError(\"El dataset es demasiado pequeño para dividir\")\n",
        "    \n",
        "    num_classes = len(df['Class'].unique())\n",
        "    print(f\"Clases encontradas: {num_classes}\")\n",
        "    \n",
        "    # Divide en entrenamiento y resto (validación + prueba)\n",
        "    train_df, temp_df = train_test_split(\n",
        "        df, train_size=train_ratio, stratify=df['Class'], random_state=42\n",
        "    )\n",
        "    val_size = val_ratio / (1 - train_ratio)\n",
        "    val_df, test_df = train_test_split(\n",
        "        temp_df, train_size=val_size, stratify=temp_df['Class'], random_state=42\n",
        "    )\n",
        "    \n",
        "    # Guarda los conjuntos\n",
        "    train_df.to_csv(TRAIN_WEIGHTS, index=False)\n",
        "    val_df.to_csv(VAL_WEIGHTS, index=False)\n",
        "    test_df.to_csv(TEST_WEIGHTS, index=False)\n",
        "    \n",
        "    print(f\"\\n{'=' * 20}\")\n",
        "    print(f\"Total imágenes: {len(df)}\")\n",
        "    print(f\"Entrenamiento: {len(train_df)} imágenes ({len(train_df['Class'].unique())} clases)\")\n",
        "    print(f\"Validación: {len(val_df)} imágenes ({len(val_df['Class'].unique())} clases)\")\n",
        "    print(f\"Prueba: {len(test_df)} imágenes ({len(test_df['Class'].unique())} clases)\")\n",
        "    print(f\"CSVs guardados en: {OUTPUT_WEIGHTS_DIR}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        split_dataset(WEIGHTS_PATH)\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {str(e)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7e_As1MAdY6m"
      },
      "source": [
        "## ***Entrenamiento del modelo***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBgUGEe_ddwa",
        "outputId": "3f7fcf00-d5df-4bcd-cd0b-b55b08346556"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                       "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cargado C:\\Users\\Arys\\Desktop\\Proyecto - 2\\balanced_weights\\train_weights.csv: 114041 imágenes, 114 clases\n",
            "Cargado C:\\Users\\Arys\\Desktop\\Proyecto - 2\\balanced_weights\\val_weights.csv: 24437 imágenes, 114 clases\n",
            "Cargado C:\\Users\\Arys\\Desktop\\Proyecto - 2\\balanced_weights\\test_weights.csv: 24438 imágenes, 114 clases\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Entrenando época 1/20: 100%|██████████| 1782/1782 [14:12<00:00,  2.09it/s]\n",
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Época 1: Pérdida Entrenamiento: 0.5696, Precisión Entrenamiento: 84.06%\n",
            "Precisión Validación: 79.73%\n",
            "Mejor modelo guardado en: C:\\Users\\Arys\\Desktop\\Proyecto - 2\\normal_model.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Entrenando época 2/20: 100%|██████████| 1782/1782 [14:41<00:00,  2.02it/s]\n",
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Época 2: Pérdida Entrenamiento: 0.2960, Precisión Entrenamiento: 90.78%\n",
            "Precisión Validación: 84.75%\n",
            "Mejor modelo guardado en: C:\\Users\\Arys\\Desktop\\Proyecto - 2\\normal_model.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Entrenando época 3/20: 100%|██████████| 1782/1782 [13:43<00:00,  2.16it/s]\n",
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Época 3: Pérdida Entrenamiento: 0.2565, Precisión Entrenamiento: 91.88%\n",
            "Precisión Validación: 87.87%\n",
            "Mejor modelo guardado en: C:\\Users\\Arys\\Desktop\\Proyecto - 2\\normal_model.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Entrenando época 4/20: 100%|██████████| 1782/1782 [13:26<00:00,  2.21it/s]\n",
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Época 4: Pérdida Entrenamiento: 0.2243, Precisión Entrenamiento: 92.82%\n",
            "Precisión Validación: 88.47%\n",
            "Mejor modelo guardado en: C:\\Users\\Arys\\Desktop\\Proyecto - 2\\normal_model.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Entrenando época 5/20: 100%|██████████| 1782/1782 [13:02<00:00,  2.28it/s]\n",
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Época 5: Pérdida Entrenamiento: 0.2126, Precisión Entrenamiento: 93.16%\n",
            "Precisión Validación: 89.50%\n",
            "Mejor modelo guardado en: C:\\Users\\Arys\\Desktop\\Proyecto - 2\\normal_model.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Entrenando época 6/20: 100%|██████████| 1782/1782 [13:02<00:00,  2.28it/s]\n",
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Época 6: Pérdida Entrenamiento: 0.1913, Precisión Entrenamiento: 93.81%\n",
            "Precisión Validación: 82.50%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Entrenando época 7/20: 100%|██████████| 1782/1782 [13:02<00:00,  2.28it/s]\n",
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Época 7: Pérdida Entrenamiento: 0.1832, Precisión Entrenamiento: 94.06%\n",
            "Precisión Validación: 90.17%\n",
            "Mejor modelo guardado en: C:\\Users\\Arys\\Desktop\\Proyecto - 2\\normal_model.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Entrenando época 8/20: 100%|██████████| 1782/1782 [13:55<00:00,  2.13it/s]\n",
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Época 8: Pérdida Entrenamiento: 0.1696, Precisión Entrenamiento: 94.43%\n",
            "Precisión Validación: 91.06%\n",
            "Mejor modelo guardado en: C:\\Users\\Arys\\Desktop\\Proyecto - 2\\normal_model.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Entrenando época 9/20: 100%|██████████| 1782/1782 [13:53<00:00,  2.14it/s]\n",
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Época 9: Pérdida Entrenamiento: 0.1636, Precisión Entrenamiento: 94.52%\n",
            "Precisión Validación: 93.45%\n",
            "Mejor modelo guardado en: C:\\Users\\Arys\\Desktop\\Proyecto - 2\\normal_model.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Entrenando época 10/20: 100%|██████████| 1782/1782 [13:52<00:00,  2.14it/s]\n",
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Época 10: Pérdida Entrenamiento: 0.1564, Precisión Entrenamiento: 94.78%\n",
            "Precisión Validación: 92.07%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Entrenando época 11/20: 100%|██████████| 1782/1782 [15:45<00:00,  1.88it/s]\n",
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Época 11: Pérdida Entrenamiento: 0.1505, Precisión Entrenamiento: 95.08%\n",
            "Precisión Validación: 91.06%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Entrenando época 12/20: 100%|██████████| 1782/1782 [16:57<00:00,  1.75it/s]\n",
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Época 12: Pérdida Entrenamiento: 0.1493, Precisión Entrenamiento: 95.03%\n",
            "Precisión Validación: 91.74%\n",
            "Parando temprano en época 12\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                      "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "====================\n",
            "Precisión en prueba: 91.85%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "from torchvision import models, transforms\n",
        "from torchvision.models import ResNet18_Weights\n",
        "from tqdm import tqdm\n",
        "\n",
        "# =================== CONFIGURACIÓN ===================\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset_resized\"\n",
        "WEIGHTS_DIR = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\balanced_weights\"\n",
        "TRAIN_WEIGHTS = os.path.join(WEIGHTS_DIR, \"train_weights.csv\")\n",
        "VAL_WEIGHTS = os.path.join(WEIGHTS_DIR, \"val_weights.csv\")\n",
        "TEST_WEIGHTS = os.path.join(WEIGHTS_DIR, \"test_weights.csv\")\n",
        "MODEL_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\normal_model.pth\"\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# =================== TRANSFORMACIONES ===================\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.RandomRotation(20),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "    transforms.RandomAffine(degrees=0, translate=(0.05, 0.05)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# =================== DATASET PERSONALIZADO ===================\n",
        "class PlantDataset(Dataset):\n",
        "    def __init__(self, weights_df, root_dir, transform=None, class_to_idx=None):\n",
        "        self.data = weights_df\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.class_to_idx = class_to_idx\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.data.iloc[idx]\n",
        "        img_parts = row['Class'].split('_')\n",
        "        img_path = f\"{self.root_dir}/{img_parts[0]}/{img_parts[1]}/{'_'.join(img_parts[2:])}/{row['Image']}\"\n",
        "        try:\n",
        "            image = Image.open(img_path).convert('RGB')\n",
        "            if self.transform:\n",
        "                image = self.transform(image)\n",
        "            label = self.class_to_idx[row['Class']]\n",
        "            return image, label\n",
        "        except Exception as e:\n",
        "            print(f\"Error al cargar {img_path}: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "# =================== DATALOADER ===================\n",
        "def create_dataloader(weights_path, root_dir, transform, class_to_idx, batch_size=64, use_sampler=True):\n",
        "    if not os.path.exists(weights_path):\n",
        "        raise FileNotFoundError(f\"No se encontró {weights_path}\")\n",
        "    weights_df = pd.read_csv(weights_path)\n",
        "    if not all(col in weights_df.columns for col in ['Class', 'Image', 'Weight']):\n",
        "        raise ValueError(f\"El CSV debe contener 'Class', 'Image' y 'Weight'\")\n",
        "    \n",
        "    dataset = PlantDataset(weights_df, root_dir, transform=transform, class_to_idx=class_to_idx)\n",
        "    sampler = None\n",
        "    if use_sampler:\n",
        "        weights = torch.tensor(weights_df['Weight'].values, dtype=torch.float)\n",
        "        sampler = WeightedRandomSampler(weights, num_samples=len(weights), replacement=True)\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, sampler=sampler, shuffle=not use_sampler)\n",
        "    print(f\"Cargado {weights_path}: {len(dataset)} imágenes, {len(class_to_idx)} clases\")\n",
        "    return dataloader\n",
        "\n",
        "# =================== ENTRENAMIENTO ===================\n",
        "def train_model(train_loader, val_loader, num_epochs=20, early_stop_patience=3):\n",
        "    model = models.resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
        "    num_classes = len(train_loader.dataset.class_to_idx)\n",
        "    model.fc = nn.Sequential(\n",
        "        nn.Dropout(0.3),\n",
        "        nn.Linear(model.fc.in_features, num_classes)\n",
        "    )\n",
        "    model = model.to(DEVICE)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=0.0005)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2)\n",
        "\n",
        "    best_acc = 0.0\n",
        "    epochs_without_improvement = 0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for images, labels in tqdm(train_loader, desc=f\"Entrenando época {epoch+1}/{num_epochs}\", leave=True):\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        train_loss = running_loss / len(train_loader)\n",
        "        train_acc = 100 * correct / total\n",
        "\n",
        "        # VALIDACIÓN\n",
        "        model.eval()\n",
        "        val_correct = 0\n",
        "        val_total = 0\n",
        "        with torch.no_grad():\n",
        "            for images, labels in tqdm(val_loader, desc=\"Validando\", leave=False):\n",
        "                images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "                outputs = model(images)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                val_total += labels.size(0)\n",
        "                val_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        val_acc = 100 * val_correct / val_total\n",
        "        scheduler.step(val_acc)\n",
        "\n",
        "        print(f\"\\nÉpoca {epoch+1}: Pérdida Entrenamiento: {train_loss:.4f}, Precisión Entrenamiento: {train_acc:.2f}%\")\n",
        "        print(f\"Precisión Validación: {val_acc:.2f}%\")\n",
        "\n",
        "        # EARLY STOPPING Y SAVE MODEL\n",
        "        if val_acc > best_acc:\n",
        "            best_acc = val_acc\n",
        "            epochs_without_improvement = 0\n",
        "            try:\n",
        "                torch.save(model.state_dict(), MODEL_PATH)\n",
        "                print(f\"Mejor modelo guardado en: {MODEL_PATH}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error al guardar el modelo: {str(e)}\")\n",
        "        else:\n",
        "            epochs_without_improvement += 1\n",
        "\n",
        "        if epochs_without_improvement >= early_stop_patience:\n",
        "            print(f\"Parando temprano en época {epoch+1}\")\n",
        "            break\n",
        "\n",
        "    return model\n",
        "\n",
        "# =================== EVALUACIÓN ===================\n",
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in tqdm(test_loader, desc=\"Evaluando en prueba\", leave=False):\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    test_acc = 100 * correct / total\n",
        "    print(f\"\\n{'=' * 20}\")\n",
        "    print(f\"Precisión en prueba: {test_acc:.2f}%\")\n",
        "    return test_acc\n",
        "\n",
        "# =================== MAIN ===================\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        # Verificar CSVs\n",
        "        for path in [TRAIN_WEIGHTS, VAL_WEIGHTS, TEST_WEIGHTS]:\n",
        "            if not os.path.exists(path):\n",
        "                raise FileNotFoundError(f\"No se encontró {path}\")\n",
        "        \n",
        "        # Crear mapeo global de clases\n",
        "        train_df = pd.read_csv(TRAIN_WEIGHTS)\n",
        "        all_classes = sorted(train_df['Class'].unique())\n",
        "        class_to_idx = {cls: idx for idx, cls in enumerate(all_classes)}\n",
        "\n",
        "        with tqdm(total=3, desc=\"Configurando DataLoaders\", leave=False) as pbar:\n",
        "            train_loader = create_dataloader(TRAIN_WEIGHTS, DATASET_PATH, train_transforms, class_to_idx, use_sampler=True)\n",
        "            pbar.update(1)\n",
        "            val_loader = create_dataloader(VAL_WEIGHTS, DATASET_PATH, val_transforms, class_to_idx, use_sampler=False)\n",
        "            pbar.update(1)\n",
        "            test_loader = create_dataloader(TEST_WEIGHTS, DATASET_PATH, val_transforms, class_to_idx, use_sampler=False)\n",
        "            pbar.update(1)\n",
        "\n",
        "        model = train_model(train_loader, val_loader)\n",
        "        evaluate_model(model, test_loader)\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {str(e)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ***Pruebas con camara***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Arys\\Desktop\\Proyecto - 2\\venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Arys\\Desktop\\Proyecto - 2\\venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicciones en tiempo real. Presiona 'q' para guardar imagen, 'Esc' para salir.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Capturando desde cámara:   0%|          | 0/1 [03:19<?, ?it/s]\n"
          ]
        },
        {
          "ename": "error",
          "evalue": "OpenCV(4.12.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window_w32.cpp:1261: error: (-27:Null pointer) NULL window: 'Umbral' in function 'cvDestroyWindow'\n",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31merror\u001b[39m                                     Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 183\u001b[39m\n\u001b[32m    180\u001b[39m             cv2.destroyWindow(\u001b[33m\"\u001b[39m\u001b[33mUmbral\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m     \u001b[43mcapture_and_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 180\u001b[39m, in \u001b[36mcapture_and_predict\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    178\u001b[39m cv2.destroyAllWindows()\n\u001b[32m    179\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m DEBUG:\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m     \u001b[43mcv2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdestroyWindow\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mUmbral\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "\u001b[31merror\u001b[39m: OpenCV(4.12.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window_w32.cpp:1261: error: (-27:Null pointer) NULL window: 'Umbral' in function 'cvDestroyWindow'\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from PIL import Image\n",
        "from torchvision import models, transforms\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ================= CONFIGURACIÓN =================\n",
        "MODEL_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\normal_model.pth\"\n",
        "WEIGHTS_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\balanced_weights\\train_weights.csv\"\n",
        "CAPTURED_IMAGES_DIR = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\captured_images\"\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "DEBUG = True  # Activa la depuración para ver la imagen umbralizada\n",
        "\n",
        "os.makedirs(CAPTURED_IMAGES_DIR, exist_ok=True)\n",
        "\n",
        "# ================ TRANSFORMACIÓN =================\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# ================ CARGAR MODELO ==================\n",
        "def load_model_and_classes(model_path, weights_path):\n",
        "    \"\"\"Carga el modelo y el mapeo de clases.\"\"\"\n",
        "    weights_df = pd.read_csv(weights_path)\n",
        "    all_classes = sorted(weights_df['Class'].unique())\n",
        "    class_to_idx = {cls: idx for idx, cls in enumerate(all_classes)}\n",
        "    idx_to_class = {idx: cls for cls, idx in class_to_idx.items()}\n",
        "    \n",
        "    model = models.resnet18(pretrained=False)\n",
        "    model.fc = nn.Sequential(\n",
        "        nn.Dropout(0.3),\n",
        "        nn.Linear(model.fc.in_features, len(class_to_idx))\n",
        "    )\n",
        "    model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
        "    model = model.to(DEVICE)\n",
        "    model.eval()\n",
        "    return model, idx_to_class\n",
        "\n",
        "def normalize_brightness(frame):\n",
        "    \"\"\"Normaliza el brillo de la imagen.\"\"\"\n",
        "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
        "    hsv[:, :, 2] = cv2.normalize(hsv[:, :, 2], None, 0, 255, cv2.NORM_MINMAX)\n",
        "    return cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
        "\n",
        "def detect_leaf(frame, min_area=500):\n",
        "    \"\"\"Detecta una hoja con umbral adaptativo y devuelve el recuadro con contornos mejorados.\"\"\"\n",
        "    # Normaliza el brillo\n",
        "    frame = normalize_brightness(frame)\n",
        "    \n",
        "    # Convierte a escala de grises y aplica desenfoque\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "    \n",
        "    # Aplica umbral adaptativo (mantenemos el original que te gusta)\n",
        "    thresh = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
        "                                   cv2.THRESH_BINARY_INV, 21, 5)\n",
        "    \n",
        "    # Ligero refinamiento morfológico para mejorar contornos sin cambiar la esencia\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
        "    cleaned = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel, iterations=1)\n",
        "    \n",
        "    # Muestra la imagen umbralizada para depuración (si DEBUG=True)\n",
        "    if DEBUG:\n",
        "        cv2.imshow(\"Umbral\", cleaned)\n",
        "    \n",
        "    # Encuentra contornos\n",
        "    contours, _ = cv2.findContours(cleaned, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    \n",
        "    if contours:\n",
        "        # Selecciona el contorno más grande\n",
        "        largest_contour = max(contours, key=cv2.contourArea)\n",
        "        area = cv2.contourArea(largest_contour)\n",
        "        if area > min_area:\n",
        "            x, y, w, h = cv2.boundingRect(largest_contour)\n",
        "            if w > 30 and h > 30 and w < frame.shape[1] * 0.9 and h < frame.shape[0] * 0.9:\n",
        "                # Dibuja el contorno en la imagen original\n",
        "                cv2.drawContours(frame, [largest_contour], -1, (0, 255, 0), 2)\n",
        "                return (x, y, x+w, y+h), frame[y:y+h, x:x+w]\n",
        "    \n",
        "    return None, frame\n",
        "\n",
        "def predict_image(image, model, idx_to_class, transform):\n",
        "    \"\"\"Predice la clase de una imagen y devuelve la confianza.\"\"\"\n",
        "    image = transform(image).unsqueeze(0).to(DEVICE)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(image)\n",
        "        probs = torch.softmax(outputs, dim=1)\n",
        "        confidence, predicted = torch.max(probs, 1)\n",
        "    return idx_to_class[predicted.item()], confidence.item()\n",
        "\n",
        "def capture_and_predict():\n",
        "    \"\"\"Captura imágenes, detecta una hoja y predice en tiempo real.\"\"\"\n",
        "    model, idx_to_class = load_model_and_classes(MODEL_PATH, WEIGHTS_PATH)\n",
        "    cap = cv2.VideoCapture(0)\n",
        "    if not cap.isOpened():\n",
        "        print(\"Error: No se pudo abrir la cámara.\")\n",
        "        return\n",
        "\n",
        "    # Reducir la resolución de la cámara para mejorar FPS\n",
        "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
        "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
        "\n",
        "    print(\"Predicciones en tiempo real. Presiona 'q' para guardar imagen, 'Esc' para salir.\")\n",
        "    \n",
        "    # Variables para estabilización\n",
        "    last_bbox = None\n",
        "    last_predicted_class = \"Buscando hoja...\"\n",
        "    last_confidence = 0.0\n",
        "    stable_count = 0\n",
        "    STABLE_THRESHOLD = 3  # Número de frames consecutivos para considerar una detección estable\n",
        "    \n",
        "    with tqdm(total=1, desc=\"Capturando desde cámara\", leave=True) as pbar:\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                print(\"Error: No se pudo leer el frame.\")\n",
        "                break\n",
        "\n",
        "            # Detecta una hoja\n",
        "            bbox, roi = detect_leaf(frame, min_area=500)\n",
        "            predicted_class = last_predicted_class\n",
        "            confidence = last_confidence\n",
        "\n",
        "            if bbox:\n",
        "                # Compara con la detección anterior para estabilizar\n",
        "                if last_bbox and abs(bbox[0] - last_bbox[0]) < 50 and abs(bbox[1] - last_bbox[1]) < 50:\n",
        "                    stable_count += 1\n",
        "                else:\n",
        "                    stable_count = 1\n",
        "                    last_bbox = bbox\n",
        "                \n",
        "                if stable_count >= STABLE_THRESHOLD:\n",
        "                    x1, y1, x2, y2 = bbox\n",
        "                    roi_pil = Image.fromarray(cv2.cvtColor(roi, cv2.COLOR_BGR2RGB))\n",
        "                    predicted_class, confidence = predict_image(roi_pil, model, idx_to_class, test_transforms)\n",
        "                    last_predicted_class = predicted_class\n",
        "                    last_confidence = confidence\n",
        "                    # Dibuja el rectángulo y la predicción\n",
        "                    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "                    cv2.putText(frame, f\"Clase: {predicted_class}\", (x1, y1-10), \n",
        "                                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
        "                    cv2.putText(frame, f\"Confianza: {confidence*100:.2f}%\", (x1, y1-30), \n",
        "                                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)\n",
        "            else:\n",
        "                stable_count = 0\n",
        "                last_bbox = None\n",
        "                predicted_class = \"Buscando hoja...\"\n",
        "                confidence = 0.0\n",
        "                last_predicted_class = predicted_class\n",
        "                last_confidence = confidence\n",
        "\n",
        "            # Muestra la predicción en la parte superior\n",
        "            cv2.putText(frame, f\"Pred: {predicted_class}\", (10, 30), \n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
        "            cv2.putText(frame, f\"Conf: {confidence*100:.2f}%\", (10, 60), \n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)\n",
        "            cv2.imshow(\"Cámara\", frame)\n",
        "\n",
        "            key = cv2.waitKey(30)  # 30ms (~33 FPS) para un feed más fluido\n",
        "            if key == ord('q') and bbox:  # Solo guarda si se detecta una hoja\n",
        "                roi_pil = Image.fromarray(cv2.cvtColor(roi, cv2.COLOR_BGR2RGB))\n",
        "                save_path = os.path.join(CAPTURED_IMAGES_DIR, \n",
        "                                       f\"captured_{predicted_class}_{confidence*100:.2f}_{int(time.time())}.jpg\")\n",
        "                roi_pil.save(save_path)\n",
        "                print(f\"Imagen guardada: {save_path}\")\n",
        "                pbar.update(0)\n",
        "            elif key == 27:  # Esc\n",
        "                break\n",
        "\n",
        "        cap.release()\n",
        "        cv2.destroyAllWindows()\n",
        "        if DEBUG:\n",
        "            cv2.destroyWindow(\"Umbral\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    capture_and_predict()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ***Generación del dataset augmentado y Carga de pesos***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Recolectando imágenes: 160it [00:00, 321.18it/s]\n",
            "Aumentando imágenes: 100%|██████████| 162916/162916 [1:20:11<00:00, 33.86it/s]  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "====================\n",
            "Imágenes totales (originales + aumentadas): 977496\n",
            "Clases únicas: 114\n",
            "Pesos guardados en: C:\\Users\\Arys\\Desktop\\Proyecto - 2\\augmented_weights\\augmented_plant_weights.csv\n",
            "Errores: 0\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms.functional import to_pil_image\n",
        "from tqdm import tqdm\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "\n",
        "# Configuración\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset_resized\"\n",
        "AUGMENTED_OUTPUT_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset_augmented\"\n",
        "AUGMENTED_WEIGHTS = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\augmented_weights\\augmented_plant_weights.csv\"\n",
        "AUGMENTATIONS_PER_IMAGE = 5\n",
        "TARGET_SIZE = (224, 224)\n",
        "MAX_WORKERS = 16\n",
        "\n",
        "# Transformaciones para aumento de datos\n",
        "augment_transforms = transforms.Compose([\n",
        "    transforms.ToTensor(),  # Convertir imagen PIL a tensor\n",
        "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomVerticalFlip(p=0.5),\n",
        "    transforms.RandomRotation(20),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "    transforms.RandomAffine(degrees=0, translate=(0.05, 0.05)),\n",
        "])\n",
        "\n",
        "def collect_image_paths(input_dir):\n",
        "    \"\"\"Recolecta rutas de imágenes .jpg.\"\"\"\n",
        "    file_paths = []\n",
        "    for root, _, files in tqdm(os.walk(input_dir), desc=\"Recolectando imágenes\"):\n",
        "        for file in files:\n",
        "            if file.lower().endswith('.jpg'):\n",
        "                file_paths.append(os.path.join(root, file))\n",
        "    return file_paths\n",
        "\n",
        "def augment_and_save_image(file_path, output_dir, augmentations_per_image):\n",
        "    \"\"\"Genera imágenes aumentadas y las guarda.\"\"\"\n",
        "    results = []\n",
        "    try:\n",
        "        # Obtener la ruta relativa y la clase\n",
        "        relative_path = os.path.relpath(os.path.dirname(file_path), DATASET_PATH)\n",
        "        output_subdir = os.path.join(output_dir, relative_path)\n",
        "        os.makedirs(output_subdir, exist_ok=True)\n",
        "        \n",
        "        # Generar nombre de clase (incluyendo prefijo: color, grayscale, segmented)\n",
        "        img_class_parts = relative_path.replace('\\\\', '/').split('/')\n",
        "        if len(img_class_parts) < 2:  # Asegurarse de que hay al menos tipo (color/grayscale/segmented) y planta\n",
        "            return [(file_path, None, None, None, \"Ruta relativa inválida\")]\n",
        "        img_class = '_'.join(img_class_parts)  # Ejemplo: color_Apple_Apple_scab\n",
        "        \n",
        "        with Image.open(file_path) as img:\n",
        "            img = img.convert('RGB')\n",
        "            base_name = os.path.splitext(os.path.basename(file_path))[0]\n",
        "            \n",
        "            # Guardar imagen original\n",
        "            output_path = os.path.join(output_subdir, f\"{base_name}.jpg\")\n",
        "            try:\n",
        "                img.resize(TARGET_SIZE, Image.LANCZOS).save(output_path, 'JPEG', quality=95)\n",
        "                results.append((file_path, output_path, img_class, 1.0, None))\n",
        "            except Exception as e:\n",
        "                results.append((file_path, None, img_class, None, f\"Error al guardar imagen original: {str(e)}\"))\n",
        "            \n",
        "            # Generar imágenes aumentadas\n",
        "            for i in range(augmentations_per_image):\n",
        "                try:\n",
        "                    aug_img = augment_transforms(img)  # Aplica transformaciones (img se convierte a tensor)\n",
        "                    aug_img_pil = to_pil_image(aug_img)  # Convierte tensor a PIL\n",
        "                    aug_path = os.path.join(output_subdir, f\"{base_name}_aug_{i}.jpg\")\n",
        "                    aug_img_pil.save(aug_path, 'JPEG', quality=95)  # Guardar con PIL\n",
        "                    results.append((file_path, aug_path, img_class, 0.5, None))  # Peso menor para aumentadas\n",
        "                except Exception as e:\n",
        "                    results.append((file_path, None, img_class, None, f\"Error al generar imagen aumentada {i}: {str(e)}\"))\n",
        "                \n",
        "        return results\n",
        "    except Exception as e:\n",
        "        return [(file_path, None, None, None, f\"Error general: {str(e)}\")]\n",
        "\n",
        "def augment_dataset(input_dir, output_dir, augmentations_per_image):\n",
        "    \"\"\"Aumenta el dataset y genera CSV con pesos.\"\"\"\n",
        "    os.makedirs(os.path.dirname(AUGMENTED_WEIGHTS), exist_ok=True)\n",
        "    file_paths = collect_image_paths(input_dir)\n",
        "    all_results = []\n",
        "    \n",
        "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "        future_to_file = {executor.submit(augment_and_save_image, path, output_dir, augmentations_per_image): path for path in file_paths}\n",
        "        for future in tqdm(as_completed(future_to_file), total=len(file_paths), desc=\"Aumentando imágenes\"):\n",
        "            all_results.extend(future.result())\n",
        "    \n",
        "    # Separar resultados válidos y errores\n",
        "    valid_results = [r for r in all_results if r[1] is not None and r[2] is not None]\n",
        "    errors = [r for r in all_results if r[4] is not None]\n",
        "    \n",
        "    # Crear DataFrame\n",
        "    data = [(r[2], os.path.basename(r[1]), r[3]) for r in valid_results]\n",
        "    if not data:\n",
        "        print(f\"Error: No se generaron imágenes válidas. Total errores: {len(errors)}\")\n",
        "        print(\"\\nArchivos con errores:\")\n",
        "        for _, _, _, _, error in errors:\n",
        "            print(f\"  {error}\")\n",
        "        return\n",
        "    \n",
        "    df = pd.DataFrame(data, columns=['Class', 'Image', 'Weight'])\n",
        "    \n",
        "    # Calcular pesos inversos por clase\n",
        "    class_counts = df['Class'].value_counts()\n",
        "    total_images = len(df)\n",
        "    df['Weight'] = df['Class'].apply(lambda x: total_images / class_counts[x])\n",
        "    weight_sum = df['Weight'].sum()\n",
        "    df['Weight'] = df['Weight'] / weight_sum\n",
        "    \n",
        "    df.to_csv(AUGMENTED_WEIGHTS, index=False)\n",
        "    \n",
        "    # Resumen\n",
        "    print(f\"\\n{'=' * 20}\")\n",
        "    print(f\"Imágenes totales (originales + aumentadas): {len(df)}\")\n",
        "    print(f\"Clases únicas: {len(df['Class'].unique())}\")\n",
        "    print(f\"Pesos guardados en: {AUGMENTED_WEIGHTS}\")\n",
        "    print(f\"Errores: {len(errors)}\")\n",
        "    if errors:\n",
        "        print(\"\\nArchivos con errores:\")\n",
        "        for _, _, _, _, error in errors:\n",
        "            print(f\"  {error}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    augment_dataset(DATASET_PATH, AUGMENTED_OUTPUT_PATH, AUGMENTATIONS_PER_IMAGE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ***División del dataset augmentado***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Arys\\AppData\\Local\\Temp\\ipykernel_19564\\2653019098.py:26: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  df = df.groupby('Class', group_keys=False).apply(lambda x: x.sample(frac=sample_fraction, random_state=42)).reset_index(drop=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Se ha muestreado el 30.0% del dataset para pruebas\n",
            "Clases encontradas: 114\n",
            "\n",
            "====================\n",
            "Total imágenes: 293258\n",
            "Entrenamiento: 205280 imágenes (114 clases)\n",
            "Validación: 43988 imágenes (114 clases)\n",
            "Prueba: 43990 imágenes (114 clases)\n",
            "CSVs guardados en: C:\\Users\\Arys\\Desktop\\Proyecto - 2\\augmented_weights\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Configuración\n",
        "AUGMENTED_WEIGHTS = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\augmented_weights\\augmented_plant_weights.csv\"\n",
        "OUTPUT_WEIGHTS_DIR = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\augmented_weights\"\n",
        "TRAIN_WEIGHTS = os.path.join(OUTPUT_WEIGHTS_DIR, \"aug_train_weights.csv\")\n",
        "VAL_WEIGHTS = os.path.join(OUTPUT_WEIGHTS_DIR, \"aug_val_weights.csv\")\n",
        "TEST_WEIGHTS = os.path.join(OUTPUT_WEIGHTS_DIR, \"aug_test_weights.csv\")\n",
        "os.makedirs(OUTPUT_WEIGHTS_DIR, exist_ok=True)\n",
        "\n",
        "def split_augmented_dataset(weights_path, train_ratio=0.7, val_ratio=0.15, sample_fraction=None):\n",
        "    \"\"\"Divide el dataset aumentado en entrenamiento, validación y prueba.\"\"\"\n",
        "    if not os.path.exists(weights_path):\n",
        "        raise FileNotFoundError(f\"No se encontró {weights_path}\")\n",
        "\n",
        "    df = pd.read_csv(weights_path)\n",
        "    if not all(col in df.columns for col in ['Class', 'Image', 'Weight']):\n",
        "        raise ValueError(\"El CSV debe contener 'Class', 'Image' y 'Weight'\")\n",
        "\n",
        "    if len(df) < 10:\n",
        "        raise ValueError(\"El dataset es demasiado pequeño para dividir\")\n",
        "\n",
        "    if sample_fraction is not None and 0 < sample_fraction < 1:\n",
        "        df = df.groupby('Class', group_keys=False).apply(lambda x: x.sample(frac=sample_fraction, random_state=42)).reset_index(drop=True)\n",
        "        print(f\"Se ha muestreado el {sample_fraction * 100:.1f}% del dataset para pruebas\")\n",
        "\n",
        "    num_classes = len(df['Class'].unique())\n",
        "    print(f\"Clases encontradas: {num_classes}\")\n",
        "\n",
        "    # Divide en entrenamiento y resto (validación + prueba)\n",
        "    train_df, temp_df = train_test_split(\n",
        "        df, train_size=train_ratio, stratify=df['Class'], random_state=42\n",
        "    )\n",
        "    val_size = val_ratio / (1 - train_ratio)\n",
        "    val_df, test_df = train_test_split(\n",
        "        temp_df, train_size=val_size, stratify=temp_df['Class'], random_state=42\n",
        "    )\n",
        "\n",
        "    # Guarda los conjuntos\n",
        "    train_df.to_csv(TRAIN_WEIGHTS, index=False)\n",
        "    val_df.to_csv(VAL_WEIGHTS, index=False)\n",
        "    test_df.to_csv(TEST_WEIGHTS, index=False)\n",
        "\n",
        "    print(f\"\\n{'=' * 20}\")\n",
        "    print(f\"Total imágenes: {len(df)}\")\n",
        "    print(f\"Entrenamiento: {len(train_df)} imágenes ({len(train_df['Class'].unique())} clases)\")\n",
        "    print(f\"Validación: {len(val_df)} imágenes ({len(val_df['Class'].unique())} clases)\")\n",
        "    print(f\"Prueba: {len(test_df)} imágenes ({len(test_df['Class'].unique())} clases)\")\n",
        "    print(f\"CSVs guardados en: {OUTPUT_WEIGHTS_DIR}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        # Usa sample_fraction=0.05 para trabajar solo con el 5% del dataset\n",
        "        split_augmented_dataset(AUGMENTED_WEIGHTS, sample_fraction=0.30)\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {str(e)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ***Entrenamiento del modelo con imagenes augmentadas y originales***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Modelo cargado desde C:\\Users\\Arys\\Desktop\\Proyecto - 2\\models\\model_epoch_12.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Entrenando época 13/20: 100%|██████████| 12830/12830 [35:05<00:00,  6.09it/s] \n",
            "Validando: 100%|██████████| 2750/2750 [02:54<00:00, 15.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Época 13: Pérdida Entrenamiento: 0.3102, Precisión Entrenamiento: 89.52%\n",
            "Precisión Validación: 94.93%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Entrenando época 14/20: 100%|██████████| 12830/12830 [37:23<00:00,  5.72it/s] \n",
            "Validando: 100%|██████████| 2750/2750 [02:37<00:00, 17.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Época 14: Pérdida Entrenamiento: 0.3046, Precisión Entrenamiento: 89.66%\n",
            "Precisión Validación: 95.49%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Entrenando época 15/20: 100%|██████████| 12830/12830 [30:03<00:00,  7.11it/s]\n",
            "Validando: 100%|██████████| 2750/2750 [02:19<00:00, 19.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Época 15: Pérdida Entrenamiento: 0.3019, Precisión Entrenamiento: 89.77%\n",
            "Precisión Validación: 96.11%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Entrenando época 16/20: 100%|██████████| 12830/12830 [29:33<00:00,  7.23it/s] \n",
            "Validando: 100%|██████████| 2750/2750 [02:25<00:00, 18.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Época 16: Pérdida Entrenamiento: 0.2993, Precisión Entrenamiento: 89.82%\n",
            "Precisión Validación: 96.28%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Entrenando época 17/20: 100%|██████████| 12830/12830 [29:42<00:00,  7.20it/s]\n",
            "Validando: 100%|██████████| 2750/2750 [02:44<00:00, 16.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Época 17: Pérdida Entrenamiento: 0.2899, Precisión Entrenamiento: 90.07%\n",
            "Precisión Validación: 95.74%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Entrenando época 18/20: 100%|██████████| 12830/12830 [31:03<00:00,  6.89it/s]  \n",
            "Validando: 100%|██████████| 2750/2750 [02:26<00:00, 18.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Época 18: Pérdida Entrenamiento: 0.2877, Precisión Entrenamiento: 90.19%\n",
            "Precisión Validación: 95.32%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Entrenando época 19/20: 100%|██████████| 12830/12830 [28:01<00:00,  7.63it/s]\n",
            "Validando: 100%|██████████| 2750/2750 [02:27<00:00, 18.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Época 19: Pérdida Entrenamiento: 0.2851, Precisión Entrenamiento: 90.30%\n",
            "Precisión Validación: 95.44%\n",
            "Parando temprano en época 19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluando en prueba: 100%|██████████| 2750/2750 [04:07<00:00, 11.12it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "====================\n",
            "Precisión en prueba: 95.51%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "from torchvision import models, transforms\n",
        "from torchvision.models import ResNet18_Weights\n",
        "from tqdm import tqdm\n",
        "\n",
        "# =================== CONFIGURACIÓN ===================\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset_augmented\"\n",
        "WEIGHTS_DIR = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\augmented_weights\"\n",
        "TRAIN_WEIGHTS = os.path.join(WEIGHTS_DIR, \"aug_train_weights.csv\")\n",
        "VAL_WEIGHTS = os.path.join(WEIGHTS_DIR, \"aug_val_weights.csv\")\n",
        "TEST_WEIGHTS = os.path.join(WEIGHTS_DIR, \"aug_test_weights.csv\")\n",
        "MODEL_DIR = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\models\"\n",
        "os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "MODEL_PATH = os.path.join(MODEL_DIR, \"augmented_model.pth\")\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "BATCH_SIZE = 16\n",
        "NUM_WORKERS = 0\n",
        "NUM_EPOCHS = 20\n",
        "EARLY_STOP_PATIENCE = 3\n",
        "METRICS_LOG = os.path.join(MODEL_DIR, \"training_metrics.csv\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.RandomRotation(20),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "    transforms.RandomAffine(degrees=0, translate=(0.05, 0.05)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "class PlantDataset(Dataset):\n",
        "    def __init__(self, weights_df, root_dir, transform=None, class_to_idx=None):\n",
        "        self.data = weights_df\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.class_to_idx = class_to_idx\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.data.iloc[idx]\n",
        "        img_parts = row['Class'].split('_')\n",
        "        img_path = f\"{self.root_dir}/{img_parts[0]}/{img_parts[1]}/{'_'.join(img_parts[2:])}/{row['Image']}\"\n",
        "        try:\n",
        "            image = Image.open(img_path).convert('RGB')\n",
        "            if self.transform:\n",
        "                image = self.transform(image)\n",
        "            label = self.class_to_idx[row['Class']]\n",
        "            return image, label\n",
        "        except Exception as e:\n",
        "            print(f\"Error al cargar {img_path}: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "def create_dataloader(weights_path, root_dir, transform, class_to_idx, batch_size=BATCH_SIZE, use_sampler=True):\n",
        "    weights_df = pd.read_csv(weights_path)\n",
        "    dataset = PlantDataset(weights_df, root_dir, transform=transform, class_to_idx=class_to_idx)\n",
        "    sampler = WeightedRandomSampler(torch.tensor(weights_df['Weight'].values, dtype=torch.float), len(weights_df), replacement=True) if use_sampler else None\n",
        "    return DataLoader(dataset, batch_size=batch_size, sampler=sampler, shuffle=not use_sampler, num_workers=NUM_WORKERS, pin_memory=torch.cuda.is_available())\n",
        "\n",
        "def train_model(train_loader, val_loader, start_epoch=1, num_epochs=NUM_EPOCHS, early_stop_patience=EARLY_STOP_PATIENCE):\n",
        "    model = models.resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
        "    num_classes = len(train_loader.dataset.class_to_idx)\n",
        "    model.fc = nn.Sequential(nn.Dropout(0.3), nn.Linear(model.fc.in_features, num_classes))\n",
        "    model = model.to(DEVICE)\n",
        "\n",
        "    checkpoint_path = os.path.join(MODEL_DIR, f\"model_epoch_{start_epoch - 1}.pth\")\n",
        "    if os.path.exists(checkpoint_path):\n",
        "        model.load_state_dict(torch.load(checkpoint_path))\n",
        "        print(f\"Modelo cargado desde {checkpoint_path}\")\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=0.0005)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2)\n",
        "\n",
        "    best_acc = 0.0\n",
        "    epochs_without_improvement = 0\n",
        "\n",
        "    if start_epoch == 1 and os.path.exists(METRICS_LOG):\n",
        "        os.remove(METRICS_LOG)\n",
        "\n",
        "    for epoch in range(start_epoch, num_epochs + 1):\n",
        "        model.train()\n",
        "        running_loss, correct, total = 0.0, 0, 0\n",
        "\n",
        "        for images, labels in tqdm(train_loader, desc=f\"Entrenando época {epoch}/{num_epochs}\"):\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        train_loss = running_loss / len(train_loader)\n",
        "        train_acc = 100 * correct / total\n",
        "\n",
        "        model.eval()\n",
        "        val_correct, val_total = 0, 0\n",
        "        with torch.no_grad():\n",
        "            for images, labels in tqdm(val_loader, desc=\"Validando\"):\n",
        "                images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "                outputs = model(images)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                val_total += labels.size(0)\n",
        "                val_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        val_acc = 100 * val_correct / val_total\n",
        "        scheduler.step(val_acc)\n",
        "\n",
        "        print(f\"\\nÉpoca {epoch}: Pérdida Entrenamiento: {train_loss:.4f}, Precisión Entrenamiento: {train_acc:.2f}%\")\n",
        "        print(f\"Precisión Validación: {val_acc:.2f}%\")\n",
        "\n",
        "        torch.save(model.state_dict(), os.path.join(MODEL_DIR, f\"model_epoch_{epoch}.pth\"))\n",
        "        if val_acc > best_acc:\n",
        "            best_acc = val_acc\n",
        "            torch.save(model.state_dict(), MODEL_PATH)\n",
        "            epochs_without_improvement = 0\n",
        "        else:\n",
        "            epochs_without_improvement += 1\n",
        "\n",
        "        with open(METRICS_LOG, \"a\") as f:\n",
        "            if epoch == start_epoch:\n",
        "                f.write(\"Epoch,TrainLoss,TrainAcc,ValAcc\\n\")\n",
        "            f.write(f\"{epoch},{train_loss:.4f},{train_acc:.2f},{val_acc:.2f}\\n\")\n",
        "\n",
        "        if epochs_without_improvement >= early_stop_patience:\n",
        "            print(f\"Parando temprano en época {epoch}\")\n",
        "            break\n",
        "    return model\n",
        "\n",
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in tqdm(test_loader, desc=\"Evaluando en prueba\"):\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print(f\"\\n{'='*20}\\nPrecisión en prueba: {100 * correct / total:.2f}%\")\n",
        "    return 100 * correct / total\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    train_df = pd.read_csv(TRAIN_WEIGHTS)\n",
        "    class_to_idx = {cls: idx for idx, cls in enumerate(sorted(train_df['Class'].unique()))}\n",
        "\n",
        "    train_loader = create_dataloader(TRAIN_WEIGHTS, DATASET_PATH, train_transforms, class_to_idx)\n",
        "    val_loader = create_dataloader(VAL_WEIGHTS, DATASET_PATH, val_transforms, class_to_idx, use_sampler=False)\n",
        "    test_loader = create_dataloader(TEST_WEIGHTS, DATASET_PATH, val_transforms, class_to_idx, use_sampler=False)\n",
        "\n",
        "    # Cambia aquí si quieres reanudar desde cierta época\n",
        "    model = train_model(train_loader, val_loader, start_epoch=13)\n",
        "    evaluate_model(model, test_loader)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ***Predicción con cámara (modelo augmentado)***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Presiona 'q' para salir, 's' para guardar imagen.\n"
          ]
        },
        {
          "ename": "error",
          "evalue": "OpenCV(4.12.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window_w32.cpp:1261: error: (-27:Null pointer) NULL window: 'Umbral Blanco y Negro' in function 'cvDestroyWindow'\n",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31merror\u001b[39m                                     Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 122\u001b[39m\n\u001b[32m    120\u001b[39m cap.release()\n\u001b[32m    121\u001b[39m cv2.destroyAllWindows()\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m \u001b[43mcv2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdestroyWindow\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mUmbral Blanco y Negro\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "\u001b[31merror\u001b[39m: OpenCV(4.12.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window_w32.cpp:1261: error: (-27:Null pointer) NULL window: 'Umbral Blanco y Negro' in function 'cvDestroyWindow'\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models\n",
        "from torchvision.models import ResNet18_Weights\n",
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import textwrap\n",
        "\n",
        "# ================= CONFIGURACIÓN =================\n",
        "MODEL_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\models\\augmented_model.pth\"\n",
        "CLASSES_CSV = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\augmented_weights\\aug_train_weights.csv\"\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "CAPTURED_IMAGES_DIR = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\captured_images\"\n",
        "os.makedirs(CAPTURED_IMAGES_DIR, exist_ok=True)\n",
        "\n",
        "# ================ CLASES =================\n",
        "train_df = pd.read_csv(CLASSES_CSV)\n",
        "classes = sorted(train_df['Class'].unique())\n",
        "class_to_idx = {cls: idx for idx, cls in enumerate(classes)}\n",
        "idx_to_class = {idx: cls for cls, idx in class_to_idx.items()}\n",
        "\n",
        "# ================ TRANSFORMACIONES =================\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ColorJitter(brightness=0.4, contrast=0.4),  # Aumentado para manejar vistas variables\n",
        "    transforms.RandomRotation(180),  # Para manejar perspectivas (arriba/abajo)\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# ================ CARGAR MODELO =================\n",
        "model = models.resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
        "model.fc = nn.Sequential(\n",
        "    nn.Dropout(0.3),\n",
        "    nn.Linear(model.fc.in_features, len(classes))\n",
        ")\n",
        "model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
        "model = model.to(DEVICE)\n",
        "model.eval()\n",
        "\n",
        "# ================ CAPTURA DE VIDEO =================\n",
        "cap = cv2.VideoCapture(0)\n",
        "cv2.namedWindow(\"Detección en tiempo real\", cv2.WINDOW_NORMAL)\n",
        "cv2.resizeWindow(\"Detección en tiempo real\", 900, 600)\n",
        "cv2.namedWindow(\"Umbral Blanco y Negro\", cv2.WINDOW_NORMAL)\n",
        "cv2.resizeWindow(\"Umbral Blanco y Negro\", 300, 300)\n",
        "\n",
        "print(\"Presiona 'q' para salir, 's' para guardar imagen.\")\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        print(\"No se pudo capturar imagen.\")\n",
        "        break\n",
        "\n",
        "    # Detección de hoja usando color verde ampliado\n",
        "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
        "    lower_green = np.array([15, 20, 20])  # Rango más amplio para \"peach\"\n",
        "    upper_green = np.array([100, 255, 255])\n",
        "    mask = cv2.inRange(hsv, lower_green, upper_green)\n",
        "    blurred = cv2.GaussianBlur(mask, (9, 9), 0)\n",
        "    _, thresh_green = cv2.threshold(blurred, 80, 255, cv2.THRESH_BINARY)\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (9, 9))\n",
        "    cleaned = cv2.morphologyEx(thresh_green, cv2.MORPH_CLOSE, kernel, iterations=4)\n",
        "\n",
        "    # Umbral blanco y negro para depuración\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    _, thresh_bw = cv2.threshold(gray, 70, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "\n",
        "    contours, _ = cv2.findContours(cleaned, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    bbox = None\n",
        "    roi = frame\n",
        "    if contours:\n",
        "        largest_contour = max(contours, key=cv2.contourArea)\n",
        "        area = cv2.contourArea(largest_contour)\n",
        "        if area > 300:  # Reducido para detectar hojas individuales\n",
        "            x, y, w, h = cv2.boundingRect(largest_contour)\n",
        "            if w > 30 and h > 30 and w < frame.shape[1] * 0.95 and h < frame.shape[0] * 0.95:\n",
        "                cv2.drawContours(frame, [largest_contour], -1, (0, 255, 0), 2)\n",
        "                bbox = (x, y, x + w, y + h)\n",
        "                roi = frame[y:y+h, x:x+w]\n",
        "                cv2.putText(frame, f\"Área: {area:.0f}\", (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
        "\n",
        "    # Preprocesamiento y predicción\n",
        "    rgb_image = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)\n",
        "    pil_image = Image.fromarray(rgb_image)\n",
        "    input_tensor = transform(pil_image).unsqueeze(0).to(DEVICE)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_tensor)\n",
        "        probs = torch.softmax(outputs, dim=1)\n",
        "        confidence, predicted = torch.max(probs, 1)\n",
        "        label = idx_to_class[predicted.item()] if confidence.item() > 0.6 else \"Desconocido\"\n",
        "\n",
        "    # Mostrar texto\n",
        "    wrapped_text = textwrap.wrap(label, width=40)\n",
        "    y = 30\n",
        "    for line in wrapped_text:\n",
        "        cv2.putText(frame, line, (10, y), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
        "        y += 25\n",
        "    cv2.putText(frame, f\"Conf: {confidence.item()*100:.2f}%\", (10, y), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)\n",
        "\n",
        "    # Mostrar ventanas\n",
        "    cv2.imshow(\"Detección en tiempo real\", frame)\n",
        "    cv2.imshow(\"Umbral Blanco y Negro\", thresh_bw)\n",
        "\n",
        "    # Salir o guardar\n",
        "    key = cv2.waitKey(50) & 0xFF\n",
        "    if key == ord('q'):\n",
        "        break\n",
        "    elif key == ord('s') and bbox:\n",
        "        roi_pil = Image.fromarray(rgb_image)\n",
        "        save_path = os.path.join(CAPTURED_IMAGES_DIR, f\"captured_{label}_{confidence.item()*100:.2f}_{int(time.time())}.jpg\")\n",
        "        roi_pil.save(save_path)\n",
        "        print(f\"Imagen guardada: {save_path}\")\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n",
        "cv2.destroyWindow(\"Umbral Blanco y Negro\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
