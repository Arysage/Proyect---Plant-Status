{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1W2icmWWyF0b"
      },
      "source": [
        "# **Proyecto - Plant Status**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nppLtvVszXNg"
      },
      "source": [
        "Para este proyecto, se utiliz√≥ el dataset disponible en la plataforma Kaggle, espec√≠ficamente el titulado https://www.kaggle.com/datasets/abdallahalidev/plantvillage-dataset/data Este conjunto de datos contiene im√°genes de diversas plantas en diferentes estados de salud, incluyendo tanto condiciones patol√≥gicas como muestras saludables.\n",
        "\n",
        "Cabe mencionar que algunas de las clases presentes en el dataset √∫nicamente incluyen im√°genes de plantas en estado saludable. A pesar de esta limitaci√≥n, se decidi√≥ continuar trabajando con dichas clases para mantener la diversidad de especies vegetales representadas en el conjunto de datos.\n",
        "\n",
        "Posteriormente, se realiz√≥ una reorganizaci√≥n del dataset con el fin de facilitar el procesamiento y la clasificaci√≥n. Para ello, se agruparon las im√°genes seg√∫n el tipo de planta, creando una estructura de carpetas nombradas con el nombre correspondiente a cada especie. Dentro de cada una de estas carpetas se almacenaron las im√°genes clasificadas por su estado, lo que permite una manipulaci√≥n m√°s ordenada y eficiente durante el desarrollo del modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ***Configuraci√≥n del entorno y Extracci√≥n***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ***Verificaci√≥n y uso de GPU (CUDA) para el procesamiento de im√°genes***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ahora, en el siguiente fragmento de c√≥digo se realiza una verificaci√≥n del entorno para comprobar si CUDA est√° disponible. Esto nos permite utilizar la GPU personal para acelerar el procesamiento de im√°genes durante el entrenamiento del modelo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "¬øCUDA disponible?: True\n",
            "‚úÖ GPU detectada: NVIDIA GeForce RTX 3050\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "print(\"¬øCUDA disponible?:\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"‚úÖ GPU detectada:\", torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print(\"‚ùå No se detect√≥ GPU\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ***Definici√≥n y verificaci√≥n de la ruta del dataset***\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Antes de cargar las im√°genes del dataset, es fundamental asegurarse de que la ruta hacia la carpeta que contiene los datos est√© correctamente definida. En el siguiente fragmento de c√≥digo, se especifica la ruta local donde se encuentra almacenado el dataset y se verifica su existencia en el sistema. Esto permite detectar posibles errores tempranamente si la ruta es incorrecta o si los archivos no se han descargado adecuadamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "¬°El dataset se encontr√≥ en: C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Definir la ruta del dataset\n",
        "dataset_path = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "\n",
        "# Verificar que la carpeta existe\n",
        "if os.path.exists(dataset_path):\n",
        "    print(f\"¬°El dataset se encontr√≥ en: {dataset_path}!\")\n",
        "else:\n",
        "    print(f\"Error: No se encontr√≥ la carpeta en {dataset_path}. Verifica la ruta.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNanNwDC1bRz"
      },
      "source": [
        "## ***An√°lisis exploratorio***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3L5-L8Yb1tNW"
      },
      "source": [
        "### ***Estructura del dataset***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMuA6qZE_r_5"
      },
      "source": [
        "Ver con que datos o carpetas se esta trabajando a lo largo de este colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "BMRcX7GQIvG2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìÅ plantvillage dataset\n",
            "==================================================\n",
            "\n",
            "COLOR\n",
            "==================================================\n",
            "    üå± Apple\n",
            "      üçÉ Apple___Apple_scab\n",
            "      üçÉ Apple___Black_rot\n",
            "      üçÉ Apple___Cedar_apple_rust\n",
            "      üçÉ Apple___healthy\n",
            "    üå± Blueberry\n",
            "      üçÉ Blueberry___healthy\n",
            "    üå± Cherry\n",
            "      üçÉ Cherry_(including_sour)___Powdery_mildew\n",
            "      üçÉ Cherry_(including_sour)___healthy\n",
            "    üå± Corn\n",
            "      üçÉ Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot\n",
            "      üçÉ Corn_(maize)___Common_rust_\n",
            "      üçÉ Corn_(maize)___Northern_Leaf_Blight\n",
            "      üçÉ Corn_(maize)___healthy\n",
            "    üå± Grape\n",
            "      üçÉ Grape___Black_rot\n",
            "      üçÉ Grape___Esca_(Black_Measles)\n",
            "      üçÉ Grape___Leaf_blight_(Isariopsis_Leaf_Spot)\n",
            "      üçÉ Grape___healthy\n",
            "    üå± Orange\n",
            "      üçÉ Orange___Haunglongbing_(Citrus_greening)\n",
            "    üå± Peach\n",
            "      üçÉ Peach___Bacterial_spot\n",
            "      üçÉ Peach___healthy\n",
            "    üå± Pepper\n",
            "      üçÉ Pepper,_bell___Bacterial_spot\n",
            "      üçÉ Pepper,_bell___healthy\n",
            "    üå± Potato\n",
            "      üçÉ Potato___Early_blight\n",
            "      üçÉ Potato___Late_blight\n",
            "      üçÉ Potato___healthy\n",
            "    üå± Raspberry\n",
            "      üçÉ Raspberry___healthy\n",
            "    üå± Soybean\n",
            "      üçÉ Soybean___healthy\n",
            "    üå± Squash\n",
            "      üçÉ Squash___Powdery_mildew\n",
            "    üå± Strawberry\n",
            "      üçÉ Strawberry___Leaf_scorch\n",
            "      üçÉ Strawberry___healthy\n",
            "    üå± Tomato\n",
            "      üçÉ Tomato___Bacterial_spot\n",
            "      üçÉ Tomato___Early_blight\n",
            "      üçÉ Tomato___Late_blight\n",
            "      üçÉ Tomato___Leaf_Mold\n",
            "      üçÉ Tomato___Septoria_leaf_spot\n",
            "      üçÉ Tomato___Spider_mites Two-spotted_spider_mite\n",
            "      üçÉ Tomato___Target_Spot\n",
            "      üçÉ Tomato___Tomato_Yellow_Leaf_Curl_Virus\n",
            "      üçÉ Tomato___Tomato_mosaic_virus\n",
            "      üçÉ Tomato___healthy\n",
            "\n",
            "GRAYSCALE\n",
            "==================================================\n",
            "    üå± Apple\n",
            "      üçÉ Apple___Apple_scab\n",
            "      üçÉ Apple___Black_rot\n",
            "      üçÉ Apple___Cedar_apple_rust\n",
            "      üçÉ Apple___healthy\n",
            "    üå± Blueberry\n",
            "      üçÉ Blueberry___healthy\n",
            "    üå± Cherry\n",
            "      üçÉ Cherry_(including_sour)___Powdery_mildew\n",
            "      üçÉ Cherry_(including_sour)___healthy\n",
            "    üå± Corn\n",
            "      üçÉ Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot\n",
            "      üçÉ Corn_(maize)___Common_rust_\n",
            "      üçÉ Corn_(maize)___Northern_Leaf_Blight\n",
            "      üçÉ Corn_(maize)___healthy\n",
            "    üå± Grape\n",
            "      üçÉ Grape___Black_rot\n",
            "      üçÉ Grape___Esca_(Black_Measles)\n",
            "      üçÉ Grape___Leaf_blight_(Isariopsis_Leaf_Spot)\n",
            "      üçÉ Grape___healthy\n",
            "    üå± Orange\n",
            "      üçÉ Orange___Haunglongbing_(Citrus_greening)\n",
            "    üå± Peach\n",
            "      üçÉ Peach___Bacterial_spot\n",
            "      üçÉ Peach___healthy\n",
            "    üå± Pepper\n",
            "      üçÉ Pepper,_bell___Bacterial_spot\n",
            "      üçÉ Pepper,_bell___healthy\n",
            "    üå± Potato\n",
            "      üçÉ Potato___Early_blight\n",
            "      üçÉ Potato___Late_blight\n",
            "      üçÉ Potato___healthy\n",
            "    üå± Raspberry\n",
            "      üçÉ Raspberry___healthy\n",
            "    üå± Soybean\n",
            "      üçÉ Soybean___healthy\n",
            "    üå± Squash\n",
            "      üçÉ Squash___Powdery_mildew\n",
            "    üå± Strawberry\n",
            "      üçÉ Strawberry___Leaf_scorch\n",
            "      üçÉ Strawberry___healthy\n",
            "    üå± Tomato\n",
            "      üçÉ Tomato___Bacterial_spot\n",
            "      üçÉ Tomato___Early_blight\n",
            "      üçÉ Tomato___Late_blight\n",
            "      üçÉ Tomato___Leaf_Mold\n",
            "      üçÉ Tomato___Septoria_leaf_spot\n",
            "      üçÉ Tomato___Spider_mites Two-spotted_spider_mite\n",
            "      üçÉ Tomato___Target_Spot\n",
            "      üçÉ Tomato___Tomato_Yellow_Leaf_Curl_Virus\n",
            "      üçÉ Tomato___Tomato_mosaic_virus\n",
            "      üçÉ Tomato___healthy\n",
            "\n",
            "SEGMENTED\n",
            "==================================================\n",
            "    üå± Apple\n",
            "      üçÉ Apple___Apple_scab\n",
            "      üçÉ Apple___Black_rot\n",
            "      üçÉ Apple___Cedar_apple_rust\n",
            "      üçÉ Apple___healthy\n",
            "    üå± Blueberry\n",
            "      üçÉ Blueberry___healthy\n",
            "    üå± Cherry\n",
            "      üçÉ Cherry_(including_sour)___Powdery_mildew\n",
            "      üçÉ Cherry_(including_sour)___healthy\n",
            "    üå± Corn\n",
            "      üçÉ Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot\n",
            "      üçÉ Corn_(maize)___Common_rust_\n",
            "      üçÉ Corn_(maize)___Northern_Leaf_Blight\n",
            "      üçÉ Corn_(maize)___healthy\n",
            "    üå± Grape\n",
            "      üçÉ Grape___Black_rot\n",
            "      üçÉ Grape___Esca_(Black_Measles)\n",
            "      üçÉ Grape___Leaf_blight_(Isariopsis_Leaf_Spot)\n",
            "      üçÉ Grape___healthy\n",
            "    üå± Orange\n",
            "      üçÉ Orange___Haunglongbing_(Citrus_greening)\n",
            "    üå± Peach\n",
            "      üçÉ Peach___Bacterial_spot\n",
            "      üçÉ Peach___healthy\n",
            "    üå± Pepper\n",
            "      üçÉ Pepper,_bell___Bacterial_spot\n",
            "      üçÉ Pepper,_bell___healthy\n",
            "    üå± Potato\n",
            "      üçÉ Potato___Early_blight\n",
            "      üçÉ Potato___Late_blight\n",
            "      üçÉ Potato___healthy\n",
            "    üå± Raspberry\n",
            "      üçÉ Raspberry___healthy\n",
            "    üå± Soybean\n",
            "      üçÉ Soybean___healthy\n",
            "    üå± Squash\n",
            "      üçÉ Squash___Powdery_mildew\n",
            "    üå± Strawberry\n",
            "      üçÉ Strawberry___Leaf_scorch\n",
            "      üçÉ Strawberry___healthy\n",
            "    üå± Tomato\n",
            "      üçÉ Tomato___Bacterial_spot\n",
            "      üçÉ Tomato___Early_blight\n",
            "      üçÉ Tomato___Late_blight\n",
            "      üçÉ Tomato___Leaf_Mold\n",
            "      üçÉ Tomato___Septoria_leaf_spot\n",
            "      üçÉ Tomato___Spider_mites Two-spotted_spider_mite\n",
            "      üçÉ Tomato___Target_Spot\n",
            "      üçÉ Tomato___Tomato_Yellow_Leaf_Curl_Virus\n",
            "      üçÉ Tomato___Tomato_mosaic_virus\n",
            "      üçÉ Tomato___healthy\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Ruta del dataset local\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "\n",
        "def list_folders_clean(directory):\n",
        "    # Verificar que la carpeta existe\n",
        "    if not os.path.exists(directory):\n",
        "        print(f\"Error: No se encontr√≥ la carpeta en {directory}.\")\n",
        "        return\n",
        "    \n",
        "    visited = set()\n",
        "    folders_by_origin = {\"color\": [], \"grayscale\": [], \"segmented\": []}\n",
        "    \n",
        "    # Recorrer el directorio\n",
        "    for root, dirs, _ in os.walk(directory):\n",
        "        depth = root[len(directory):].count(os.sep)\n",
        "        folder_name = os.path.basename(root)\n",
        "        if root == directory:\n",
        "            folder_name = \"plantvillage dataset\"\n",
        "        \n",
        "        full_path = os.path.normpath(os.path.join(root))\n",
        "        if full_path not in visited and depth >= 1:\n",
        "            visited.add(full_path)\n",
        "            \n",
        "            # Determinar el tipo (color, grayscale, segmented)\n",
        "            origin = \"\"\n",
        "            parent_path = os.path.dirname(root)\n",
        "            parent_name = os.path.basename(parent_path)\n",
        "            if depth == 1:\n",
        "                origin = folder_name\n",
        "            elif depth >= 2 and parent_name in [\"color\", \"grayscale\", \"segmented\"]:\n",
        "                origin = parent_name\n",
        "            elif depth >= 2:\n",
        "                grandparent_path = os.path.dirname(parent_path)\n",
        "                grandparent_name = os.path.basename(grandparent_path)\n",
        "                if grandparent_name in [\"color\", \"grayscale\", \"segmented\"]:\n",
        "                    origin = grandparent_name\n",
        "            \n",
        "            # Guardar carpetas de nivel 2 o mayor\n",
        "            if depth >= 2 and origin:\n",
        "                is_simple = \"___\" not in folder_name\n",
        "                folders_by_origin[origin].append((depth, folder_name, is_simple))\n",
        "    \n",
        "    # Imprimir carpeta ra√≠z\n",
        "    print(f\"üìÅ plantvillage dataset\")\n",
        "    print(f\"{'=' * 50}\")\n",
        "    \n",
        "    # Imprimir carpetas por tipo\n",
        "    for origin in [\"color\", \"grayscale\", \"segmented\"]:\n",
        "        if folders_by_origin[origin]:\n",
        "            print(f\"\\n{origin.upper()}\")\n",
        "            print(f\"{'=' * 50}\")\n",
        "            for depth, folder_name, is_simple in sorted(folders_by_origin[origin], key=lambda x: x[1]):\n",
        "                indent = \"  \" * (depth - 1)\n",
        "                icon = \"üå±\" if is_simple else \"üçÉ\"\n",
        "                print(f\"{indent}{icon} {folder_name}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    list_folders_clean(DATASET_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "El dataset PlantVillage contiene im√°genes de m√∫ltiples especies de plantas en tres formatos: color, escala de grises y segmentado. Cada especie incluye diferentes estados, que abarcan desde plantas saludables hasta diversas enfermedades comunes.\n",
        "\n",
        "Este conjunto de datos ofrece una amplia variedad de condiciones para el entrenamiento y evaluaci√≥n de modelos de clasificaci√≥n y diagn√≥stico de enfermedades en plantas, lo que lo convierte en un recurso valioso para proyectos de aprendizaje autom√°tico en agricultura."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KZITuhg16f_"
      },
      "source": [
        "### ***Formato o extension de las imagenes***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TtC0m_hq_vzK"
      },
      "source": [
        "Se verific√≥ la extensi√≥n de las im√°genes en el dataset y, para nuestro trabajo, se utilizar√°n √∫nicamente las im√°genes con extensi√≥n .jpg."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "nOrKmLSk1k-a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============================\n",
            "Extensiones de Im√°genes\n",
            "==============================\n",
            "Extensi√≥n      Conteo\n",
            "----------------------\n",
            ".jpg           162916\n",
            "\n",
            "Total archivos: 162916\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from collections import defaultdict\n",
        "\n",
        "# Ruta del dataset local\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "\n",
        "def analyze_image_extensions(directory):\n",
        "    # Verificar que la carpeta existe\n",
        "    if not os.path.exists(directory):\n",
        "        print(f\"Error: No se encontr√≥ la carpeta en {directory}.\")\n",
        "        return\n",
        "    \n",
        "    # Almacenar conteo de extensiones\n",
        "    ext_counts = defaultdict(int)\n",
        "    total_files = 0\n",
        "    file_extensions = ('.jpg', '.jpeg', '.png', '.bmp', '.gif')\n",
        "    \n",
        "    # Recorrer el directorio\n",
        "    for root, _, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            ext = os.path.splitext(file)[1].lower()\n",
        "            if ext in file_extensions:\n",
        "                ext_counts[ext] += 1\n",
        "                total_files += 1\n",
        "    \n",
        "    # Imprimir resumen\n",
        "    print(f\"{'=' * 30}\")\n",
        "    print(\"Extensiones de Im√°genes\")\n",
        "    print(f\"{'=' * 30}\")\n",
        "    print(f\"{'Extensi√≥n':<10} {'Conteo':>10}\")\n",
        "    print(\"-\" * 22)\n",
        "    for ext in sorted(ext_counts):\n",
        "        print(f\"{ext:<10} {ext_counts[ext]:>10}\")\n",
        "    print(f\"\\nTotal archivos: {total_files}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    analyze_image_extensions(DATASET_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lpYsjGa0DEa"
      },
      "source": [
        "Se encontr√≥ la siguiente distribuci√≥n de extensiones en las im√°genes del dataset:\n",
        "\n",
        "* Archivos con extensi√≥n .jpeg: 2\n",
        "\n",
        "* Archivos con extensi√≥n .jpg: 162,912\n",
        "\n",
        "* Archivos con extensi√≥n .png: 2\n",
        "\n",
        "En total, el dataset contiene 162,916 archivos de imagen.\n",
        "\n",
        "Dado que la gran mayor√≠a de las im√°genes utilizan la extensi√≥n .jpg, se requerir√° unificar todas las extensiones al formato .jpg para facilitar el procesamiento, estandarizaci√≥n y evitar errores por incompatibilidades en la lectura o filtrado por extensi√≥n."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAe8jAnq2oY8"
      },
      "source": [
        "### ***Resoluci√≥nes dentro del dataset por planta y tipo de Imagen***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Utilizaremos CUDA para procesar las im√°genes directamente en nuestra tarjeta gr√°fica.\n",
        "A continuaci√≥n, se muestra un ejemplo de c√≥digo para verificar que CUDA est√© funcionando correctamente:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CUDA version: 12090\n",
            "GPU devices: 1\n"
          ]
        }
      ],
      "source": [
        "import cupy as cp\n",
        "print(f\"CUDA version: {cp.cuda.runtime.runtimeGetVersion()}\")\n",
        "print(f\"GPU devices: {cp.cuda.runtime.getDeviceCount()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ahora analizaremos las dimensiones de las im√°genes por cada carpeta (color, grayscale, y segmented) y por cada planta dentro del dataset.\n",
        "Debido a posibles cuellos de botella en el procesamiento, este an√°lisis se realizar√° planta por planta y carpeta por carpeta, de forma secuencial. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "***Conclusi√≥n del an√°lisis de dimensiones de las im√°genes***\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Durante el an√°lisis del dataset, se detectaron dimensiones distintas a 256 x 256, particularmente en la carpeta segmented de las plantas Peach, Strawberry y Potato.\n",
        "\n",
        "Sin embargo, para asegurar la compatibilidad con el modelo a utilizar ‚ÄîResNet, el cual requiere entradas de 224 x 224 p√≠xeles‚Äî, ser√° necesario redimensionar todas las im√°genes a 224 x 224, sin importar su dimensi√≥n original.\n",
        "\n",
        "Esta transformaci√≥n garantiza una entrada homog√©nea al modelo, evitando errores durante la etapa de entrenamiento o inferencia."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### ***Color***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ***Apple***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Procesando im√°genes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3171/3171 [00:01<00:00, 3091.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============================\n",
            "Dimensiones de Im√°genes (Apple - COLOR)\n",
            "==============================\n",
            "Dimensi√≥n           Conteo\n",
            "---------------------------\n",
            "256x256               3171\n",
            "\n",
            "Total im√°genes procesadas: 3171\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import cupy as cp\n",
        "import numpy as np\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ruta del dataset local\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "# Nombre de la planta a procesar\n",
        "PLANT_NAME = \"Apple\"\n",
        "# Categor√≠a a procesar\n",
        "CATEGORY = \"color\"\n",
        "# N√∫mero de hilos para paralelizaci√≥n\n",
        "MAX_WORKERS = 16\n",
        "\n",
        "def collect_image_paths(directory):\n",
        "    file_paths = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        if PLANT_NAME in root:\n",
        "            for file in files:\n",
        "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    file_paths.append(os.path.join(root, file))\n",
        "    return file_paths\n",
        "\n",
        "def process_image(file_path):\n",
        "    try:\n",
        "        with Image.open(file_path) as img:\n",
        "            return (img.size[0], img.size[1])\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def analyze_plant_dimensions():\n",
        "    category_path = os.path.join(DATASET_PATH, CATEGORY, PLANT_NAME)\n",
        "    if not os.path.exists(category_path):\n",
        "        print(f\"Error: No se encontr√≥ la carpeta {category_path}.\")\n",
        "        return None, None, 0\n",
        "    \n",
        "    file_paths = collect_image_paths(category_path)\n",
        "    dimensions = []\n",
        "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "        # Usar tqdm para mostrar progreso\n",
        "        with tqdm(total=len(file_paths), desc=\"Procesando im√°genes\") as pbar:\n",
        "            for dim in executor.map(process_image, file_paths):\n",
        "                if dim is not None:\n",
        "                    dimensions.append(dim)\n",
        "                pbar.update(1)\n",
        "    \n",
        "    try:\n",
        "        dim_array = cp.array(dimensions, dtype=cp.int32)\n",
        "        unique_dims, counts = np.unique(dim_array.get(), axis=0, return_counts=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error en el c√°lculo de dimensiones: {e}\")\n",
        "        return None, None, len(dimensions)\n",
        "    \n",
        "    return unique_dims, counts, len(dimensions)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unique_dims, counts, total_dims = analyze_plant_dimensions()\n",
        "    if unique_dims is not None and counts is not None:\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"Dimensiones de Im√°genes ({PLANT_NAME} - {CATEGORY.upper()})\")\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"{'Dimensi√≥n':<15} {'Conteo':>10}\")\n",
        "        print(\"-\" * 27)\n",
        "        for dim, count in zip(unique_dims, counts):\n",
        "            print(f\"{f'{dim[0]}x{dim[1]}':<15} {count:>10}\")\n",
        "        print(f\"\\nTotal im√°genes procesadas: {total_dims}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ***Blueberry***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Procesando im√°genes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1502/1502 [00:00<00:00, 5103.20it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============================\n",
            "Dimensiones de Im√°genes (Blueberry - COLOR)\n",
            "==============================\n",
            "Dimensi√≥n           Conteo\n",
            "---------------------------\n",
            "256x256               1502\n",
            "\n",
            "Total im√°genes procesadas: 1502\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import cupy as cp\n",
        "import numpy as np\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ruta del dataset local\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "# Nombre de la planta a procesar\n",
        "PLANT_NAME = \"Blueberry\"\n",
        "# Categor√≠a a procesar\n",
        "CATEGORY = \"color\"\n",
        "# N√∫mero de hilos para paralelizaci√≥n\n",
        "MAX_WORKERS = 16\n",
        "\n",
        "def collect_image_paths(directory):\n",
        "    file_paths = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        if PLANT_NAME in root:\n",
        "            for file in files:\n",
        "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    file_paths.append(os.path.join(root, file))\n",
        "    return file_paths\n",
        "\n",
        "def process_image(file_path):\n",
        "    try:\n",
        "        with Image.open(file_path) as img:\n",
        "            return (img.size[0], img.size[1])\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def analyze_plant_dimensions():\n",
        "    category_path = os.path.join(DATASET_PATH, CATEGORY, PLANT_NAME)\n",
        "    if not os.path.exists(category_path):\n",
        "        print(f\"Error: No se encontr√≥ la carpeta {category_path}.\")\n",
        "        return None, None, 0\n",
        "    \n",
        "    file_paths = collect_image_paths(category_path)\n",
        "    dimensions = []\n",
        "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "        # Usar tqdm para mostrar progreso\n",
        "        with tqdm(total=len(file_paths), desc=\"Procesando im√°genes\") as pbar:\n",
        "            for dim in executor.map(process_image, file_paths):\n",
        "                if dim is not None:\n",
        "                    dimensions.append(dim)\n",
        "                pbar.update(1)\n",
        "    \n",
        "    try:\n",
        "        dim_array = cp.array(dimensions, dtype=cp.int32)\n",
        "        unique_dims, counts = np.unique(dim_array.get(), axis=0, return_counts=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error en el c√°lculo de dimensiones: {e}\")\n",
        "        return None, None, len(dimensions)\n",
        "    \n",
        "    return unique_dims, counts, len(dimensions)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unique_dims, counts, total_dims = analyze_plant_dimensions()\n",
        "    if unique_dims is not None and counts is not None:\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"Dimensiones de Im√°genes ({PLANT_NAME} - {CATEGORY.upper()})\")\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"{'Dimensi√≥n':<15} {'Conteo':>10}\")\n",
        "        print(\"-\" * 27)\n",
        "        for dim, count in zip(unique_dims, counts):\n",
        "            print(f\"{f'{dim[0]}x{dim[1]}':<15} {count:>10}\")\n",
        "        print(f\"\\nTotal im√°genes procesadas: {total_dims}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ***Cherry***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Procesando im√°genes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1906/1906 [00:00<00:00, 4925.06it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============================\n",
            "Dimensiones de Im√°genes (Cherry - COLOR)\n",
            "==============================\n",
            "Dimensi√≥n           Conteo\n",
            "---------------------------\n",
            "256x256               1906\n",
            "\n",
            "Total im√°genes procesadas: 1906\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import cupy as cp\n",
        "import numpy as np\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ruta del dataset local\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "# Nombre de la planta a procesar\n",
        "PLANT_NAME = \"Cherry\"\n",
        "# Categor√≠a a procesar\n",
        "CATEGORY = \"color\"\n",
        "# N√∫mero de hilos para paralelizaci√≥n\n",
        "MAX_WORKERS = 16\n",
        "\n",
        "def collect_image_paths(directory):\n",
        "    file_paths = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        if PLANT_NAME in root:\n",
        "            for file in files:\n",
        "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    file_paths.append(os.path.join(root, file))\n",
        "    return file_paths\n",
        "\n",
        "def process_image(file_path):\n",
        "    try:\n",
        "        with Image.open(file_path) as img:\n",
        "            return (img.size[0], img.size[1])\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def analyze_plant_dimensions():\n",
        "    category_path = os.path.join(DATASET_PATH, CATEGORY, PLANT_NAME)\n",
        "    if not os.path.exists(category_path):\n",
        "        print(f\"Error: No se encontr√≥ la carpeta {category_path}.\")\n",
        "        return None, None, 0\n",
        "    \n",
        "    file_paths = collect_image_paths(category_path)\n",
        "    dimensions = []\n",
        "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "        # Usar tqdm para mostrar progreso\n",
        "        with tqdm(total=len(file_paths), desc=\"Procesando im√°genes\") as pbar:\n",
        "            for dim in executor.map(process_image, file_paths):\n",
        "                if dim is not None:\n",
        "                    dimensions.append(dim)\n",
        "                pbar.update(1)\n",
        "    \n",
        "    try:\n",
        "        dim_array = cp.array(dimensions, dtype=cp.int32)\n",
        "        unique_dims, counts = np.unique(dim_array.get(), axis=0, return_counts=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error en el c√°lculo de dimensiones: {e}\")\n",
        "        return None, None, len(dimensions)\n",
        "    \n",
        "    return unique_dims, counts, len(dimensions)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unique_dims, counts, total_dims = analyze_plant_dimensions()\n",
        "    if unique_dims is not None and counts is not None:\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"Dimensiones de Im√°genes ({PLANT_NAME} - {CATEGORY.upper()})\")\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"{'Dimensi√≥n':<15} {'Conteo':>10}\")\n",
        "        print(\"-\" * 27)\n",
        "        for dim, count in zip(unique_dims, counts):\n",
        "            print(f\"{f'{dim[0]}x{dim[1]}':<15} {count:>10}\")\n",
        "        print(f\"\\nTotal im√°genes procesadas: {total_dims}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ***Corn***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Procesando im√°genes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3852/3852 [00:00<00:00, 4767.34it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============================\n",
            "Dimensiones de Im√°genes (Corn - COLOR)\n",
            "==============================\n",
            "Dimensi√≥n           Conteo\n",
            "---------------------------\n",
            "256x256               3852\n",
            "\n",
            "Total im√°genes procesadas: 3852\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import cupy as cp\n",
        "import numpy as np\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ruta del dataset local\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "# Nombre de la planta a procesar\n",
        "PLANT_NAME = \"Corn\"\n",
        "# Categor√≠a a procesar\n",
        "CATEGORY = \"color\"\n",
        "# N√∫mero de hilos para paralelizaci√≥n\n",
        "MAX_WORKERS = 16\n",
        "\n",
        "def collect_image_paths(directory):\n",
        "    file_paths = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        if PLANT_NAME in root:\n",
        "            for file in files:\n",
        "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    file_paths.append(os.path.join(root, file))\n",
        "    return file_paths\n",
        "\n",
        "def process_image(file_path):\n",
        "    try:\n",
        "        with Image.open(file_path) as img:\n",
        "            return (img.size[0], img.size[1])\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def analyze_plant_dimensions():\n",
        "    category_path = os.path.join(DATASET_PATH, CATEGORY, PLANT_NAME)\n",
        "    if not os.path.exists(category_path):\n",
        "        print(f\"Error: No se encontr√≥ la carpeta {category_path}.\")\n",
        "        return None, None, 0\n",
        "    \n",
        "    file_paths = collect_image_paths(category_path)\n",
        "    dimensions = []\n",
        "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "        # Usar tqdm para mostrar progreso\n",
        "        with tqdm(total=len(file_paths), desc=\"Procesando im√°genes\") as pbar:\n",
        "            for dim in executor.map(process_image, file_paths):\n",
        "                if dim is not None:\n",
        "                    dimensions.append(dim)\n",
        "                pbar.update(1)\n",
        "    \n",
        "    try:\n",
        "        dim_array = cp.array(dimensions, dtype=cp.int32)\n",
        "        unique_dims, counts = np.unique(dim_array.get(), axis=0, return_counts=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error en el c√°lculo de dimensiones: {e}\")\n",
        "        return None, None, len(dimensions)\n",
        "    \n",
        "    return unique_dims, counts, len(dimensions)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unique_dims, counts, total_dims = analyze_plant_dimensions()\n",
        "    if unique_dims is not None and counts is not None:\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"Dimensiones de Im√°genes ({PLANT_NAME} - {CATEGORY.upper()})\")\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"{'Dimensi√≥n':<15} {'Conteo':>10}\")\n",
        "        print(\"-\" * 27)\n",
        "        for dim, count in zip(unique_dims, counts):\n",
        "            print(f\"{f'{dim[0]}x{dim[1]}':<15} {count:>10}\")\n",
        "        print(f\"\\nTotal im√°genes procesadas: {total_dims}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ***Grape***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Procesando im√°genes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4062/4062 [00:00<00:00, 4864.67it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============================\n",
            "Dimensiones de Im√°genes (Grape - COLOR)\n",
            "==============================\n",
            "Dimensi√≥n           Conteo\n",
            "---------------------------\n",
            "256x256               4062\n",
            "\n",
            "Total im√°genes procesadas: 4062\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import cupy as cp\n",
        "import numpy as np\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ruta del dataset local\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "# Nombre de la planta a procesar\n",
        "PLANT_NAME = \"Grape\"\n",
        "# Categor√≠a a procesar\n",
        "CATEGORY = \"color\"\n",
        "# N√∫mero de hilos para paralelizaci√≥n\n",
        "MAX_WORKERS = 16\n",
        "\n",
        "def collect_image_paths(directory):\n",
        "    file_paths = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        if PLANT_NAME in root:\n",
        "            for file in files:\n",
        "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    file_paths.append(os.path.join(root, file))\n",
        "    return file_paths\n",
        "\n",
        "def process_image(file_path):\n",
        "    try:\n",
        "        with Image.open(file_path) as img:\n",
        "            return (img.size[0], img.size[1])\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def analyze_plant_dimensions():\n",
        "    category_path = os.path.join(DATASET_PATH, CATEGORY, PLANT_NAME)\n",
        "    if not os.path.exists(category_path):\n",
        "        print(f\"Error: No se encontr√≥ la carpeta {category_path}.\")\n",
        "        return None, None, 0\n",
        "    \n",
        "    file_paths = collect_image_paths(category_path)\n",
        "    dimensions = []\n",
        "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "        # Usar tqdm para mostrar progreso\n",
        "        with tqdm(total=len(file_paths), desc=\"Procesando im√°genes\") as pbar:\n",
        "            for dim in executor.map(process_image, file_paths):\n",
        "                if dim is not None:\n",
        "                    dimensions.append(dim)\n",
        "                pbar.update(1)\n",
        "    \n",
        "    try:\n",
        "        dim_array = cp.array(dimensions, dtype=cp.int32)\n",
        "        unique_dims, counts = np.unique(dim_array.get(), axis=0, return_counts=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error en el c√°lculo de dimensiones: {e}\")\n",
        "        return None, None, len(dimensions)\n",
        "    \n",
        "    return unique_dims, counts, len(dimensions)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unique_dims, counts, total_dims = analyze_plant_dimensions()\n",
        "    if unique_dims is not None and counts is not None:\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"Dimensiones de Im√°genes ({PLANT_NAME} - {CATEGORY.upper()})\")\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"{'Dimensi√≥n':<15} {'Conteo':>10}\")\n",
        "        print(\"-\" * 27)\n",
        "        for dim, count in zip(unique_dims, counts):\n",
        "            print(f\"{f'{dim[0]}x{dim[1]}':<15} {count:>10}\")\n",
        "        print(f\"\\nTotal im√°genes procesadas: {total_dims}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ***Orange***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Procesando im√°genes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5507/5507 [00:01<00:00, 3979.02it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============================\n",
            "Dimensiones de Im√°genes (Orange - COLOR)\n",
            "==============================\n",
            "Dimensi√≥n           Conteo\n",
            "---------------------------\n",
            "256x256               5507\n",
            "\n",
            "Total im√°genes procesadas: 5507\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import cupy as cp\n",
        "import numpy as np\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ruta del dataset local\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "# Nombre de la planta a procesar\n",
        "PLANT_NAME = \"Orange\"\n",
        "# Categor√≠a a procesar\n",
        "CATEGORY = \"color\"\n",
        "# N√∫mero de hilos para paralelizaci√≥n\n",
        "MAX_WORKERS = 16\n",
        "\n",
        "def collect_image_paths(directory):\n",
        "    file_paths = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        if PLANT_NAME in root:\n",
        "            for file in files:\n",
        "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    file_paths.append(os.path.join(root, file))\n",
        "    return file_paths\n",
        "\n",
        "def process_image(file_path):\n",
        "    try:\n",
        "        with Image.open(file_path) as img:\n",
        "            return (img.size[0], img.size[1])\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def analyze_plant_dimensions():\n",
        "    category_path = os.path.join(DATASET_PATH, CATEGORY, PLANT_NAME)\n",
        "    if not os.path.exists(category_path):\n",
        "        print(f\"Error: No se encontr√≥ la carpeta {category_path}.\")\n",
        "        return None, None, 0\n",
        "    \n",
        "    file_paths = collect_image_paths(category_path)\n",
        "    dimensions = []\n",
        "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "        # Usar tqdm para mostrar progreso\n",
        "        with tqdm(total=len(file_paths), desc=\"Procesando im√°genes\") as pbar:\n",
        "            for dim in executor.map(process_image, file_paths):\n",
        "                if dim is not None:\n",
        "                    dimensions.append(dim)\n",
        "                pbar.update(1)\n",
        "    \n",
        "    try:\n",
        "        dim_array = cp.array(dimensions, dtype=cp.int32)\n",
        "        unique_dims, counts = np.unique(dim_array.get(), axis=0, return_counts=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error en el c√°lculo de dimensiones: {e}\")\n",
        "        return None, None, len(dimensions)\n",
        "    \n",
        "    return unique_dims, counts, len(dimensions)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unique_dims, counts, total_dims = analyze_plant_dimensions()\n",
        "    if unique_dims is not None and counts is not None:\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"Dimensiones de Im√°genes ({PLANT_NAME} - {CATEGORY.upper()})\")\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"{'Dimensi√≥n':<15} {'Conteo':>10}\")\n",
        "        print(\"-\" * 27)\n",
        "        for dim, count in zip(unique_dims, counts):\n",
        "            print(f\"{f'{dim[0]}x{dim[1]}':<15} {count:>10}\")\n",
        "        print(f\"\\nTotal im√°genes procesadas: {total_dims}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ***Peach***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Procesando im√°genes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2657/2657 [00:00<00:00, 4653.24it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============================\n",
            "Dimensiones de Im√°genes (Peach - COLOR)\n",
            "==============================\n",
            "Dimensi√≥n           Conteo\n",
            "---------------------------\n",
            "256x256               2657\n",
            "\n",
            "Total im√°genes procesadas: 2657\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import cupy as cp\n",
        "import numpy as np\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ruta del dataset local\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "# Nombre de la planta a procesar\n",
        "PLANT_NAME = \"Peach\"\n",
        "# Categor√≠a a procesar\n",
        "CATEGORY = \"color\"\n",
        "# N√∫mero de hilos para paralelizaci√≥n\n",
        "MAX_WORKERS = 16\n",
        "\n",
        "def collect_image_paths(directory):\n",
        "    file_paths = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        if PLANT_NAME in root:\n",
        "            for file in files:\n",
        "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    file_paths.append(os.path.join(root, file))\n",
        "    return file_paths\n",
        "\n",
        "def process_image(file_path):\n",
        "    try:\n",
        "        with Image.open(file_path) as img:\n",
        "            return (img.size[0], img.size[1])\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def analyze_plant_dimensions():\n",
        "    category_path = os.path.join(DATASET_PATH, CATEGORY, PLANT_NAME)\n",
        "    if not os.path.exists(category_path):\n",
        "        print(f\"Error: No se encontr√≥ la carpeta {category_path}.\")\n",
        "        return None, None, 0\n",
        "    \n",
        "    file_paths = collect_image_paths(category_path)\n",
        "    dimensions = []\n",
        "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "        # Usar tqdm para mostrar progreso\n",
        "        with tqdm(total=len(file_paths), desc=\"Procesando im√°genes\") as pbar:\n",
        "            for dim in executor.map(process_image, file_paths):\n",
        "                if dim is not None:\n",
        "                    dimensions.append(dim)\n",
        "                pbar.update(1)\n",
        "    \n",
        "    try:\n",
        "        dim_array = cp.array(dimensions, dtype=cp.int32)\n",
        "        unique_dims, counts = np.unique(dim_array.get(), axis=0, return_counts=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error en el c√°lculo de dimensiones: {e}\")\n",
        "        return None, None, len(dimensions)\n",
        "    \n",
        "    return unique_dims, counts, len(dimensions)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unique_dims, counts, total_dims = analyze_plant_dimensions()\n",
        "    if unique_dims is not None and counts is not None:\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"Dimensiones de Im√°genes ({PLANT_NAME} - {CATEGORY.upper()})\")\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"{'Dimensi√≥n':<15} {'Conteo':>10}\")\n",
        "        print(\"-\" * 27)\n",
        "        for dim, count in zip(unique_dims, counts):\n",
        "            print(f\"{f'{dim[0]}x{dim[1]}':<15} {count:>10}\")\n",
        "        print(f\"\\nTotal im√°genes procesadas: {total_dims}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ***Pepper***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Procesando im√°genes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2475/2475 [00:00<00:00, 5195.23it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============================\n",
            "Dimensiones de Im√°genes (Pepper - COLOR)\n",
            "==============================\n",
            "Dimensi√≥n           Conteo\n",
            "---------------------------\n",
            "256x256               2475\n",
            "\n",
            "Total im√°genes procesadas: 2475\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import cupy as cp\n",
        "import numpy as np\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ruta del dataset local\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "# Nombre de la planta a procesar\n",
        "PLANT_NAME = \"Pepper\"\n",
        "# Categor√≠a a procesar\n",
        "CATEGORY = \"color\"\n",
        "# N√∫mero de hilos para paralelizaci√≥n\n",
        "MAX_WORKERS = 16\n",
        "\n",
        "def collect_image_paths(directory):\n",
        "    file_paths = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        if PLANT_NAME in root:\n",
        "            for file in files:\n",
        "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    file_paths.append(os.path.join(root, file))\n",
        "    return file_paths\n",
        "\n",
        "def process_image(file_path):\n",
        "    try:\n",
        "        with Image.open(file_path) as img:\n",
        "            return (img.size[0], img.size[1])\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def analyze_plant_dimensions():\n",
        "    category_path = os.path.join(DATASET_PATH, CATEGORY, PLANT_NAME)\n",
        "    if not os.path.exists(category_path):\n",
        "        print(f\"Error: No se encontr√≥ la carpeta {category_path}.\")\n",
        "        return None, None, 0\n",
        "    \n",
        "    file_paths = collect_image_paths(category_path)\n",
        "    dimensions = []\n",
        "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "        # Usar tqdm para mostrar progreso\n",
        "        with tqdm(total=len(file_paths), desc=\"Procesando im√°genes\") as pbar:\n",
        "            for dim in executor.map(process_image, file_paths):\n",
        "                if dim is not None:\n",
        "                    dimensions.append(dim)\n",
        "                pbar.update(1)\n",
        "    \n",
        "    try:\n",
        "        dim_array = cp.array(dimensions, dtype=cp.int32)\n",
        "        unique_dims, counts = np.unique(dim_array.get(), axis=0, return_counts=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error en el c√°lculo de dimensiones: {e}\")\n",
        "        return None, None, len(dimensions)\n",
        "    \n",
        "    return unique_dims, counts, len(dimensions)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unique_dims, counts, total_dims = analyze_plant_dimensions()\n",
        "    if unique_dims is not None and counts is not None:\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"Dimensiones de Im√°genes ({PLANT_NAME} - {CATEGORY.upper()})\")\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"{'Dimensi√≥n':<15} {'Conteo':>10}\")\n",
        "        print(\"-\" * 27)\n",
        "        for dim, count in zip(unique_dims, counts):\n",
        "            print(f\"{f'{dim[0]}x{dim[1]}':<15} {count:>10}\")\n",
        "        print(f\"\\nTotal im√°genes procesadas: {total_dims}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ***Potato***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Procesando im√°genes:   0%|          | 0/2152 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Procesando im√°genes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2152/2152 [00:00<00:00, 4981.51it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============================\n",
            "Dimensiones de Im√°genes (Potato - COLOR)\n",
            "==============================\n",
            "Dimensi√≥n           Conteo\n",
            "---------------------------\n",
            "256x256               2152\n",
            "\n",
            "Total im√°genes procesadas: 2152\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import cupy as cp\n",
        "import numpy as np\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ruta del dataset local\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "# Nombre de la planta a procesar\n",
        "PLANT_NAME = \"Potato\"\n",
        "# Categor√≠a a procesar\n",
        "CATEGORY = \"color\"\n",
        "# N√∫mero de hilos para paralelizaci√≥n\n",
        "MAX_WORKERS = 16\n",
        "\n",
        "def collect_image_paths(directory):\n",
        "    file_paths = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        if PLANT_NAME in root:\n",
        "            for file in files:\n",
        "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    file_paths.append(os.path.join(root, file))\n",
        "    return file_paths\n",
        "\n",
        "def process_image(file_path):\n",
        "    try:\n",
        "        with Image.open(file_path) as img:\n",
        "            return (img.size[0], img.size[1])\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def analyze_plant_dimensions():\n",
        "    category_path = os.path.join(DATASET_PATH, CATEGORY, PLANT_NAME)\n",
        "    if not os.path.exists(category_path):\n",
        "        print(f\"Error: No se encontr√≥ la carpeta {category_path}.\")\n",
        "        return None, None, 0\n",
        "    \n",
        "    file_paths = collect_image_paths(category_path)\n",
        "    dimensions = []\n",
        "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "        # Usar tqdm para mostrar progreso\n",
        "        with tqdm(total=len(file_paths), desc=\"Procesando im√°genes\") as pbar:\n",
        "            for dim in executor.map(process_image, file_paths):\n",
        "                if dim is not None:\n",
        "                    dimensions.append(dim)\n",
        "                pbar.update(1)\n",
        "    \n",
        "    try:\n",
        "        dim_array = cp.array(dimensions, dtype=cp.int32)\n",
        "        unique_dims, counts = np.unique(dim_array.get(), axis=0, return_counts=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error en el c√°lculo de dimensiones: {e}\")\n",
        "        return None, None, len(dimensions)\n",
        "    \n",
        "    return unique_dims, counts, len(dimensions)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unique_dims, counts, total_dims = analyze_plant_dimensions()\n",
        "    if unique_dims is not None and counts is not None:\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"Dimensiones de Im√°genes ({PLANT_NAME} - {CATEGORY.upper()})\")\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"{'Dimensi√≥n':<15} {'Conteo':>10}\")\n",
        "        print(\"-\" * 27)\n",
        "        for dim, count in zip(unique_dims, counts):\n",
        "            print(f\"{f'{dim[0]}x{dim[1]}':<15} {count:>10}\")\n",
        "        print(f\"\\nTotal im√°genes procesadas: {total_dims}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ***Raspberry***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Procesando im√°genes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 371/371 [00:00<00:00, 4818.16it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============================\n",
            "Dimensiones de Im√°genes (Raspberry - COLOR)\n",
            "==============================\n",
            "Dimensi√≥n           Conteo\n",
            "---------------------------\n",
            "256x256                371\n",
            "\n",
            "Total im√°genes procesadas: 371\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import cupy as cp\n",
        "import numpy as np\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ruta del dataset local\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "# Nombre de la planta a procesar\n",
        "PLANT_NAME = \"Raspberry\"\n",
        "# Categor√≠a a procesar\n",
        "CATEGORY = \"color\"\n",
        "# N√∫mero de hilos para paralelizaci√≥n\n",
        "MAX_WORKERS = 16\n",
        "\n",
        "def collect_image_paths(directory):\n",
        "    file_paths = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        if PLANT_NAME in root:\n",
        "            for file in files:\n",
        "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    file_paths.append(os.path.join(root, file))\n",
        "    return file_paths\n",
        "\n",
        "def process_image(file_path):\n",
        "    try:\n",
        "        with Image.open(file_path) as img:\n",
        "            return (img.size[0], img.size[1])\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def analyze_plant_dimensions():\n",
        "    category_path = os.path.join(DATASET_PATH, CATEGORY, PLANT_NAME)\n",
        "    if not os.path.exists(category_path):\n",
        "        print(f\"Error: No se encontr√≥ la carpeta {category_path}.\")\n",
        "        return None, None, 0\n",
        "    \n",
        "    file_paths = collect_image_paths(category_path)\n",
        "    dimensions = []\n",
        "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "        # Usar tqdm para mostrar progreso\n",
        "        with tqdm(total=len(file_paths), desc=\"Procesando im√°genes\") as pbar:\n",
        "            for dim in executor.map(process_image, file_paths):\n",
        "                if dim is not None:\n",
        "                    dimensions.append(dim)\n",
        "                pbar.update(1)\n",
        "    \n",
        "    try:\n",
        "        dim_array = cp.array(dimensions, dtype=cp.int32)\n",
        "        unique_dims, counts = np.unique(dim_array.get(), axis=0, return_counts=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error en el c√°lculo de dimensiones: {e}\")\n",
        "        return None, None, len(dimensions)\n",
        "    \n",
        "    return unique_dims, counts, len(dimensions)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unique_dims, counts, total_dims = analyze_plant_dimensions()\n",
        "    if unique_dims is not None and counts is not None:\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"Dimensiones de Im√°genes ({PLANT_NAME} - {CATEGORY.upper()})\")\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"{'Dimensi√≥n':<15} {'Conteo':>10}\")\n",
        "        print(\"-\" * 27)\n",
        "        for dim, count in zip(unique_dims, counts):\n",
        "            print(f\"{f'{dim[0]}x{dim[1]}':<15} {count:>10}\")\n",
        "        print(f\"\\nTotal im√°genes procesadas: {total_dims}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ***Soybean***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Procesando im√°genes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5090/5090 [00:01<00:00, 4975.56it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============================\n",
            "Dimensiones de Im√°genes (Soybean - COLOR)\n",
            "==============================\n",
            "Dimensi√≥n           Conteo\n",
            "---------------------------\n",
            "256x256               5090\n",
            "\n",
            "Total im√°genes procesadas: 5090\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import cupy as cp\n",
        "import numpy as np\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ruta del dataset local\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "# Nombre de la planta a procesar\n",
        "PLANT_NAME = \"Soybean\"\n",
        "# Categor√≠a a procesar\n",
        "CATEGORY = \"color\"\n",
        "# N√∫mero de hilos para paralelizaci√≥n\n",
        "MAX_WORKERS = 16\n",
        "\n",
        "def collect_image_paths(directory):\n",
        "    file_paths = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        if PLANT_NAME in root:\n",
        "            for file in files:\n",
        "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    file_paths.append(os.path.join(root, file))\n",
        "    return file_paths\n",
        "\n",
        "def process_image(file_path):\n",
        "    try:\n",
        "        with Image.open(file_path) as img:\n",
        "            return (img.size[0], img.size[1])\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def analyze_plant_dimensions():\n",
        "    category_path = os.path.join(DATASET_PATH, CATEGORY, PLANT_NAME)\n",
        "    if not os.path.exists(category_path):\n",
        "        print(f\"Error: No se encontr√≥ la carpeta {category_path}.\")\n",
        "        return None, None, 0\n",
        "    \n",
        "    file_paths = collect_image_paths(category_path)\n",
        "    dimensions = []\n",
        "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "        # Usar tqdm para mostrar progreso\n",
        "        with tqdm(total=len(file_paths), desc=\"Procesando im√°genes\") as pbar:\n",
        "            for dim in executor.map(process_image, file_paths):\n",
        "                if dim is not None:\n",
        "                    dimensions.append(dim)\n",
        "                pbar.update(1)\n",
        "    \n",
        "    try:\n",
        "        dim_array = cp.array(dimensions, dtype=cp.int32)\n",
        "        unique_dims, counts = np.unique(dim_array.get(), axis=0, return_counts=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error en el c√°lculo de dimensiones: {e}\")\n",
        "        return None, None, len(dimensions)\n",
        "    \n",
        "    return unique_dims, counts, len(dimensions)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unique_dims, counts, total_dims = analyze_plant_dimensions()\n",
        "    if unique_dims is not None and counts is not None:\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"Dimensiones de Im√°genes ({PLANT_NAME} - {CATEGORY.upper()})\")\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"{'Dimensi√≥n':<15} {'Conteo':>10}\")\n",
        "        print(\"-\" * 27)\n",
        "        for dim, count in zip(unique_dims, counts):\n",
        "            print(f\"{f'{dim[0]}x{dim[1]}':<15} {count:>10}\")\n",
        "        print(f\"\\nTotal im√°genes procesadas: {total_dims}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ***Squash***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Procesando im√°genes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1835/1835 [00:00<00:00, 3553.04it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============================\n",
            "Dimensiones de Im√°genes (Squash - COLOR)\n",
            "==============================\n",
            "Dimensi√≥n           Conteo\n",
            "---------------------------\n",
            "256x256               1835\n",
            "\n",
            "Total im√°genes procesadas: 1835\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import cupy as cp\n",
        "import numpy as np\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ruta del dataset local\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "# Nombre de la planta a procesar\n",
        "PLANT_NAME = \"Squash\"\n",
        "# Categor√≠a a procesar\n",
        "CATEGORY = \"color\"\n",
        "# N√∫mero de hilos para paralelizaci√≥n\n",
        "MAX_WORKERS = 16\n",
        "\n",
        "def collect_image_paths(directory):\n",
        "    file_paths = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        if PLANT_NAME in root:\n",
        "            for file in files:\n",
        "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    file_paths.append(os.path.join(root, file))\n",
        "    return file_paths\n",
        "\n",
        "def process_image(file_path):\n",
        "    try:\n",
        "        with Image.open(file_path) as img:\n",
        "            return (img.size[0], img.size[1])\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def analyze_plant_dimensions():\n",
        "    category_path = os.path.join(DATASET_PATH, CATEGORY, PLANT_NAME)\n",
        "    if not os.path.exists(category_path):\n",
        "        print(f\"Error: No se encontr√≥ la carpeta {category_path}.\")\n",
        "        return None, None, 0\n",
        "    \n",
        "    file_paths = collect_image_paths(category_path)\n",
        "    dimensions = []\n",
        "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "        # Usar tqdm para mostrar progreso\n",
        "        with tqdm(total=len(file_paths), desc=\"Procesando im√°genes\") as pbar:\n",
        "            for dim in executor.map(process_image, file_paths):\n",
        "                if dim is not None:\n",
        "                    dimensions.append(dim)\n",
        "                pbar.update(1)\n",
        "    \n",
        "    try:\n",
        "        dim_array = cp.array(dimensions, dtype=cp.int32)\n",
        "        unique_dims, counts = np.unique(dim_array.get(), axis=0, return_counts=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error en el c√°lculo de dimensiones: {e}\")\n",
        "        return None, None, len(dimensions)\n",
        "    \n",
        "    return unique_dims, counts, len(dimensions)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unique_dims, counts, total_dims = analyze_plant_dimensions()\n",
        "    if unique_dims is not None and counts is not None:\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"Dimensiones de Im√°genes ({PLANT_NAME} - {CATEGORY.upper()})\")\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"{'Dimensi√≥n':<15} {'Conteo':>10}\")\n",
        "        print(\"-\" * 27)\n",
        "        for dim, count in zip(unique_dims, counts):\n",
        "            print(f\"{f'{dim[0]}x{dim[1]}':<15} {count:>10}\")\n",
        "        print(f\"\\nTotal im√°genes procesadas: {total_dims}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ***Strawberry***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Procesando im√°genes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1565/1565 [00:00<00:00, 5212.53it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============================\n",
            "Dimensiones de Im√°genes (Strawberry - COLOR)\n",
            "==============================\n",
            "Dimensi√≥n           Conteo\n",
            "---------------------------\n",
            "256x256               1565\n",
            "\n",
            "Total im√°genes procesadas: 1565\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import cupy as cp\n",
        "import numpy as np\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ruta del dataset local\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "# Nombre de la planta a procesar\n",
        "PLANT_NAME = \"Strawberry\"\n",
        "# Categor√≠a a procesar\n",
        "CATEGORY = \"color\"\n",
        "# N√∫mero de hilos para paralelizaci√≥n\n",
        "MAX_WORKERS = 16\n",
        "\n",
        "def collect_image_paths(directory):\n",
        "    file_paths = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        if PLANT_NAME in root:\n",
        "            for file in files:\n",
        "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    file_paths.append(os.path.join(root, file))\n",
        "    return file_paths\n",
        "\n",
        "def process_image(file_path):\n",
        "    try:\n",
        "        with Image.open(file_path) as img:\n",
        "            return (img.size[0], img.size[1])\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def analyze_plant_dimensions():\n",
        "    category_path = os.path.join(DATASET_PATH, CATEGORY, PLANT_NAME)\n",
        "    if not os.path.exists(category_path):\n",
        "        print(f\"Error: No se encontr√≥ la carpeta {category_path}.\")\n",
        "        return None, None, 0\n",
        "    \n",
        "    file_paths = collect_image_paths(category_path)\n",
        "    dimensions = []\n",
        "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "        # Usar tqdm para mostrar progreso\n",
        "        with tqdm(total=len(file_paths), desc=\"Procesando im√°genes\") as pbar:\n",
        "            for dim in executor.map(process_image, file_paths):\n",
        "                if dim is not None:\n",
        "                    dimensions.append(dim)\n",
        "                pbar.update(1)\n",
        "    \n",
        "    try:\n",
        "        dim_array = cp.array(dimensions, dtype=cp.int32)\n",
        "        unique_dims, counts = np.unique(dim_array.get(), axis=0, return_counts=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error en el c√°lculo de dimensiones: {e}\")\n",
        "        return None, None, len(dimensions)\n",
        "    \n",
        "    return unique_dims, counts, len(dimensions)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unique_dims, counts, total_dims = analyze_plant_dimensions()\n",
        "    if unique_dims is not None and counts is not None:\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"Dimensiones de Im√°genes ({PLANT_NAME} - {CATEGORY.upper()})\")\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"{'Dimensi√≥n':<15} {'Conteo':>10}\")\n",
        "        print(\"-\" * 27)\n",
        "        for dim, count in zip(unique_dims, counts):\n",
        "            print(f\"{f'{dim[0]}x{dim[1]}':<15} {count:>10}\")\n",
        "        print(f\"\\nTotal im√°genes procesadas: {total_dims}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ***Tomato***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Procesando im√°genes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18160/18160 [00:03<00:00, 4927.47it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============================\n",
            "Dimensiones de Im√°genes (Tomato - COLOR)\n",
            "==============================\n",
            "Dimensi√≥n           Conteo\n",
            "---------------------------\n",
            "256x256              18160\n",
            "\n",
            "Total im√°genes procesadas: 18160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import cupy as cp\n",
        "import numpy as np\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ruta del dataset local\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "# Nombre de la planta a procesar\n",
        "PLANT_NAME = \"Tomato\"\n",
        "# Categor√≠a a procesar\n",
        "CATEGORY = \"color\"\n",
        "# N√∫mero de hilos para paralelizaci√≥n\n",
        "MAX_WORKERS = 16\n",
        "\n",
        "def collect_image_paths(directory):\n",
        "    file_paths = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        if PLANT_NAME in root:\n",
        "            for file in files:\n",
        "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    file_paths.append(os.path.join(root, file))\n",
        "    return file_paths\n",
        "\n",
        "def process_image(file_path):\n",
        "    try:\n",
        "        with Image.open(file_path) as img:\n",
        "            return (img.size[0], img.size[1])\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def analyze_plant_dimensions():\n",
        "    category_path = os.path.join(DATASET_PATH, CATEGORY, PLANT_NAME)\n",
        "    if not os.path.exists(category_path):\n",
        "        print(f\"Error: No se encontr√≥ la carpeta {category_path}.\")\n",
        "        return None, None, 0\n",
        "    \n",
        "    file_paths = collect_image_paths(category_path)\n",
        "    dimensions = []\n",
        "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "        # Usar tqdm para mostrar progreso\n",
        "        with tqdm(total=len(file_paths), desc=\"Procesando im√°genes\") as pbar:\n",
        "            for dim in executor.map(process_image, file_paths):\n",
        "                if dim is not None:\n",
        "                    dimensions.append(dim)\n",
        "                pbar.update(1)\n",
        "    \n",
        "    try:\n",
        "        dim_array = cp.array(dimensions, dtype=cp.int32)\n",
        "        unique_dims, counts = np.unique(dim_array.get(), axis=0, return_counts=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error en el c√°lculo de dimensiones: {e}\")\n",
        "        return None, None, len(dimensions)\n",
        "    \n",
        "    return unique_dims, counts, len(dimensions)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unique_dims, counts, total_dims = analyze_plant_dimensions()\n",
        "    if unique_dims is not None and counts is not None:\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"Dimensiones de Im√°genes ({PLANT_NAME} - {CATEGORY.upper()})\")\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"{'Dimensi√≥n':<15} {'Conteo':>10}\")\n",
        "        print(\"-\" * 27)\n",
        "        for dim, count in zip(unique_dims, counts):\n",
        "            print(f\"{f'{dim[0]}x{dim[1]}':<15} {count:>10}\")\n",
        "        print(f\"\\nTotal im√°genes procesadas: {total_dims}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### ***Grayscale***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ***Apple***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Procesando im√°genes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3171/3171 [00:00<00:00, 4704.76it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============================\n",
            "Dimensiones de Im√°genes (Apple - GRAYSCALE)\n",
            "==============================\n",
            "Dimensi√≥n           Conteo\n",
            "---------------------------\n",
            "256x256               3171\n",
            "\n",
            "Total im√°genes procesadas: 3171\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import cupy as cp\n",
        "import numpy as np\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ruta del dataset local\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "# Nombre de la planta a procesar\n",
        "PLANT_NAME = \"Apple\"\n",
        "# Categor√≠a a procesar\n",
        "CATEGORY = \"grayscale\"\n",
        "# N√∫mero de hilos para paralelizaci√≥n\n",
        "MAX_WORKERS = 16\n",
        "\n",
        "def collect_image_paths(directory):\n",
        "    file_paths = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        if PLANT_NAME in root:\n",
        "            for file in files:\n",
        "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    file_paths.append(os.path.join(root, file))\n",
        "    return file_paths\n",
        "\n",
        "def process_image(file_path):\n",
        "    try:\n",
        "        with Image.open(file_path) as img:\n",
        "            return (img.size[0], img.size[1])\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def analyze_plant_dimensions():\n",
        "    category_path = os.path.join(DATASET_PATH, CATEGORY, PLANT_NAME)\n",
        "    if not os.path.exists(category_path):\n",
        "        print(f\"Error: No se encontr√≥ la carpeta {category_path}.\")\n",
        "        return None, None, 0\n",
        "    \n",
        "    file_paths = collect_image_paths(category_path)\n",
        "    dimensions = []\n",
        "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "        # Usar tqdm para mostrar progreso\n",
        "        with tqdm(total=len(file_paths), desc=\"Procesando im√°genes\") as pbar:\n",
        "            for dim in executor.map(process_image, file_paths):\n",
        "                if dim is not None:\n",
        "                    dimensions.append(dim)\n",
        "                pbar.update(1)\n",
        "    \n",
        "    try:\n",
        "        dim_array = cp.array(dimensions, dtype=cp.int32)\n",
        "        unique_dims, counts = np.unique(dim_array.get(), axis=0, return_counts=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error en el c√°lculo de dimensiones: {e}\")\n",
        "        return None, None, len(dimensions)\n",
        "    \n",
        "    return unique_dims, counts, len(dimensions)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unique_dims, counts, total_dims = analyze_plant_dimensions()\n",
        "    if unique_dims is not None and counts is not None:\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"Dimensiones de Im√°genes ({PLANT_NAME} - {CATEGORY.upper()})\")\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"{'Dimensi√≥n':<15} {'Conteo':>10}\")\n",
        "        print(\"-\" * 27)\n",
        "        for dim, count in zip(unique_dims, counts):\n",
        "            print(f\"{f'{dim[0]}x{dim[1]}':<15} {count:>10}\")\n",
        "        print(f\"\\nTotal im√°genes procesadas: {total_dims}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ***Blueberry***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Procesando im√°genes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1502/1502 [00:00<00:00, 5900.12it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============================\n",
            "Dimensiones de Im√°genes (Blueberry - GRAYSCALE)\n",
            "==============================\n",
            "Dimensi√≥n           Conteo\n",
            "---------------------------\n",
            "256x256               1502\n",
            "\n",
            "Total im√°genes procesadas: 1502\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import cupy as cp\n",
        "import numpy as np\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ruta del dataset local\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "# Nombre de la planta a procesar\n",
        "PLANT_NAME = \"Blueberry\"\n",
        "# Categor√≠a a procesar\n",
        "CATEGORY = \"grayscale\"\n",
        "# N√∫mero de hilos para paralelizaci√≥n\n",
        "MAX_WORKERS = 16\n",
        "\n",
        "def collect_image_paths(directory):\n",
        "    file_paths = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        if PLANT_NAME in root:\n",
        "            for file in files:\n",
        "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    file_paths.append(os.path.join(root, file))\n",
        "    return file_paths\n",
        "\n",
        "def process_image(file_path):\n",
        "    try:\n",
        "        with Image.open(file_path) as img:\n",
        "            return (img.size[0], img.size[1])\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def analyze_plant_dimensions():\n",
        "    category_path = os.path.join(DATASET_PATH, CATEGORY, PLANT_NAME)\n",
        "    if not os.path.exists(category_path):\n",
        "        print(f\"Error: No se encontr√≥ la carpeta {category_path}.\")\n",
        "        return None, None, 0\n",
        "    \n",
        "    file_paths = collect_image_paths(category_path)\n",
        "    dimensions = []\n",
        "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "        # Usar tqdm para mostrar progreso\n",
        "        with tqdm(total=len(file_paths), desc=\"Procesando im√°genes\") as pbar:\n",
        "            for dim in executor.map(process_image, file_paths):\n",
        "                if dim is not None:\n",
        "                    dimensions.append(dim)\n",
        "                pbar.update(1)\n",
        "    \n",
        "    try:\n",
        "        dim_array = cp.array(dimensions, dtype=cp.int32)\n",
        "        unique_dims, counts = np.unique(dim_array.get(), axis=0, return_counts=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error en el c√°lculo de dimensiones: {e}\")\n",
        "        return None, None, len(dimensions)\n",
        "    \n",
        "    return unique_dims, counts, len(dimensions)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unique_dims, counts, total_dims = analyze_plant_dimensions()\n",
        "    if unique_dims is not None and counts is not None:\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"Dimensiones de Im√°genes ({PLANT_NAME} - {CATEGORY.upper()})\")\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"{'Dimensi√≥n':<15} {'Conteo':>10}\")\n",
        "        print(\"-\" * 27)\n",
        "        for dim, count in zip(unique_dims, counts):\n",
        "            print(f\"{f'{dim[0]}x{dim[1]}':<15} {count:>10}\")\n",
        "        print(f\"\\nTotal im√°genes procesadas: {total_dims}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ***Cherry***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Procesando im√°genes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1906/1906 [00:00<00:00, 4933.46it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============================\n",
            "Dimensiones de Im√°genes (Cherry - GRAYSCALE)\n",
            "==============================\n",
            "Dimensi√≥n           Conteo\n",
            "---------------------------\n",
            "256x256               1906\n",
            "\n",
            "Total im√°genes procesadas: 1906\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import cupy as cp\n",
        "import numpy as np\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ruta del dataset local\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "# Nombre de la planta a procesar\n",
        "PLANT_NAME = \"Cherry\"\n",
        "# Categor√≠a a procesar\n",
        "CATEGORY = \"grayscale\"\n",
        "# N√∫mero de hilos para paralelizaci√≥n\n",
        "MAX_WORKERS = 16\n",
        "\n",
        "def collect_image_paths(directory):\n",
        "    file_paths = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        if PLANT_NAME in root:\n",
        "            for file in files:\n",
        "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    file_paths.append(os.path.join(root, file))\n",
        "    return file_paths\n",
        "\n",
        "def process_image(file_path):\n",
        "    try:\n",
        "        with Image.open(file_path) as img:\n",
        "            return (img.size[0], img.size[1])\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def analyze_plant_dimensions():\n",
        "    category_path = os.path.join(DATASET_PATH, CATEGORY, PLANT_NAME)\n",
        "    if not os.path.exists(category_path):\n",
        "        print(f\"Error: No se encontr√≥ la carpeta {category_path}.\")\n",
        "        return None, None, 0\n",
        "    \n",
        "    file_paths = collect_image_paths(category_path)\n",
        "    dimensions = []\n",
        "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "        # Usar tqdm para mostrar progreso\n",
        "        with tqdm(total=len(file_paths), desc=\"Procesando im√°genes\") as pbar:\n",
        "            for dim in executor.map(process_image, file_paths):\n",
        "                if dim is not None:\n",
        "                    dimensions.append(dim)\n",
        "                pbar.update(1)\n",
        "    \n",
        "    try:\n",
        "        dim_array = cp.array(dimensions, dtype=cp.int32)\n",
        "        unique_dims, counts = np.unique(dim_array.get(), axis=0, return_counts=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error en el c√°lculo de dimensiones: {e}\")\n",
        "        return None, None, len(dimensions)\n",
        "    \n",
        "    return unique_dims, counts, len(dimensions)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unique_dims, counts, total_dims = analyze_plant_dimensions()\n",
        "    if unique_dims is not None and counts is not None:\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"Dimensiones de Im√°genes ({PLANT_NAME} - {CATEGORY.upper()})\")\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"{'Dimensi√≥n':<15} {'Conteo':>10}\")\n",
        "        print(\"-\" * 27)\n",
        "        for dim, count in zip(unique_dims, counts):\n",
        "            print(f\"{f'{dim[0]}x{dim[1]}':<15} {count:>10}\")\n",
        "        print(f\"\\nTotal im√°genes procesadas: {total_dims}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ***Corn***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Procesando im√°genes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3852/3852 [00:00<00:00, 5632.23it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============================\n",
            "Dimensiones de Im√°genes (Corn - GRAYSCALE)\n",
            "==============================\n",
            "Dimensi√≥n           Conteo\n",
            "---------------------------\n",
            "256x256               3852\n",
            "\n",
            "Total im√°genes procesadas: 3852\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import cupy as cp\n",
        "import numpy as np\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ruta del dataset local\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "# Nombre de la planta a procesar\n",
        "PLANT_NAME = \"Corn\"\n",
        "# Categor√≠a a procesar\n",
        "CATEGORY = \"grayscale\"\n",
        "# N√∫mero de hilos para paralelizaci√≥n\n",
        "MAX_WORKERS = 16\n",
        "\n",
        "def collect_image_paths(directory):\n",
        "    file_paths = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        if PLANT_NAME in root:\n",
        "            for file in files:\n",
        "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    file_paths.append(os.path.join(root, file))\n",
        "    return file_paths\n",
        "\n",
        "def process_image(file_path):\n",
        "    try:\n",
        "        with Image.open(file_path) as img:\n",
        "            return (img.size[0], img.size[1])\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def analyze_plant_dimensions():\n",
        "    category_path = os.path.join(DATASET_PATH, CATEGORY, PLANT_NAME)\n",
        "    if not os.path.exists(category_path):\n",
        "        print(f\"Error: No se encontr√≥ la carpeta {category_path}.\")\n",
        "        return None, None, 0\n",
        "    \n",
        "    file_paths = collect_image_paths(category_path)\n",
        "    dimensions = []\n",
        "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "        # Usar tqdm para mostrar progreso\n",
        "        with tqdm(total=len(file_paths), desc=\"Procesando im√°genes\") as pbar:\n",
        "            for dim in executor.map(process_image, file_paths):\n",
        "                if dim is not None:\n",
        "                    dimensions.append(dim)\n",
        "                pbar.update(1)\n",
        "    \n",
        "    try:\n",
        "        dim_array = cp.array(dimensions, dtype=cp.int32)\n",
        "        unique_dims, counts = np.unique(dim_array.get(), axis=0, return_counts=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error en el c√°lculo de dimensiones: {e}\")\n",
        "        return None, None, len(dimensions)\n",
        "    \n",
        "    return unique_dims, counts, len(dimensions)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unique_dims, counts, total_dims = analyze_plant_dimensions()\n",
        "    if unique_dims is not None and counts is not None:\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"Dimensiones de Im√°genes ({PLANT_NAME} - {CATEGORY.upper()})\")\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"{'Dimensi√≥n':<15} {'Conteo':>10}\")\n",
        "        print(\"-\" * 27)\n",
        "        for dim, count in zip(unique_dims, counts):\n",
        "            print(f\"{f'{dim[0]}x{dim[1]}':<15} {count:>10}\")\n",
        "        print(f\"\\nTotal im√°genes procesadas: {total_dims}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ***Grape***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Procesando im√°genes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4062/4062 [00:00<00:00, 5439.98it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============================\n",
            "Dimensiones de Im√°genes (Grape - GRAYSCALE)\n",
            "==============================\n",
            "Dimensi√≥n           Conteo\n",
            "---------------------------\n",
            "256x256               4062\n",
            "\n",
            "Total im√°genes procesadas: 4062\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import cupy as cp\n",
        "import numpy as np\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ruta del dataset local\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "# Nombre de la planta a procesar\n",
        "PLANT_NAME = \"Grape\"\n",
        "# Categor√≠a a procesar\n",
        "CATEGORY = \"grayscale\"\n",
        "# N√∫mero de hilos para paralelizaci√≥n\n",
        "MAX_WORKERS = 16\n",
        "\n",
        "def collect_image_paths(directory):\n",
        "    file_paths = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        if PLANT_NAME in root:\n",
        "            for file in files:\n",
        "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    file_paths.append(os.path.join(root, file))\n",
        "    return file_paths\n",
        "\n",
        "def process_image(file_path):\n",
        "    try:\n",
        "        with Image.open(file_path) as img:\n",
        "            return (img.size[0], img.size[1])\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def analyze_plant_dimensions():\n",
        "    category_path = os.path.join(DATASET_PATH, CATEGORY, PLANT_NAME)\n",
        "    if not os.path.exists(category_path):\n",
        "        print(f\"Error: No se encontr√≥ la carpeta {category_path}.\")\n",
        "        return None, None, 0\n",
        "    \n",
        "    file_paths = collect_image_paths(category_path)\n",
        "    dimensions = []\n",
        "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "        # Usar tqdm para mostrar progreso\n",
        "        with tqdm(total=len(file_paths), desc=\"Procesando im√°genes\") as pbar:\n",
        "            for dim in executor.map(process_image, file_paths):\n",
        "                if dim is not None:\n",
        "                    dimensions.append(dim)\n",
        "                pbar.update(1)\n",
        "    \n",
        "    try:\n",
        "        dim_array = cp.array(dimensions, dtype=cp.int32)\n",
        "        unique_dims, counts = np.unique(dim_array.get(), axis=0, return_counts=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error en el c√°lculo de dimensiones: {e}\")\n",
        "        return None, None, len(dimensions)\n",
        "    \n",
        "    return unique_dims, counts, len(dimensions)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unique_dims, counts, total_dims = analyze_plant_dimensions()\n",
        "    if unique_dims is not None and counts is not None:\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"Dimensiones de Im√°genes ({PLANT_NAME} - {CATEGORY.upper()})\")\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"{'Dimensi√≥n':<15} {'Conteo':>10}\")\n",
        "        print(\"-\" * 27)\n",
        "        for dim, count in zip(unique_dims, counts):\n",
        "            print(f\"{f'{dim[0]}x{dim[1]}':<15} {count:>10}\")\n",
        "        print(f\"\\nTotal im√°genes procesadas: {total_dims}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ***Orange***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Procesando im√°genes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5507/5507 [00:01<00:00, 5465.90it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============================\n",
            "Dimensiones de Im√°genes (Orange - GRAYSCALE)\n",
            "==============================\n",
            "Dimensi√≥n           Conteo\n",
            "---------------------------\n",
            "256x256               5507\n",
            "\n",
            "Total im√°genes procesadas: 5507\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import cupy as cp\n",
        "import numpy as np\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ruta del dataset local\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "# Nombre de la planta a procesar\n",
        "PLANT_NAME = \"Orange\"\n",
        "# Categor√≠a a procesar\n",
        "CATEGORY = \"grayscale\"\n",
        "# N√∫mero de hilos para paralelizaci√≥n\n",
        "MAX_WORKERS = 16\n",
        "\n",
        "def collect_image_paths(directory):\n",
        "    file_paths = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        if PLANT_NAME in root:\n",
        "            for file in files:\n",
        "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    file_paths.append(os.path.join(root, file))\n",
        "    return file_paths\n",
        "\n",
        "def process_image(file_path):\n",
        "    try:\n",
        "        with Image.open(file_path) as img:\n",
        "            return (img.size[0], img.size[1])\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def analyze_plant_dimensions():\n",
        "    category_path = os.path.join(DATASET_PATH, CATEGORY, PLANT_NAME)\n",
        "    if not os.path.exists(category_path):\n",
        "        print(f\"Error: No se encontr√≥ la carpeta {category_path}.\")\n",
        "        return None, None, 0\n",
        "    \n",
        "    file_paths = collect_image_paths(category_path)\n",
        "    dimensions = []\n",
        "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "        # Usar tqdm para mostrar progreso\n",
        "        with tqdm(total=len(file_paths), desc=\"Procesando im√°genes\") as pbar:\n",
        "            for dim in executor.map(process_image, file_paths):\n",
        "                if dim is not None:\n",
        "                    dimensions.append(dim)\n",
        "                pbar.update(1)\n",
        "    \n",
        "    try:\n",
        "        dim_array = cp.array(dimensions, dtype=cp.int32)\n",
        "        unique_dims, counts = np.unique(dim_array.get(), axis=0, return_counts=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error en el c√°lculo de dimensiones: {e}\")\n",
        "        return None, None, len(dimensions)\n",
        "    \n",
        "    return unique_dims, counts, len(dimensions)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unique_dims, counts, total_dims = analyze_plant_dimensions()\n",
        "    if unique_dims is not None and counts is not None:\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"Dimensiones de Im√°genes ({PLANT_NAME} - {CATEGORY.upper()})\")\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"{'Dimensi√≥n':<15} {'Conteo':>10}\")\n",
        "        print(\"-\" * 27)\n",
        "        for dim, count in zip(unique_dims, counts):\n",
        "            print(f\"{f'{dim[0]}x{dim[1]}':<15} {count:>10}\")\n",
        "        print(f\"\\nTotal im√°genes procesadas: {total_dims}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ***Peach***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Procesando im√°genes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2657/2657 [00:00<00:00, 5805.21it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============================\n",
            "Dimensiones de Im√°genes (Peach - GRAYSCALE)\n",
            "==============================\n",
            "Dimensi√≥n           Conteo\n",
            "---------------------------\n",
            "256x256               2657\n",
            "\n",
            "Total im√°genes procesadas: 2657\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import cupy as cp\n",
        "import numpy as np\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ruta del dataset local\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "# Nombre de la planta a procesar\n",
        "PLANT_NAME = \"Peach\"\n",
        "# Categor√≠a a procesar\n",
        "CATEGORY = \"grayscale\"\n",
        "# N√∫mero de hilos para paralelizaci√≥n\n",
        "MAX_WORKERS = 16\n",
        "\n",
        "def collect_image_paths(directory):\n",
        "    file_paths = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        if PLANT_NAME in root:\n",
        "            for file in files:\n",
        "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    file_paths.append(os.path.join(root, file))\n",
        "    return file_paths\n",
        "\n",
        "def process_image(file_path):\n",
        "    try:\n",
        "        with Image.open(file_path) as img:\n",
        "            return (img.size[0], img.size[1])\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def analyze_plant_dimensions():\n",
        "    category_path = os.path.join(DATASET_PATH, CATEGORY, PLANT_NAME)\n",
        "    if not os.path.exists(category_path):\n",
        "        print(f\"Error: No se encontr√≥ la carpeta {category_path}.\")\n",
        "        return None, None, 0\n",
        "    \n",
        "    file_paths = collect_image_paths(category_path)\n",
        "    dimensions = []\n",
        "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "        # Usar tqdm para mostrar progreso\n",
        "        with tqdm(total=len(file_paths), desc=\"Procesando im√°genes\") as pbar:\n",
        "            for dim in executor.map(process_image, file_paths):\n",
        "                if dim is not None:\n",
        "                    dimensions.append(dim)\n",
        "                pbar.update(1)\n",
        "    \n",
        "    try:\n",
        "        dim_array = cp.array(dimensions, dtype=cp.int32)\n",
        "        unique_dims, counts = np.unique(dim_array.get(), axis=0, return_counts=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error en el c√°lculo de dimensiones: {e}\")\n",
        "        return None, None, len(dimensions)\n",
        "    \n",
        "    return unique_dims, counts, len(dimensions)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unique_dims, counts, total_dims = analyze_plant_dimensions()\n",
        "    if unique_dims is not None and counts is not None:\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"Dimensiones de Im√°genes ({PLANT_NAME} - {CATEGORY.upper()})\")\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"{'Dimensi√≥n':<15} {'Conteo':>10}\")\n",
        "        print(\"-\" * 27)\n",
        "        for dim, count in zip(unique_dims, counts):\n",
        "            print(f\"{f'{dim[0]}x{dim[1]}':<15} {count:>10}\")\n",
        "        print(f\"\\nTotal im√°genes procesadas: {total_dims}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ***Pepper***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Procesando im√°genes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2475/2475 [00:00<00:00, 5093.92it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============================\n",
            "Dimensiones de Im√°genes (Pepper - GRAYSCALE)\n",
            "==============================\n",
            "Dimensi√≥n           Conteo\n",
            "---------------------------\n",
            "256x256               2475\n",
            "\n",
            "Total im√°genes procesadas: 2475\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import cupy as cp\n",
        "import numpy as np\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ruta del dataset local\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "# Nombre de la planta a procesar\n",
        "PLANT_NAME = \"Pepper\"\n",
        "# Categor√≠a a procesar\n",
        "CATEGORY = \"grayscale\"\n",
        "# N√∫mero de hilos para paralelizaci√≥n\n",
        "MAX_WORKERS = 16\n",
        "\n",
        "def collect_image_paths(directory):\n",
        "    file_paths = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        if PLANT_NAME in root:\n",
        "            for file in files:\n",
        "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    file_paths.append(os.path.join(root, file))\n",
        "    return file_paths\n",
        "\n",
        "def process_image(file_path):\n",
        "    try:\n",
        "        with Image.open(file_path) as img:\n",
        "            return (img.size[0], img.size[1])\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def analyze_plant_dimensions():\n",
        "    category_path = os.path.join(DATASET_PATH, CATEGORY, PLANT_NAME)\n",
        "    if not os.path.exists(category_path):\n",
        "        print(f\"Error: No se encontr√≥ la carpeta {category_path}.\")\n",
        "        return None, None, 0\n",
        "    \n",
        "    file_paths = collect_image_paths(category_path)\n",
        "    dimensions = []\n",
        "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "        # Usar tqdm para mostrar progreso\n",
        "        with tqdm(total=len(file_paths), desc=\"Procesando im√°genes\") as pbar:\n",
        "            for dim in executor.map(process_image, file_paths):\n",
        "                if dim is not None:\n",
        "                    dimensions.append(dim)\n",
        "                pbar.update(1)\n",
        "    \n",
        "    try:\n",
        "        dim_array = cp.array(dimensions, dtype=cp.int32)\n",
        "        unique_dims, counts = np.unique(dim_array.get(), axis=0, return_counts=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error en el c√°lculo de dimensiones: {e}\")\n",
        "        return None, None, len(dimensions)\n",
        "    \n",
        "    return unique_dims, counts, len(dimensions)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unique_dims, counts, total_dims = analyze_plant_dimensions()\n",
        "    if unique_dims is not None and counts is not None:\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"Dimensiones de Im√°genes ({PLANT_NAME} - {CATEGORY.upper()})\")\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"{'Dimensi√≥n':<15} {'Conteo':>10}\")\n",
        "        print(\"-\" * 27)\n",
        "        for dim, count in zip(unique_dims, counts):\n",
        "            print(f\"{f'{dim[0]}x{dim[1]}':<15} {count:>10}\")\n",
        "        print(f\"\\nTotal im√°genes procesadas: {total_dims}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ***Potato***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Procesando im√°genes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2152/2152 [00:00<00:00, 5764.15it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============================\n",
            "Dimensiones de Im√°genes (Potato - GRAYSCALE)\n",
            "==============================\n",
            "Dimensi√≥n           Conteo\n",
            "---------------------------\n",
            "256x256               2152\n",
            "\n",
            "Total im√°genes procesadas: 2152\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import cupy as cp\n",
        "import numpy as np\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ruta del dataset local\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "# Nombre de la planta a procesar\n",
        "PLANT_NAME = \"Potato\"\n",
        "# Categor√≠a a procesar\n",
        "CATEGORY = \"grayscale\"\n",
        "# N√∫mero de hilos para paralelizaci√≥n\n",
        "MAX_WORKERS = 16\n",
        "\n",
        "def collect_image_paths(directory):\n",
        "    file_paths = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        if PLANT_NAME in root:\n",
        "            for file in files:\n",
        "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    file_paths.append(os.path.join(root, file))\n",
        "    return file_paths\n",
        "\n",
        "def process_image(file_path):\n",
        "    try:\n",
        "        with Image.open(file_path) as img:\n",
        "            return (img.size[0], img.size[1])\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def analyze_plant_dimensions():\n",
        "    category_path = os.path.join(DATASET_PATH, CATEGORY, PLANT_NAME)\n",
        "    if not os.path.exists(category_path):\n",
        "        print(f\"Error: No se encontr√≥ la carpeta {category_path}.\")\n",
        "        return None, None, 0\n",
        "    \n",
        "    file_paths = collect_image_paths(category_path)\n",
        "    dimensions = []\n",
        "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "        # Usar tqdm para mostrar progreso\n",
        "        with tqdm(total=len(file_paths), desc=\"Procesando im√°genes\") as pbar:\n",
        "            for dim in executor.map(process_image, file_paths):\n",
        "                if dim is not None:\n",
        "                    dimensions.append(dim)\n",
        "                pbar.update(1)\n",
        "    \n",
        "    try:\n",
        "        dim_array = cp.array(dimensions, dtype=cp.int32)\n",
        "        unique_dims, counts = np.unique(dim_array.get(), axis=0, return_counts=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error en el c√°lculo de dimensiones: {e}\")\n",
        "        return None, None, len(dimensions)\n",
        "    \n",
        "    return unique_dims, counts, len(dimensions)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unique_dims, counts, total_dims = analyze_plant_dimensions()\n",
        "    if unique_dims is not None and counts is not None:\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"Dimensiones de Im√°genes ({PLANT_NAME} - {CATEGORY.upper()})\")\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"{'Dimensi√≥n':<15} {'Conteo':>10}\")\n",
        "        print(\"-\" * 27)\n",
        "        for dim, count in zip(unique_dims, counts):\n",
        "            print(f\"{f'{dim[0]}x{dim[1]}':<15} {count:>10}\")\n",
        "        print(f\"\\nTotal im√°genes procesadas: {total_dims}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ***Raspberry***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Procesando im√°genes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 371/371 [00:00<00:00, 5640.02it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============================\n",
            "Dimensiones de Im√°genes (Raspberry - GRAYSCALE)\n",
            "==============================\n",
            "Dimensi√≥n           Conteo\n",
            "---------------------------\n",
            "256x256                371\n",
            "\n",
            "Total im√°genes procesadas: 371\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import cupy as cp\n",
        "import numpy as np\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ruta del dataset local\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "# Nombre de la planta a procesar\n",
        "PLANT_NAME = \"Raspberry\"\n",
        "# Categor√≠a a procesar\n",
        "CATEGORY = \"grayscale\"\n",
        "# N√∫mero de hilos para paralelizaci√≥n\n",
        "MAX_WORKERS = 16\n",
        "\n",
        "def collect_image_paths(directory):\n",
        "    file_paths = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        if PLANT_NAME in root:\n",
        "            for file in files:\n",
        "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    file_paths.append(os.path.join(root, file))\n",
        "    return file_paths\n",
        "\n",
        "def process_image(file_path):\n",
        "    try:\n",
        "        with Image.open(file_path) as img:\n",
        "            return (img.size[0], img.size[1])\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def analyze_plant_dimensions():\n",
        "    category_path = os.path.join(DATASET_PATH, CATEGORY, PLANT_NAME)\n",
        "    if not os.path.exists(category_path):\n",
        "        print(f\"Error: No se encontr√≥ la carpeta {category_path}.\")\n",
        "        return None, None, 0\n",
        "    \n",
        "    file_paths = collect_image_paths(category_path)\n",
        "    dimensions = []\n",
        "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "        # Usar tqdm para mostrar progreso\n",
        "        with tqdm(total=len(file_paths), desc=\"Procesando im√°genes\") as pbar:\n",
        "            for dim in executor.map(process_image, file_paths):\n",
        "                if dim is not None:\n",
        "                    dimensions.append(dim)\n",
        "                pbar.update(1)\n",
        "    \n",
        "    try:\n",
        "        dim_array = cp.array(dimensions, dtype=cp.int32)\n",
        "        unique_dims, counts = np.unique(dim_array.get(), axis=0, return_counts=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error en el c√°lculo de dimensiones: {e}\")\n",
        "        return None, None, len(dimensions)\n",
        "    \n",
        "    return unique_dims, counts, len(dimensions)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unique_dims, counts, total_dims = analyze_plant_dimensions()\n",
        "    if unique_dims is not None and counts is not None:\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"Dimensiones de Im√°genes ({PLANT_NAME} - {CATEGORY.upper()})\")\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"{'Dimensi√≥n':<15} {'Conteo':>10}\")\n",
        "        print(\"-\" * 27)\n",
        "        for dim, count in zip(unique_dims, counts):\n",
        "            print(f\"{f'{dim[0]}x{dim[1]}':<15} {count:>10}\")\n",
        "        print(f\"\\nTotal im√°genes procesadas: {total_dims}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ***Soybean***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Procesando im√°genes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5090/5090 [00:00<00:00, 5485.34it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============================\n",
            "Dimensiones de Im√°genes (Soybean - GRAYSCALE)\n",
            "==============================\n",
            "Dimensi√≥n           Conteo\n",
            "---------------------------\n",
            "256x256               5090\n",
            "\n",
            "Total im√°genes procesadas: 5090\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import cupy as cp\n",
        "import numpy as np\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ruta del dataset local\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "# Nombre de la planta a procesar\n",
        "PLANT_NAME = \"Soybean\"\n",
        "# Categor√≠a a procesar\n",
        "CATEGORY = \"grayscale\"\n",
        "# N√∫mero de hilos para paralelizaci√≥n\n",
        "MAX_WORKERS = 16\n",
        "\n",
        "def collect_image_paths(directory):\n",
        "    file_paths = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        if PLANT_NAME in root:\n",
        "            for file in files:\n",
        "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    file_paths.append(os.path.join(root, file))\n",
        "    return file_paths\n",
        "\n",
        "def process_image(file_path):\n",
        "    try:\n",
        "        with Image.open(file_path) as img:\n",
        "            return (img.size[0], img.size[1])\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def analyze_plant_dimensions():\n",
        "    category_path = os.path.join(DATASET_PATH, CATEGORY, PLANT_NAME)\n",
        "    if not os.path.exists(category_path):\n",
        "        print(f\"Error: No se encontr√≥ la carpeta {category_path}.\")\n",
        "        return None, None, 0\n",
        "    \n",
        "    file_paths = collect_image_paths(category_path)\n",
        "    dimensions = []\n",
        "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "        # Usar tqdm para mostrar progreso\n",
        "        with tqdm(total=len(file_paths), desc=\"Procesando im√°genes\") as pbar:\n",
        "            for dim in executor.map(process_image, file_paths):\n",
        "                if dim is not None:\n",
        "                    dimensions.append(dim)\n",
        "                pbar.update(1)\n",
        "    \n",
        "    try:\n",
        "        dim_array = cp.array(dimensions, dtype=cp.int32)\n",
        "        unique_dims, counts = np.unique(dim_array.get(), axis=0, return_counts=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error en el c√°lculo de dimensiones: {e}\")\n",
        "        return None, None, len(dimensions)\n",
        "    \n",
        "    return unique_dims, counts, len(dimensions)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unique_dims, counts, total_dims = analyze_plant_dimensions()\n",
        "    if unique_dims is not None and counts is not None:\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"Dimensiones de Im√°genes ({PLANT_NAME} - {CATEGORY.upper()})\")\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"{'Dimensi√≥n':<15} {'Conteo':>10}\")\n",
        "        print(\"-\" * 27)\n",
        "        for dim, count in zip(unique_dims, counts):\n",
        "            print(f\"{f'{dim[0]}x{dim[1]}':<15} {count:>10}\")\n",
        "        print(f\"\\nTotal im√°genes procesadas: {total_dims}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ***Squash***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Procesando im√°genes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1835/1835 [00:00<00:00, 5462.27it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============================\n",
            "Dimensiones de Im√°genes (Squash - GRAYSCALE)\n",
            "==============================\n",
            "Dimensi√≥n           Conteo\n",
            "---------------------------\n",
            "256x256               1835\n",
            "\n",
            "Total im√°genes procesadas: 1835\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import cupy as cp\n",
        "import numpy as np\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ruta del dataset local\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "# Nombre de la planta a procesar\n",
        "PLANT_NAME = \"Squash\"\n",
        "# Categor√≠a a procesar\n",
        "CATEGORY = \"grayscale\"\n",
        "# N√∫mero de hilos para paralelizaci√≥n\n",
        "MAX_WORKERS = 16\n",
        "\n",
        "def collect_image_paths(directory):\n",
        "    file_paths = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        if PLANT_NAME in root:\n",
        "            for file in files:\n",
        "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    file_paths.append(os.path.join(root, file))\n",
        "    return file_paths\n",
        "\n",
        "def process_image(file_path):\n",
        "    try:\n",
        "        with Image.open(file_path) as img:\n",
        "            return (img.size[0], img.size[1])\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def analyze_plant_dimensions():\n",
        "    category_path = os.path.join(DATASET_PATH, CATEGORY, PLANT_NAME)\n",
        "    if not os.path.exists(category_path):\n",
        "        print(f\"Error: No se encontr√≥ la carpeta {category_path}.\")\n",
        "        return None, None, 0\n",
        "    \n",
        "    file_paths = collect_image_paths(category_path)\n",
        "    dimensions = []\n",
        "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "        # Usar tqdm para mostrar progreso\n",
        "        with tqdm(total=len(file_paths), desc=\"Procesando im√°genes\") as pbar:\n",
        "            for dim in executor.map(process_image, file_paths):\n",
        "                if dim is not None:\n",
        "                    dimensions.append(dim)\n",
        "                pbar.update(1)\n",
        "    \n",
        "    try:\n",
        "        dim_array = cp.array(dimensions, dtype=cp.int32)\n",
        "        unique_dims, counts = np.unique(dim_array.get(), axis=0, return_counts=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error en el c√°lculo de dimensiones: {e}\")\n",
        "        return None, None, len(dimensions)\n",
        "    \n",
        "    return unique_dims, counts, len(dimensions)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unique_dims, counts, total_dims = analyze_plant_dimensions()\n",
        "    if unique_dims is not None and counts is not None:\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"Dimensiones de Im√°genes ({PLANT_NAME} - {CATEGORY.upper()})\")\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"{'Dimensi√≥n':<15} {'Conteo':>10}\")\n",
        "        print(\"-\" * 27)\n",
        "        for dim, count in zip(unique_dims, counts):\n",
        "            print(f\"{f'{dim[0]}x{dim[1]}':<15} {count:>10}\")\n",
        "        print(f\"\\nTotal im√°genes procesadas: {total_dims}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ***Strawberry***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Procesando im√°genes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1565/1565 [00:00<00:00, 4875.42it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============================\n",
            "Dimensiones de Im√°genes (Strawberry - GRAYSCALE)\n",
            "==============================\n",
            "Dimensi√≥n           Conteo\n",
            "---------------------------\n",
            "256x256               1565\n",
            "\n",
            "Total im√°genes procesadas: 1565\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import cupy as cp\n",
        "import numpy as np\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ruta del dataset local\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "# Nombre de la planta a procesar\n",
        "PLANT_NAME = \"Strawberry\"\n",
        "# Categor√≠a a procesar\n",
        "CATEGORY = \"grayscale\"\n",
        "# N√∫mero de hilos para paralelizaci√≥n\n",
        "MAX_WORKERS = 16\n",
        "\n",
        "def collect_image_paths(directory):\n",
        "    file_paths = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        if PLANT_NAME in root:\n",
        "            for file in files:\n",
        "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    file_paths.append(os.path.join(root, file))\n",
        "    return file_paths\n",
        "\n",
        "def process_image(file_path):\n",
        "    try:\n",
        "        with Image.open(file_path) as img:\n",
        "            return (img.size[0], img.size[1])\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def analyze_plant_dimensions():\n",
        "    category_path = os.path.join(DATASET_PATH, CATEGORY, PLANT_NAME)\n",
        "    if not os.path.exists(category_path):\n",
        "        print(f\"Error: No se encontr√≥ la carpeta {category_path}.\")\n",
        "        return None, None, 0\n",
        "    \n",
        "    file_paths = collect_image_paths(category_path)\n",
        "    dimensions = []\n",
        "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "        # Usar tqdm para mostrar progreso\n",
        "        with tqdm(total=len(file_paths), desc=\"Procesando im√°genes\") as pbar:\n",
        "            for dim in executor.map(process_image, file_paths):\n",
        "                if dim is not None:\n",
        "                    dimensions.append(dim)\n",
        "                pbar.update(1)\n",
        "    \n",
        "    try:\n",
        "        dim_array = cp.array(dimensions, dtype=cp.int32)\n",
        "        unique_dims, counts = np.unique(dim_array.get(), axis=0, return_counts=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error en el c√°lculo de dimensiones: {e}\")\n",
        "        return None, None, len(dimensions)\n",
        "    \n",
        "    return unique_dims, counts, len(dimensions)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unique_dims, counts, total_dims = analyze_plant_dimensions()\n",
        "    if unique_dims is not None and counts is not None:\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"Dimensiones de Im√°genes ({PLANT_NAME} - {CATEGORY.upper()})\")\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"{'Dimensi√≥n':<15} {'Conteo':>10}\")\n",
        "        print(\"-\" * 27)\n",
        "        for dim, count in zip(unique_dims, counts):\n",
        "            print(f\"{f'{dim[0]}x{dim[1]}':<15} {count:>10}\")\n",
        "        print(f\"\\nTotal im√°genes procesadas: {total_dims}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ***Tomato***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Procesando im√°genes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18160/18160 [00:03<00:00, 5530.09it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============================\n",
            "Dimensiones de Im√°genes (Tomato - GRAYSCALE)\n",
            "==============================\n",
            "Dimensi√≥n           Conteo\n",
            "---------------------------\n",
            "256x256              18160\n",
            "\n",
            "Total im√°genes procesadas: 18160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import cupy as cp\n",
        "import numpy as np\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ruta del dataset local\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "# Nombre de la planta a procesar\n",
        "PLANT_NAME = \"Tomato\"\n",
        "# Categor√≠a a procesar\n",
        "CATEGORY = \"grayscale\"\n",
        "# N√∫mero de hilos para paralelizaci√≥n\n",
        "MAX_WORKERS = 16\n",
        "\n",
        "def collect_image_paths(directory):\n",
        "    file_paths = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        if PLANT_NAME in root:\n",
        "            for file in files:\n",
        "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    file_paths.append(os.path.join(root, file))\n",
        "    return file_paths\n",
        "\n",
        "def process_image(file_path):\n",
        "    try:\n",
        "        with Image.open(file_path) as img:\n",
        "            return (img.size[0], img.size[1])\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def analyze_plant_dimensions():\n",
        "    category_path = os.path.join(DATASET_PATH, CATEGORY, PLANT_NAME)\n",
        "    if not os.path.exists(category_path):\n",
        "        print(f\"Error: No se encontr√≥ la carpeta {category_path}.\")\n",
        "        return None, None, 0\n",
        "    \n",
        "    file_paths = collect_image_paths(category_path)\n",
        "    dimensions = []\n",
        "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "        # Usar tqdm para mostrar progreso\n",
        "        with tqdm(total=len(file_paths), desc=\"Procesando im√°genes\") as pbar:\n",
        "            for dim in executor.map(process_image, file_paths):\n",
        "                if dim is not None:\n",
        "                    dimensions.append(dim)\n",
        "                pbar.update(1)\n",
        "    \n",
        "    try:\n",
        "        dim_array = cp.array(dimensions, dtype=cp.int32)\n",
        "        unique_dims, counts = np.unique(dim_array.get(), axis=0, return_counts=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error en el c√°lculo de dimensiones: {e}\")\n",
        "        return None, None, len(dimensions)\n",
        "    \n",
        "    return unique_dims, counts, len(dimensions)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unique_dims, counts, total_dims = analyze_plant_dimensions()\n",
        "    if unique_dims is not None and counts is not None:\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"Dimensiones de Im√°genes ({PLANT_NAME} - {CATEGORY.upper()})\")\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"{'Dimensi√≥n':<15} {'Conteo':>10}\")\n",
        "        print(\"-\" * 27)\n",
        "        for dim, count in zip(unique_dims, counts):\n",
        "            print(f\"{f'{dim[0]}x{dim[1]}':<15} {count:>10}\")\n",
        "        print(f\"\\nTotal im√°genes procesadas: {total_dims}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### ***Segmented***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ***Apple***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Procesando im√°genes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3171/3171 [00:00<00:00, 4925.75it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============================\n",
            "Dimensiones de Im√°genes (Apple - SEGMENTED)\n",
            "==============================\n",
            "Dimensi√≥n           Conteo\n",
            "---------------------------\n",
            "256x256               3171\n",
            "\n",
            "Total im√°genes procesadas: 3171\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import cupy as cp\n",
        "import numpy as np\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ruta del dataset local\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "# Nombre de la planta a procesar\n",
        "PLANT_NAME = \"Apple\"\n",
        "# Categor√≠a a procesar\n",
        "CATEGORY = \"segmented\"\n",
        "# N√∫mero de hilos para paralelizaci√≥n\n",
        "MAX_WORKERS = 16\n",
        "\n",
        "def collect_image_paths(directory):\n",
        "    file_paths = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        if PLANT_NAME in root:\n",
        "            for file in files:\n",
        "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    file_paths.append(os.path.join(root, file))\n",
        "    return file_paths\n",
        "\n",
        "def process_image(file_path):\n",
        "    try:\n",
        "        with Image.open(file_path) as img:\n",
        "            return (img.size[0], img.size[1])\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def analyze_plant_dimensions():\n",
        "    category_path = os.path.join(DATASET_PATH, CATEGORY, PLANT_NAME)\n",
        "    if not os.path.exists(category_path):\n",
        "        print(f\"Error: No se encontr√≥ la carpeta {category_path}.\")\n",
        "        return None, None, 0\n",
        "    \n",
        "    file_paths = collect_image_paths(category_path)\n",
        "    dimensions = []\n",
        "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "        # Usar tqdm para mostrar progreso\n",
        "        with tqdm(total=len(file_paths), desc=\"Procesando im√°genes\") as pbar:\n",
        "            for dim in executor.map(process_image, file_paths):\n",
        "                if dim is not None:\n",
        "                    dimensions.append(dim)\n",
        "                pbar.update(1)\n",
        "    \n",
        "    try:\n",
        "        dim_array = cp.array(dimensions, dtype=cp.int32)\n",
        "        unique_dims, counts = np.unique(dim_array.get(), axis=0, return_counts=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error en el c√°lculo de dimensiones: {e}\")\n",
        "        return None, None, len(dimensions)\n",
        "    \n",
        "    return unique_dims, counts, len(dimensions)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unique_dims, counts, total_dims = analyze_plant_dimensions()\n",
        "    if unique_dims is not None and counts is not None:\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"Dimensiones de Im√°genes ({PLANT_NAME} - {CATEGORY.upper()})\")\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"{'Dimensi√≥n':<15} {'Conteo':>10}\")\n",
        "        print(\"-\" * 27)\n",
        "        for dim, count in zip(unique_dims, counts):\n",
        "            print(f\"{f'{dim[0]}x{dim[1]}':<15} {count:>10}\")\n",
        "        print(f\"\\nTotal im√°genes procesadas: {total_dims}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ***Blueberry***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Procesando im√°genes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1502/1502 [00:00<00:00, 4747.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============================\n",
            "Dimensiones de Im√°genes (Blueberry - SEGMENTED)\n",
            "==============================\n",
            "Dimensi√≥n           Conteo\n",
            "---------------------------\n",
            "256x256               1502\n",
            "\n",
            "Total im√°genes procesadas: 1502\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import cupy as cp\n",
        "import numpy as np\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ruta del dataset local\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "# Nombre de la planta a procesar\n",
        "PLANT_NAME = \"Blueberry\"\n",
        "# Categor√≠a a procesar\n",
        "CATEGORY = \"segmented\"\n",
        "# N√∫mero de hilos para paralelizaci√≥n\n",
        "MAX_WORKERS = 16\n",
        "\n",
        "def collect_image_paths(directory):\n",
        "    file_paths = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        if PLANT_NAME in root:\n",
        "            for file in files:\n",
        "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    file_paths.append(os.path.join(root, file))\n",
        "    return file_paths\n",
        "\n",
        "def process_image(file_path):\n",
        "    try:\n",
        "        with Image.open(file_path) as img:\n",
        "            return (img.size[0], img.size[1])\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def analyze_plant_dimensions():\n",
        "    category_path = os.path.join(DATASET_PATH, CATEGORY, PLANT_NAME)\n",
        "    if not os.path.exists(category_path):\n",
        "        print(f\"Error: No se encontr√≥ la carpeta {category_path}.\")\n",
        "        return None, None, 0\n",
        "    \n",
        "    file_paths = collect_image_paths(category_path)\n",
        "    dimensions = []\n",
        "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "        # Usar tqdm para mostrar progreso\n",
        "        with tqdm(total=len(file_paths), desc=\"Procesando im√°genes\") as pbar:\n",
        "            for dim in executor.map(process_image, file_paths):\n",
        "                if dim is not None:\n",
        "                    dimensions.append(dim)\n",
        "                pbar.update(1)\n",
        "    \n",
        "    try:\n",
        "        dim_array = cp.array(dimensions, dtype=cp.int32)\n",
        "        unique_dims, counts = np.unique(dim_array.get(), axis=0, return_counts=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error en el c√°lculo de dimensiones: {e}\")\n",
        "        return None, None, len(dimensions)\n",
        "    \n",
        "    return unique_dims, counts, len(dimensions)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unique_dims, counts, total_dims = analyze_plant_dimensions()\n",
        "    if unique_dims is not None and counts is not None:\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"Dimensiones de Im√°genes ({PLANT_NAME} - {CATEGORY.upper()})\")\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"{'Dimensi√≥n':<15} {'Conteo':>10}\")\n",
        "        print(\"-\" * 27)\n",
        "        for dim, count in zip(unique_dims, counts):\n",
        "            print(f\"{f'{dim[0]}x{dim[1]}':<15} {count:>10}\")\n",
        "        print(f\"\\nTotal im√°genes procesadas: {total_dims}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ***Cherry***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Procesando im√°genes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1906/1906 [00:00<00:00, 5193.47it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============================\n",
            "Dimensiones de Im√°genes (Cherry - SEGMENTED)\n",
            "==============================\n",
            "Dimensi√≥n           Conteo\n",
            "---------------------------\n",
            "256x256               1906\n",
            "\n",
            "Total im√°genes procesadas: 1906\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import cupy as cp\n",
        "import numpy as np\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ruta del dataset local\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "# Nombre de la planta a procesar\n",
        "PLANT_NAME = \"Cherry\"\n",
        "# Categor√≠a a procesar\n",
        "CATEGORY = \"segmented\"\n",
        "# N√∫mero de hilos para paralelizaci√≥n\n",
        "MAX_WORKERS = 16\n",
        "\n",
        "def collect_image_paths(directory):\n",
        "    file_paths = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        if PLANT_NAME in root:\n",
        "            for file in files:\n",
        "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    file_paths.append(os.path.join(root, file))\n",
        "    return file_paths\n",
        "\n",
        "def process_image(file_path):\n",
        "    try:\n",
        "        with Image.open(file_path) as img:\n",
        "            return (img.size[0], img.size[1])\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def analyze_plant_dimensions():\n",
        "    category_path = os.path.join(DATASET_PATH, CATEGORY, PLANT_NAME)\n",
        "    if not os.path.exists(category_path):\n",
        "        print(f\"Error: No se encontr√≥ la carpeta {category_path}.\")\n",
        "        return None, None, 0\n",
        "    \n",
        "    file_paths = collect_image_paths(category_path)\n",
        "    dimensions = []\n",
        "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "        # Usar tqdm para mostrar progreso\n",
        "        with tqdm(total=len(file_paths), desc=\"Procesando im√°genes\") as pbar:\n",
        "            for dim in executor.map(process_image, file_paths):\n",
        "                if dim is not None:\n",
        "                    dimensions.append(dim)\n",
        "                pbar.update(1)\n",
        "    \n",
        "    try:\n",
        "        dim_array = cp.array(dimensions, dtype=cp.int32)\n",
        "        unique_dims, counts = np.unique(dim_array.get(), axis=0, return_counts=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error en el c√°lculo de dimensiones: {e}\")\n",
        "        return None, None, len(dimensions)\n",
        "    \n",
        "    return unique_dims, counts, len(dimensions)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unique_dims, counts, total_dims = analyze_plant_dimensions()\n",
        "    if unique_dims is not None and counts is not None:\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"Dimensiones de Im√°genes ({PLANT_NAME} - {CATEGORY.upper()})\")\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"{'Dimensi√≥n':<15} {'Conteo':>10}\")\n",
        "        print(\"-\" * 27)\n",
        "        for dim, count in zip(unique_dims, counts):\n",
        "            print(f\"{f'{dim[0]}x{dim[1]}':<15} {count:>10}\")\n",
        "        print(f\"\\nTotal im√°genes procesadas: {total_dims}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ***Corn***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Procesando im√°genes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3852/3852 [00:01<00:00, 3468.22it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============================\n",
            "Dimensiones de Im√°genes (Corn - SEGMENTED)\n",
            "==============================\n",
            "Dimensi√≥n           Conteo\n",
            "---------------------------\n",
            "256x256               3852\n",
            "\n",
            "Total im√°genes procesadas: 3852\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import cupy as cp\n",
        "import numpy as np\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ruta del dataset local\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "# Nombre de la planta a procesar\n",
        "PLANT_NAME = \"Corn\"\n",
        "# Categor√≠a a procesar\n",
        "CATEGORY = \"segmented\"\n",
        "# N√∫mero de hilos para paralelizaci√≥n\n",
        "MAX_WORKERS = 16\n",
        "\n",
        "def collect_image_paths(directory):\n",
        "    file_paths = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        if PLANT_NAME in root:\n",
        "            for file in files:\n",
        "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    file_paths.append(os.path.join(root, file))\n",
        "    return file_paths\n",
        "\n",
        "def process_image(file_path):\n",
        "    try:\n",
        "        with Image.open(file_path) as img:\n",
        "            return (img.size[0], img.size[1])\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def analyze_plant_dimensions():\n",
        "    category_path = os.path.join(DATASET_PATH, CATEGORY, PLANT_NAME)\n",
        "    if not os.path.exists(category_path):\n",
        "        print(f\"Error: No se encontr√≥ la carpeta {category_path}.\")\n",
        "        return None, None, 0\n",
        "    \n",
        "    file_paths = collect_image_paths(category_path)\n",
        "    dimensions = []\n",
        "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "        # Usar tqdm para mostrar progreso\n",
        "        with tqdm(total=len(file_paths), desc=\"Procesando im√°genes\") as pbar:\n",
        "            for dim in executor.map(process_image, file_paths):\n",
        "                if dim is not None:\n",
        "                    dimensions.append(dim)\n",
        "                pbar.update(1)\n",
        "    \n",
        "    try:\n",
        "        dim_array = cp.array(dimensions, dtype=cp.int32)\n",
        "        unique_dims, counts = np.unique(dim_array.get(), axis=0, return_counts=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error en el c√°lculo de dimensiones: {e}\")\n",
        "        return None, None, len(dimensions)\n",
        "    \n",
        "    return unique_dims, counts, len(dimensions)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unique_dims, counts, total_dims = analyze_plant_dimensions()\n",
        "    if unique_dims is not None and counts is not None:\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"Dimensiones de Im√°genes ({PLANT_NAME} - {CATEGORY.upper()})\")\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"{'Dimensi√≥n':<15} {'Conteo':>10}\")\n",
        "        print(\"-\" * 27)\n",
        "        for dim, count in zip(unique_dims, counts):\n",
        "            print(f\"{f'{dim[0]}x{dim[1]}':<15} {count:>10}\")\n",
        "        print(f\"\\nTotal im√°genes procesadas: {total_dims}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ***Grape***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Procesando im√°genes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4063/4063 [00:00<00:00, 4969.45it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============================\n",
            "Dimensiones de Im√°genes (Grape - SEGMENTED)\n",
            "==============================\n",
            "Dimensi√≥n           Conteo\n",
            "---------------------------\n",
            "256x256               4063\n",
            "\n",
            "Total im√°genes procesadas: 4063\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import cupy as cp\n",
        "import numpy as np\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ruta del dataset local\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "# Nombre de la planta a procesar\n",
        "PLANT_NAME = \"Grape\"\n",
        "# Categor√≠a a procesar\n",
        "CATEGORY = \"segmented\"\n",
        "# N√∫mero de hilos para paralelizaci√≥n\n",
        "MAX_WORKERS = 16\n",
        "\n",
        "def collect_image_paths(directory):\n",
        "    file_paths = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        if PLANT_NAME in root:\n",
        "            for file in files:\n",
        "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    file_paths.append(os.path.join(root, file))\n",
        "    return file_paths\n",
        "\n",
        "def process_image(file_path):\n",
        "    try:\n",
        "        with Image.open(file_path) as img:\n",
        "            return (img.size[0], img.size[1])\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def analyze_plant_dimensions():\n",
        "    category_path = os.path.join(DATASET_PATH, CATEGORY, PLANT_NAME)\n",
        "    if not os.path.exists(category_path):\n",
        "        print(f\"Error: No se encontr√≥ la carpeta {category_path}.\")\n",
        "        return None, None, 0\n",
        "    \n",
        "    file_paths = collect_image_paths(category_path)\n",
        "    dimensions = []\n",
        "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "        # Usar tqdm para mostrar progreso\n",
        "        with tqdm(total=len(file_paths), desc=\"Procesando im√°genes\") as pbar:\n",
        "            for dim in executor.map(process_image, file_paths):\n",
        "                if dim is not None:\n",
        "                    dimensions.append(dim)\n",
        "                pbar.update(1)\n",
        "    \n",
        "    try:\n",
        "        dim_array = cp.array(dimensions, dtype=cp.int32)\n",
        "        unique_dims, counts = np.unique(dim_array.get(), axis=0, return_counts=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error en el c√°lculo de dimensiones: {e}\")\n",
        "        return None, None, len(dimensions)\n",
        "    \n",
        "    return unique_dims, counts, len(dimensions)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unique_dims, counts, total_dims = analyze_plant_dimensions()\n",
        "    if unique_dims is not None and counts is not None:\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"Dimensiones de Im√°genes ({PLANT_NAME} - {CATEGORY.upper()})\")\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"{'Dimensi√≥n':<15} {'Conteo':>10}\")\n",
        "        print(\"-\" * 27)\n",
        "        for dim, count in zip(unique_dims, counts):\n",
        "            print(f\"{f'{dim[0]}x{dim[1]}':<15} {count:>10}\")\n",
        "        print(f\"\\nTotal im√°genes procesadas: {total_dims}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ***Orange***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Procesando im√°genes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5507/5507 [00:01<00:00, 5067.89it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============================\n",
            "Dimensiones de Im√°genes (Orange - SEGMENTED)\n",
            "==============================\n",
            "Dimensi√≥n           Conteo\n",
            "---------------------------\n",
            "256x256               5507\n",
            "\n",
            "Total im√°genes procesadas: 5507\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import cupy as cp\n",
        "import numpy as np\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ruta del dataset local\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "# Nombre de la planta a procesar\n",
        "PLANT_NAME = \"Orange\"\n",
        "# Categor√≠a a procesar\n",
        "CATEGORY = \"segmented\"\n",
        "# N√∫mero de hilos para paralelizaci√≥n\n",
        "MAX_WORKERS = 16\n",
        "\n",
        "def collect_image_paths(directory):\n",
        "    file_paths = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        if PLANT_NAME in root:\n",
        "            for file in files:\n",
        "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    file_paths.append(os.path.join(root, file))\n",
        "    return file_paths\n",
        "\n",
        "def process_image(file_path):\n",
        "    try:\n",
        "        with Image.open(file_path) as img:\n",
        "            return (img.size[0], img.size[1])\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def analyze_plant_dimensions():\n",
        "    category_path = os.path.join(DATASET_PATH, CATEGORY, PLANT_NAME)\n",
        "    if not os.path.exists(category_path):\n",
        "        print(f\"Error: No se encontr√≥ la carpeta {category_path}.\")\n",
        "        return None, None, 0\n",
        "    \n",
        "    file_paths = collect_image_paths(category_path)\n",
        "    dimensions = []\n",
        "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "        # Usar tqdm para mostrar progreso\n",
        "        with tqdm(total=len(file_paths), desc=\"Procesando im√°genes\") as pbar:\n",
        "            for dim in executor.map(process_image, file_paths):\n",
        "                if dim is not None:\n",
        "                    dimensions.append(dim)\n",
        "                pbar.update(1)\n",
        "    \n",
        "    try:\n",
        "        dim_array = cp.array(dimensions, dtype=cp.int32)\n",
        "        unique_dims, counts = np.unique(dim_array.get(), axis=0, return_counts=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error en el c√°lculo de dimensiones: {e}\")\n",
        "        return None, None, len(dimensions)\n",
        "    \n",
        "    return unique_dims, counts, len(dimensions)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unique_dims, counts, total_dims = analyze_plant_dimensions()\n",
        "    if unique_dims is not None and counts is not None:\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"Dimensiones de Im√°genes ({PLANT_NAME} - {CATEGORY.upper()})\")\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"{'Dimensi√≥n':<15} {'Conteo':>10}\")\n",
        "        print(\"-\" * 27)\n",
        "        for dim, count in zip(unique_dims, counts):\n",
        "            print(f\"{f'{dim[0]}x{dim[1]}':<15} {count:>10}\")\n",
        "        print(f\"\\nTotal im√°genes procesadas: {total_dims}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ***Peach***\n",
        "(Otras dimensiones aparte de: 256x 256)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Procesando im√°genes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2657/2657 [00:00<00:00, 5261.41it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============================\n",
            "Dimensiones de Im√°genes (Peach - SEGMENTED)\n",
            "==============================\n",
            "Dimensi√≥n           Conteo\n",
            "---------------------------\n",
            "256x256               2655\n",
            "324x512                  1\n",
            "466x512                  1\n",
            "\n",
            "Total im√°genes procesadas: 2657\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import cupy as cp\n",
        "import numpy as np\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ruta del dataset local\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "# Nombre de la planta a procesar\n",
        "PLANT_NAME = \"Peach\"\n",
        "# Categor√≠a a procesar\n",
        "CATEGORY = \"segmented\"\n",
        "# N√∫mero de hilos para paralelizaci√≥n\n",
        "MAX_WORKERS = 16\n",
        "\n",
        "def collect_image_paths(directory):\n",
        "    file_paths = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        if PLANT_NAME in root:\n",
        "            for file in files:\n",
        "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    file_paths.append(os.path.join(root, file))\n",
        "    return file_paths\n",
        "\n",
        "def process_image(file_path):\n",
        "    try:\n",
        "        with Image.open(file_path) as img:\n",
        "            return (img.size[0], img.size[1])\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def analyze_plant_dimensions():\n",
        "    category_path = os.path.join(DATASET_PATH, CATEGORY, PLANT_NAME)\n",
        "    if not os.path.exists(category_path):\n",
        "        print(f\"Error: No se encontr√≥ la carpeta {category_path}.\")\n",
        "        return None, None, 0\n",
        "    \n",
        "    file_paths = collect_image_paths(category_path)\n",
        "    dimensions = []\n",
        "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "        # Usar tqdm para mostrar progreso\n",
        "        with tqdm(total=len(file_paths), desc=\"Procesando im√°genes\") as pbar:\n",
        "            for dim in executor.map(process_image, file_paths):\n",
        "                if dim is not None:\n",
        "                    dimensions.append(dim)\n",
        "                pbar.update(1)\n",
        "    \n",
        "    try:\n",
        "        dim_array = cp.array(dimensions, dtype=cp.int32)\n",
        "        unique_dims, counts = np.unique(dim_array.get(), axis=0, return_counts=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error en el c√°lculo de dimensiones: {e}\")\n",
        "        return None, None, len(dimensions)\n",
        "    \n",
        "    return unique_dims, counts, len(dimensions)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unique_dims, counts, total_dims = analyze_plant_dimensions()\n",
        "    if unique_dims is not None and counts is not None:\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"Dimensiones de Im√°genes ({PLANT_NAME} - {CATEGORY.upper()})\")\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"{'Dimensi√≥n':<15} {'Conteo':>10}\")\n",
        "        print(\"-\" * 27)\n",
        "        for dim, count in zip(unique_dims, counts):\n",
        "            print(f\"{f'{dim[0]}x{dim[1]}':<15} {count:>10}\")\n",
        "        print(f\"\\nTotal im√°genes procesadas: {total_dims}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ***Pepper***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Procesando im√°genes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2475/2475 [00:00<00:00, 5333.59it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============================\n",
            "Dimensiones de Im√°genes (Pepper - SEGMENTED)\n",
            "==============================\n",
            "Dimensi√≥n           Conteo\n",
            "---------------------------\n",
            "256x256               2475\n",
            "\n",
            "Total im√°genes procesadas: 2475\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import cupy as cp\n",
        "import numpy as np\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ruta del dataset local\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "# Nombre de la planta a procesar\n",
        "PLANT_NAME = \"Pepper\"\n",
        "# Categor√≠a a procesar\n",
        "CATEGORY = \"segmented\"\n",
        "# N√∫mero de hilos para paralelizaci√≥n\n",
        "MAX_WORKERS = 16\n",
        "\n",
        "def collect_image_paths(directory):\n",
        "    file_paths = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        if PLANT_NAME in root:\n",
        "            for file in files:\n",
        "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    file_paths.append(os.path.join(root, file))\n",
        "    return file_paths\n",
        "\n",
        "def process_image(file_path):\n",
        "    try:\n",
        "        with Image.open(file_path) as img:\n",
        "            return (img.size[0], img.size[1])\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def analyze_plant_dimensions():\n",
        "    category_path = os.path.join(DATASET_PATH, CATEGORY, PLANT_NAME)\n",
        "    if not os.path.exists(category_path):\n",
        "        print(f\"Error: No se encontr√≥ la carpeta {category_path}.\")\n",
        "        return None, None, 0\n",
        "    \n",
        "    file_paths = collect_image_paths(category_path)\n",
        "    dimensions = []\n",
        "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "        # Usar tqdm para mostrar progreso\n",
        "        with tqdm(total=len(file_paths), desc=\"Procesando im√°genes\") as pbar:\n",
        "            for dim in executor.map(process_image, file_paths):\n",
        "                if dim is not None:\n",
        "                    dimensions.append(dim)\n",
        "                pbar.update(1)\n",
        "    \n",
        "    try:\n",
        "        dim_array = cp.array(dimensions, dtype=cp.int32)\n",
        "        unique_dims, counts = np.unique(dim_array.get(), axis=0, return_counts=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error en el c√°lculo de dimensiones: {e}\")\n",
        "        return None, None, len(dimensions)\n",
        "    \n",
        "    return unique_dims, counts, len(dimensions)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unique_dims, counts, total_dims = analyze_plant_dimensions()\n",
        "    if unique_dims is not None and counts is not None:\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"Dimensiones de Im√°genes ({PLANT_NAME} - {CATEGORY.upper()})\")\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"{'Dimensi√≥n':<15} {'Conteo':>10}\")\n",
        "        print(\"-\" * 27)\n",
        "        for dim, count in zip(unique_dims, counts):\n",
        "            print(f\"{f'{dim[0]}x{dim[1]}':<15} {count:>10}\")\n",
        "        print(f\"\\nTotal im√°genes procesadas: {total_dims}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ***Potato***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Procesando im√°genes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2152/2152 [00:00<00:00, 5096.48it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============================\n",
            "Dimensiones de Im√°genes (Potato - SEGMENTED)\n",
            "==============================\n",
            "Dimensi√≥n           Conteo\n",
            "---------------------------\n",
            "256x256               2152\n",
            "\n",
            "Total im√°genes procesadas: 2152\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import cupy as cp\n",
        "import numpy as np\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ruta del dataset local\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "# Nombre de la planta a procesar\n",
        "PLANT_NAME = \"Potato\"\n",
        "# Categor√≠a a procesar\n",
        "CATEGORY = \"segmented\"\n",
        "# N√∫mero de hilos para paralelizaci√≥n\n",
        "MAX_WORKERS = 16\n",
        "\n",
        "def collect_image_paths(directory):\n",
        "    file_paths = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        if PLANT_NAME in root:\n",
        "            for file in files:\n",
        "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    file_paths.append(os.path.join(root, file))\n",
        "    return file_paths\n",
        "\n",
        "def process_image(file_path):\n",
        "    try:\n",
        "        with Image.open(file_path) as img:\n",
        "            return (img.size[0], img.size[1])\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def analyze_plant_dimensions():\n",
        "    category_path = os.path.join(DATASET_PATH, CATEGORY, PLANT_NAME)\n",
        "    if not os.path.exists(category_path):\n",
        "        print(f\"Error: No se encontr√≥ la carpeta {category_path}.\")\n",
        "        return None, None, 0\n",
        "    \n",
        "    file_paths = collect_image_paths(category_path)\n",
        "    dimensions = []\n",
        "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "        # Usar tqdm para mostrar progreso\n",
        "        with tqdm(total=len(file_paths), desc=\"Procesando im√°genes\") as pbar:\n",
        "            for dim in executor.map(process_image, file_paths):\n",
        "                if dim is not None:\n",
        "                    dimensions.append(dim)\n",
        "                pbar.update(1)\n",
        "    \n",
        "    try:\n",
        "        dim_array = cp.array(dimensions, dtype=cp.int32)\n",
        "        unique_dims, counts = np.unique(dim_array.get(), axis=0, return_counts=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error en el c√°lculo de dimensiones: {e}\")\n",
        "        return None, None, len(dimensions)\n",
        "    \n",
        "    return unique_dims, counts, len(dimensions)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unique_dims, counts, total_dims = analyze_plant_dimensions()\n",
        "    if unique_dims is not None and counts is not None:\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"Dimensiones de Im√°genes ({PLANT_NAME} - {CATEGORY.upper()})\")\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"{'Dimensi√≥n':<15} {'Conteo':>10}\")\n",
        "        print(\"-\" * 27)\n",
        "        for dim, count in zip(unique_dims, counts):\n",
        "            print(f\"{f'{dim[0]}x{dim[1]}':<15} {count:>10}\")\n",
        "        print(f\"\\nTotal im√°genes procesadas: {total_dims}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ***Raspberry***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Procesando im√°genes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 371/371 [00:00<00:00, 4685.99it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============================\n",
            "Dimensiones de Im√°genes (Raspberry - SEGMENTED)\n",
            "==============================\n",
            "Dimensi√≥n           Conteo\n",
            "---------------------------\n",
            "256x256                371\n",
            "\n",
            "Total im√°genes procesadas: 371\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import cupy as cp\n",
        "import numpy as np\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ruta del dataset local\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "# Nombre de la planta a procesar\n",
        "PLANT_NAME = \"Raspberry\"\n",
        "# Categor√≠a a procesar\n",
        "CATEGORY = \"segmented\"\n",
        "# N√∫mero de hilos para paralelizaci√≥n\n",
        "MAX_WORKERS = 16\n",
        "\n",
        "def collect_image_paths(directory):\n",
        "    file_paths = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        if PLANT_NAME in root:\n",
        "            for file in files:\n",
        "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    file_paths.append(os.path.join(root, file))\n",
        "    return file_paths\n",
        "\n",
        "def process_image(file_path):\n",
        "    try:\n",
        "        with Image.open(file_path) as img:\n",
        "            return (img.size[0], img.size[1])\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def analyze_plant_dimensions():\n",
        "    category_path = os.path.join(DATASET_PATH, CATEGORY, PLANT_NAME)\n",
        "    if not os.path.exists(category_path):\n",
        "        print(f\"Error: No se encontr√≥ la carpeta {category_path}.\")\n",
        "        return None, None, 0\n",
        "    \n",
        "    file_paths = collect_image_paths(category_path)\n",
        "    dimensions = []\n",
        "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "        # Usar tqdm para mostrar progreso\n",
        "        with tqdm(total=len(file_paths), desc=\"Procesando im√°genes\") as pbar:\n",
        "            for dim in executor.map(process_image, file_paths):\n",
        "                if dim is not None:\n",
        "                    dimensions.append(dim)\n",
        "                pbar.update(1)\n",
        "    \n",
        "    try:\n",
        "        dim_array = cp.array(dimensions, dtype=cp.int32)\n",
        "        unique_dims, counts = np.unique(dim_array.get(), axis=0, return_counts=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error en el c√°lculo de dimensiones: {e}\")\n",
        "        return None, None, len(dimensions)\n",
        "    \n",
        "    return unique_dims, counts, len(dimensions)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unique_dims, counts, total_dims = analyze_plant_dimensions()\n",
        "    if unique_dims is not None and counts is not None:\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"Dimensiones de Im√°genes ({PLANT_NAME} - {CATEGORY.upper()})\")\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"{'Dimensi√≥n':<15} {'Conteo':>10}\")\n",
        "        print(\"-\" * 27)\n",
        "        for dim, count in zip(unique_dims, counts):\n",
        "            print(f\"{f'{dim[0]}x{dim[1]}':<15} {count:>10}\")\n",
        "        print(f\"\\nTotal im√°genes procesadas: {total_dims}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ***Soybean***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Procesando im√°genes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5090/5090 [00:00<00:00, 5365.50it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============================\n",
            "Dimensiones de Im√°genes (Soybean - SEGMENTED)\n",
            "==============================\n",
            "Dimensi√≥n           Conteo\n",
            "---------------------------\n",
            "256x256               5090\n",
            "\n",
            "Total im√°genes procesadas: 5090\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import cupy as cp\n",
        "import numpy as np\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ruta del dataset local\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "# Nombre de la planta a procesar\n",
        "PLANT_NAME = \"Soybean\"\n",
        "# Categor√≠a a procesar\n",
        "CATEGORY = \"segmented\"\n",
        "# N√∫mero de hilos para paralelizaci√≥n\n",
        "MAX_WORKERS = 16\n",
        "\n",
        "def collect_image_paths(directory):\n",
        "    file_paths = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        if PLANT_NAME in root:\n",
        "            for file in files:\n",
        "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    file_paths.append(os.path.join(root, file))\n",
        "    return file_paths\n",
        "\n",
        "def process_image(file_path):\n",
        "    try:\n",
        "        with Image.open(file_path) as img:\n",
        "            return (img.size[0], img.size[1])\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def analyze_plant_dimensions():\n",
        "    category_path = os.path.join(DATASET_PATH, CATEGORY, PLANT_NAME)\n",
        "    if not os.path.exists(category_path):\n",
        "        print(f\"Error: No se encontr√≥ la carpeta {category_path}.\")\n",
        "        return None, None, 0\n",
        "    \n",
        "    file_paths = collect_image_paths(category_path)\n",
        "    dimensions = []\n",
        "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "        # Usar tqdm para mostrar progreso\n",
        "        with tqdm(total=len(file_paths), desc=\"Procesando im√°genes\") as pbar:\n",
        "            for dim in executor.map(process_image, file_paths):\n",
        "                if dim is not None:\n",
        "                    dimensions.append(dim)\n",
        "                pbar.update(1)\n",
        "    \n",
        "    try:\n",
        "        dim_array = cp.array(dimensions, dtype=cp.int32)\n",
        "        unique_dims, counts = np.unique(dim_array.get(), axis=0, return_counts=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error en el c√°lculo de dimensiones: {e}\")\n",
        "        return None, None, len(dimensions)\n",
        "    \n",
        "    return unique_dims, counts, len(dimensions)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unique_dims, counts, total_dims = analyze_plant_dimensions()\n",
        "    if unique_dims is not None and counts is not None:\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"Dimensiones de Im√°genes ({PLANT_NAME} - {CATEGORY.upper()})\")\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"{'Dimensi√≥n':<15} {'Conteo':>10}\")\n",
        "        print(\"-\" * 27)\n",
        "        for dim, count in zip(unique_dims, counts):\n",
        "            print(f\"{f'{dim[0]}x{dim[1]}':<15} {count:>10}\")\n",
        "        print(f\"\\nTotal im√°genes procesadas: {total_dims}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ***Squash***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Procesando im√°genes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1835/1835 [00:00<00:00, 4558.84it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============================\n",
            "Dimensiones de Im√°genes (Squash - SEGMENTED)\n",
            "==============================\n",
            "Dimensi√≥n           Conteo\n",
            "---------------------------\n",
            "256x256               1835\n",
            "\n",
            "Total im√°genes procesadas: 1835\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import cupy as cp\n",
        "import numpy as np\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ruta del dataset local\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "# Nombre de la planta a procesar\n",
        "PLANT_NAME = \"Squash\"\n",
        "# Categor√≠a a procesar\n",
        "CATEGORY = \"segmented\"\n",
        "# N√∫mero de hilos para paralelizaci√≥n\n",
        "MAX_WORKERS = 16\n",
        "\n",
        "def collect_image_paths(directory):\n",
        "    file_paths = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        if PLANT_NAME in root:\n",
        "            for file in files:\n",
        "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    file_paths.append(os.path.join(root, file))\n",
        "    return file_paths\n",
        "\n",
        "def process_image(file_path):\n",
        "    try:\n",
        "        with Image.open(file_path) as img:\n",
        "            return (img.size[0], img.size[1])\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def analyze_plant_dimensions():\n",
        "    category_path = os.path.join(DATASET_PATH, CATEGORY, PLANT_NAME)\n",
        "    if not os.path.exists(category_path):\n",
        "        print(f\"Error: No se encontr√≥ la carpeta {category_path}.\")\n",
        "        return None, None, 0\n",
        "    \n",
        "    file_paths = collect_image_paths(category_path)\n",
        "    dimensions = []\n",
        "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "        # Usar tqdm para mostrar progreso\n",
        "        with tqdm(total=len(file_paths), desc=\"Procesando im√°genes\") as pbar:\n",
        "            for dim in executor.map(process_image, file_paths):\n",
        "                if dim is not None:\n",
        "                    dimensions.append(dim)\n",
        "                pbar.update(1)\n",
        "    \n",
        "    try:\n",
        "        dim_array = cp.array(dimensions, dtype=cp.int32)\n",
        "        unique_dims, counts = np.unique(dim_array.get(), axis=0, return_counts=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error en el c√°lculo de dimensiones: {e}\")\n",
        "        return None, None, len(dimensions)\n",
        "    \n",
        "    return unique_dims, counts, len(dimensions)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unique_dims, counts, total_dims = analyze_plant_dimensions()\n",
        "    if unique_dims is not None and counts is not None:\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"Dimensiones de Im√°genes ({PLANT_NAME} - {CATEGORY.upper()})\")\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"{'Dimensi√≥n':<15} {'Conteo':>10}\")\n",
        "        print(\"-\" * 27)\n",
        "        for dim, count in zip(unique_dims, counts):\n",
        "            print(f\"{f'{dim[0]}x{dim[1]}':<15} {count:>10}\")\n",
        "        print(f\"\\nTotal im√°genes procesadas: {total_dims}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ***Strawberry***\n",
        "(Otras dimensiones aparte de: 256x 256)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Procesando im√°genes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1565/1565 [00:00<00:00, 5115.83it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============================\n",
            "Dimensiones de Im√°genes (Strawberry - SEGMENTED)\n",
            "==============================\n",
            "Dimensi√≥n           Conteo\n",
            "---------------------------\n",
            "256x256               1564\n",
            "470x512                  1\n",
            "\n",
            "Total im√°genes procesadas: 1565\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import cupy as cp\n",
        "import numpy as np\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ruta del dataset local\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "# Nombre de la planta a procesar\n",
        "PLANT_NAME = \"Strawberry\"\n",
        "# Categor√≠a a procesar\n",
        "CATEGORY = \"segmented\"\n",
        "# N√∫mero de hilos para paralelizaci√≥n\n",
        "MAX_WORKERS = 16\n",
        "\n",
        "def collect_image_paths(directory):\n",
        "    file_paths = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        if PLANT_NAME in root:\n",
        "            for file in files:\n",
        "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    file_paths.append(os.path.join(root, file))\n",
        "    return file_paths\n",
        "\n",
        "def process_image(file_path):\n",
        "    try:\n",
        "        with Image.open(file_path) as img:\n",
        "            return (img.size[0], img.size[1])\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def analyze_plant_dimensions():\n",
        "    category_path = os.path.join(DATASET_PATH, CATEGORY, PLANT_NAME)\n",
        "    if not os.path.exists(category_path):\n",
        "        print(f\"Error: No se encontr√≥ la carpeta {category_path}.\")\n",
        "        return None, None, 0\n",
        "    \n",
        "    file_paths = collect_image_paths(category_path)\n",
        "    dimensions = []\n",
        "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "        # Usar tqdm para mostrar progreso\n",
        "        with tqdm(total=len(file_paths), desc=\"Procesando im√°genes\") as pbar:\n",
        "            for dim in executor.map(process_image, file_paths):\n",
        "                if dim is not None:\n",
        "                    dimensions.append(dim)\n",
        "                pbar.update(1)\n",
        "    \n",
        "    try:\n",
        "        dim_array = cp.array(dimensions, dtype=cp.int32)\n",
        "        unique_dims, counts = np.unique(dim_array.get(), axis=0, return_counts=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error en el c√°lculo de dimensiones: {e}\")\n",
        "        return None, None, len(dimensions)\n",
        "    \n",
        "    return unique_dims, counts, len(dimensions)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unique_dims, counts, total_dims = analyze_plant_dimensions()\n",
        "    if unique_dims is not None and counts is not None:\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"Dimensiones de Im√°genes ({PLANT_NAME} - {CATEGORY.upper()})\")\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"{'Dimensi√≥n':<15} {'Conteo':>10}\")\n",
        "        print(\"-\" * 27)\n",
        "        for dim, count in zip(unique_dims, counts):\n",
        "            print(f\"{f'{dim[0]}x{dim[1]}':<15} {count:>10}\")\n",
        "        print(f\"\\nTotal im√°genes procesadas: {total_dims}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ***Tomato***\n",
        "(Otras dimensiones aparte de: 256x 256)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Procesando im√°genes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18160/18160 [00:03<00:00, 5134.67it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============================\n",
            "Dimensiones de Im√°genes (Tomato - SEGMENTED)\n",
            "==============================\n",
            "Dimensi√≥n           Conteo\n",
            "---------------------------\n",
            "256x256              18159\n",
            "335x512                  1\n",
            "\n",
            "Total im√°genes procesadas: 18160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import cupy as cp\n",
        "import numpy as np\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ruta del dataset local\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "# Nombre de la planta a procesar\n",
        "PLANT_NAME = \"Tomato\"\n",
        "# Categor√≠a a procesar\n",
        "CATEGORY = \"segmented\"\n",
        "# N√∫mero de hilos para paralelizaci√≥n\n",
        "MAX_WORKERS = 16\n",
        "\n",
        "def collect_image_paths(directory):\n",
        "    file_paths = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        if PLANT_NAME in root:\n",
        "            for file in files:\n",
        "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    file_paths.append(os.path.join(root, file))\n",
        "    return file_paths\n",
        "\n",
        "def process_image(file_path):\n",
        "    try:\n",
        "        with Image.open(file_path) as img:\n",
        "            return (img.size[0], img.size[1])\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def analyze_plant_dimensions():\n",
        "    category_path = os.path.join(DATASET_PATH, CATEGORY, PLANT_NAME)\n",
        "    if not os.path.exists(category_path):\n",
        "        print(f\"Error: No se encontr√≥ la carpeta {category_path}.\")\n",
        "        return None, None, 0\n",
        "    \n",
        "    file_paths = collect_image_paths(category_path)\n",
        "    dimensions = []\n",
        "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "        # Usar tqdm para mostrar progreso\n",
        "        with tqdm(total=len(file_paths), desc=\"Procesando im√°genes\") as pbar:\n",
        "            for dim in executor.map(process_image, file_paths):\n",
        "                if dim is not None:\n",
        "                    dimensions.append(dim)\n",
        "                pbar.update(1)\n",
        "    \n",
        "    try:\n",
        "        dim_array = cp.array(dimensions, dtype=cp.int32)\n",
        "        unique_dims, counts = np.unique(dim_array.get(), axis=0, return_counts=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error en el c√°lculo de dimensiones: {e}\")\n",
        "        return None, None, len(dimensions)\n",
        "    \n",
        "    return unique_dims, counts, len(dimensions)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unique_dims, counts, total_dims = analyze_plant_dimensions()\n",
        "    if unique_dims is not None and counts is not None:\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"Dimensiones de Im√°genes ({PLANT_NAME} - {CATEGORY.upper()})\")\n",
        "        print(f\"{'=' * 30}\")\n",
        "        print(f\"{'Dimensi√≥n':<15} {'Conteo':>10}\")\n",
        "        print(\"-\" * 27)\n",
        "        for dim, count in zip(unique_dims, counts):\n",
        "            print(f\"{f'{dim[0]}x{dim[1]}':<15} {count:>10}\")\n",
        "        print(f\"\\nTotal im√°genes procesadas: {total_dims}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GinG_RKWsu7i"
      },
      "source": [
        "### ***Detecci√≥n de im√°genes corruptas o vac√≠as***\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADSdPZmkvFkX"
      },
      "source": [
        "Se realizar√° una revisi√≥n del dataset para identificar im√°genes corruptas o vac√≠as, con el objetivo de determinar si es necesario eliminarlas o corregirlas antes de continuar con el preprocesamiento y entrenamiento del modelo. Esta validaci√≥n es fundamental para garantizar la calidad y consistencia de los datos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jKQC_HICs7uJ",
        "outputId": "d47c7f98-4541-4acc-c944-ad6239d765db"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Recolectando im√°genes: 161it [00:00, 268.70it/s]\n",
            "Verificando im√°genes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 162916/162916 [01:07<00:00, 2430.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "====================\n",
            "Total im√°genes: 162916\n",
            "Im√°genes corruptas: 0\n",
            "‚úÖ No se encontraron im√°genes corruptas.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Configuraci√≥n\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "MAX_WORKERS = 16\n",
        "\n",
        "def collect_image_paths(input_dir):\n",
        "    \"\"\"Recolecta rutas de im√°genes .jpg, .jpeg y .png con barra de progreso.\"\"\"\n",
        "    file_paths = []\n",
        "    for root, _, files in tqdm(os.walk(input_dir), desc=\"Recolectando im√°genes\"):\n",
        "        for file in files:\n",
        "            if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                file_paths.append(os.path.join(root, file))\n",
        "    return file_paths\n",
        "\n",
        "def check_image(file_path):\n",
        "    \"\"\"Verifica si una imagen es v√°lida o est√° corrupta.\"\"\"\n",
        "    try:\n",
        "        if os.path.getsize(file_path) == 0:\n",
        "            return file_path, \"Archivo vac√≠o (0 bytes)\"\n",
        "        with Image.open(file_path) as img:\n",
        "            img.verify()\n",
        "            img = Image.open(file_path)\n",
        "            img.load()\n",
        "            if img.size[0] == 0 or img.size[1] == 0:\n",
        "                return file_path, \"Dimensiones inv√°lidas\"\n",
        "        return file_path, None\n",
        "    except Exception as e:\n",
        "        return file_path, f\"Error: {str(e)}\"\n",
        "\n",
        "def check_dataset(input_dir, max_workers=MAX_WORKERS):\n",
        "    \"\"\"Verifica im√°genes en paralelo y genera informe.\"\"\"\n",
        "    file_paths = collect_image_paths(input_dir)\n",
        "    corrupted_images = []\n",
        "\n",
        "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
        "        future_to_file = {executor.submit(check_image, path): path for path in file_paths}\n",
        "        for future in tqdm(as_completed(future_to_file), total=len(file_paths), desc=\"Verificando im√°genes\"):\n",
        "            file_path, error = future.result()\n",
        "            if error:\n",
        "                corrupted_images.append((file_path, error))\n",
        "\n",
        "    # Resumen\n",
        "    print(f\"\\n{'=' * 20}\")\n",
        "    print(f\"Total im√°genes: {len(file_paths)}\")\n",
        "    print(f\"Im√°genes corruptas: {len(corrupted_images)}\")\n",
        "    if corrupted_images:\n",
        "        print(\"\\nIm√°genes con problemas:\")\n",
        "        for file_path, error in corrupted_images:\n",
        "            print(f\"  {file_path}: {error}\")\n",
        "        output_file = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\corrupted_images.txt\"\n",
        "        with open(output_file, 'w') as f:\n",
        "            for file_path, _ in corrupted_images:\n",
        "                f.write(f\"{file_path}\\n\")\n",
        "        print(f\"\\nLista de im√°genes corruptas guardada en: {output_file}\")\n",
        "    else:\n",
        "        print(\"‚úÖ No se encontraron im√°genes corruptas.\")\n",
        "\n",
        "    return corrupted_images\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    check_dataset(DATASET_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLmw-dlbwf4u"
      },
      "source": [
        "### ***Buscar balanceo entre clases***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se analizar√° la distribuci√≥n de im√°genes entre las distintas clases ‚Äîo en este caso, entre los diferentes estados de salud de las plantas‚Äî con el objetivo de verificar si existe un balance adecuado.\n",
        "Este an√°lisis permitir√° identificar posibles desbalances que, en etapas posteriores, podr√≠an requerir t√©cnicas de reajuste de cantidades o asignaci√≥n de pesos por clase durante el entrenamiento del modelo, para evitar sesgos y mejorar el rendimiento general."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "***Conclusi√≥n del an√°lisis***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tras el an√°lisis realizado, se lleg√≥ a las siguientes conclusiones:\n",
        "\n",
        "Balance entre clases:\n",
        "Se observ√≥ un desbalance significativo en la cantidad de im√°genes entre distintas clases (estados de salud de las plantas). Esto indica que ser√° necesario aplicar t√©cnicas de balanceo, ya sea ajustando la cantidad de muestras por clase o utilizando pesos diferenciados durante el entrenamiento del modelo. Esta medida es crucial para evitar sesgos que afecten negativamente la capacidad de generalizaci√≥n del modelo, especialmente al emplear arquitecturas como ResNet.\n",
        "\n",
        "Verificaci√≥n de im√°genes corruptas o vac√≠as:\n",
        "Se ejecut√≥ un script para identificar im√°genes que presentaran errores como archivos vac√≠os, da√±os en la codificaci√≥n o dimensiones inv√°lidas.\n",
        "El resultado mostr√≥ que existen im√°genes corruptas en el dataset, por lo que ser√° necesario eliminarlas o corregirlas antes de continuar con el preprocesamiento.\n",
        "Se gener√≥ un archivo con la lista de im√°genes problem√°ticas para facilitar su depuraci√≥n:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Nk-NcmgYwkXP",
        "outputId": "2de07558-24aa-493e-add5-24c00363a9da"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Procesando subdirectorios: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00, 14.42it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "====================\n",
            "Total im√°genes: 162916\n",
            "Total clases: 114\n",
            "Media de im√°genes por clase: 1429.09\n",
            "Desviaci√≥n est√°ndar: 1260.43\n",
            "M√≠nimo: 152 (color_Potato_Potato___healthy)\n",
            "M√°ximo: 5507 (color_Orange_Orange___Haunglongbing_(Citrus_greening))\n",
            "Relaci√≥n de desbalance: 36.23\n",
            "‚ö†Ô∏è Dataset desbalanceado. Considera balancear las clases.\n",
            "Conteo guardado en: C:\\Users\\Arys\\Desktop\\Proyecto - 2\\class_counts.csv\n",
            "\n",
            "Clases con m√°s im√°genes:\n",
            "                                                    Class  Count\n",
            "    color_Orange_Orange___Haunglongbing_(Citrus_greening)   5507\n",
            "grayscale_Orange_Orange___Haunglongbing_(Citrus_greening)   5507\n",
            "segmented_Orange_Orange___Haunglongbing_(Citrus_greening)   5507\n",
            "  segmented_Tomato_Tomato___Tomato_Yellow_Leaf_Curl_Virus   5357\n",
            "  grayscale_Tomato_Tomato___Tomato_Yellow_Leaf_Curl_Virus   5357\n",
            "\n",
            "Clases con menos im√°genes:\n",
            "                                   Class  Count\n",
            "grayscale_Apple_Apple___Cedar_apple_rust    275\n",
            "segmented_Apple_Apple___Cedar_apple_rust    275\n",
            "           color_Potato_Potato___healthy    152\n",
            "       grayscale_Potato_Potato___healthy    152\n",
            "       segmented_Potato_Potato___healthy    152\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Configuraci√≥n\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "MAX_WORKERS = 16\n",
        "OUTPUT_CSV = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\class_counts.csv\"\n",
        "\n",
        "def collect_class_counts(input_dir):\n",
        "    \"\"\"Recolecta conteos de im√°genes .jpg, .jpeg y .png por clase con barra de progreso.\"\"\"\n",
        "    class_counts = {}\n",
        "    subdirs = ['color', 'grayscale', 'segmented']\n",
        "\n",
        "    for subdir in tqdm(subdirs, desc=\"Procesando subdirectorios\"):\n",
        "        subdir_path = os.path.join(input_dir, subdir)\n",
        "        if not os.path.exists(subdir_path):\n",
        "            continue\n",
        "\n",
        "        for plant in os.listdir(subdir_path):\n",
        "            plant_path = os.path.join(subdir_path, plant)\n",
        "            if not os.path.isdir(plant_path):\n",
        "                continue\n",
        "\n",
        "            for state in os.listdir(plant_path):\n",
        "                state_path = os.path.join(plant_path, state)\n",
        "                if not os.path.isdir(state_path):\n",
        "                    continue\n",
        "\n",
        "                images = [f for f in os.listdir(state_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "                if images:\n",
        "                    class_name = f\"{subdir}_{plant}_{state}\"\n",
        "                    class_counts[class_name] = len(images)\n",
        "\n",
        "    return class_counts\n",
        "\n",
        "def generate_balance_report(class_counts):\n",
        "    \"\"\"Genera informe de balance de clases.\"\"\"\n",
        "    if not class_counts:\n",
        "        print(\"Error: No se encontraron clases con im√°genes.\")\n",
        "        return\n",
        "\n",
        "    # Convertir a DataFrame y ordenar\n",
        "    df = pd.DataFrame(list(class_counts.items()), columns=['Class', 'Count']).sort_values(by='Count', ascending=False)\n",
        "\n",
        "    # Estad√≠sticas\n",
        "    total_images = df['Count'].sum()\n",
        "    num_classes = len(df)\n",
        "    mean_count = df['Count'].mean()\n",
        "    std_count = df['Count'].std() if len(df['Count']) > 1 else 0\n",
        "    min_count = df['Count'].min()\n",
        "    max_count = df['Count'].max()\n",
        "\n",
        "    # Imprimir resumen\n",
        "    print(f\"\\n{'=' * 20}\")\n",
        "    print(f\"Total im√°genes: {total_images}\")\n",
        "    print(f\"Total clases: {num_classes}\")\n",
        "    print(f\"Media de im√°genes por clase: {mean_count:.2f}\")\n",
        "    print(f\"Desviaci√≥n est√°ndar: {std_count:.2f}\")\n",
        "    print(f\"M√≠nimo: {min_count} ({df.loc[df['Count'].idxmin(), 'Class']})\")\n",
        "    print(f\"M√°ximo: {max_count} ({df.loc[df['Count'].idxmax(), 'Class']})\")\n",
        "\n",
        "    # Evaluar balance\n",
        "    imbalance_ratio = max_count / min_count if min_count > 0 else float('inf')\n",
        "    print(f\"Relaci√≥n de desbalance: {imbalance_ratio:.2f}\")\n",
        "    print(\"‚ö†Ô∏è Dataset desbalanceado. Considera balancear las clases.\" if imbalance_ratio > 2 and num_classes > 1 else \"‚úÖ Dataset razonablemente balanceado.\")\n",
        "\n",
        "    # Guardar conteos en CSV\n",
        "    df.to_csv(OUTPUT_CSV, index=False)\n",
        "    print(f\"Conteo guardado en: {OUTPUT_CSV}\")\n",
        "\n",
        "    # Mostrar clases extremas\n",
        "    print(\"\\nClases con m√°s im√°genes:\")\n",
        "    print(df.head(5)[['Class', 'Count']].to_string(index=False) if len(df) >= 5 else \"No hay datos suficientes.\")\n",
        "    print(\"\\nClases con menos im√°genes:\")\n",
        "    print(df.tail(5)[['Class', 'Count']].to_string(index=False) if len(df) >= 5 else \"No hay datos suficientes.\")\n",
        "\n",
        "def main():\n",
        "    \"\"\"Ejecuta el an√°lisis de balance de clases.\"\"\"\n",
        "    class_counts = collect_class_counts(DATASET_PATH)\n",
        "    generate_balance_report(class_counts)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RipfOhdz2FMR"
      },
      "source": [
        "## ***Preprocesamiento***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gw6NOop2Mxo"
      },
      "source": [
        "### ***Conversi√≥n de formatos de imagen***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvXDCXZ5_z-V"
      },
      "source": [
        "Se identificaron 2 archivos con extensi√≥n .jpeg y 2 archivos con extensi√≥n .png dentro del dataset.\n",
        "Para mantener la uniformidad en el preprocesamiento, todas estas im√°genes fueron convertidas al formato .jpg, eliminando las versiones originales con extensiones distintas. Esto garantiza una estructura de datos homog√©nea para las etapas posteriores del flujo de trabajo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Fm5YVMWA7mV4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Procesando directorios: 160it [00:00, 333.34it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "====================\n",
            "Im√°genes .jpeg convertidas: 0\n",
            "Im√°genes .png convertidas: 0\n",
            "Total archivos procesados: 0\n",
            "No se encontraron im√°genes .png o .jpeg.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ruta del dataset local\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "\n",
        "def convert_only_png_jpeg_to_jpg_replace(input_dir):\n",
        "    \"\"\"Convierte im√°genes .png y .jpeg a .jpg en el mismo directorio, eliminando los originales.\"\"\"\n",
        "    target_extensions = ('.png', '.jpeg')\n",
        "    converted_count = {'jpeg': 0, 'png': 0}\n",
        "    total_files_processed = 0\n",
        "\n",
        "    # Recorre directorios y busca im√°genes .png y .jpeg\n",
        "    for root, _, files in tqdm(os.walk(input_dir), desc=\"Procesando directorios\"):\n",
        "        for file in files:\n",
        "            ext = os.path.splitext(file)[1].lower()\n",
        "            if ext in target_extensions:\n",
        "                input_path = os.path.join(root, file)\n",
        "                output_path = os.path.join(root, os.path.splitext(file)[0] + '.jpg')\n",
        "\n",
        "                try:\n",
        "                    # Convierte la imagen a RGB y guarda como .jpg\n",
        "                    with Image.open(input_path) as img:\n",
        "                        if img.mode != 'RGB':\n",
        "                            img = img.convert('RGB')\n",
        "                        img.save(output_path, 'JPEG', quality=95)\n",
        "                    converted_count[ext[1:]] += 1\n",
        "                    total_files_processed += 1\n",
        "                    # Elimina el archivo original\n",
        "                    os.remove(input_path)\n",
        "                except Exception as e:\n",
        "                    print(f\"Error al procesar {input_path}: {e}\")\n",
        "\n",
        "    # Imprime resumen de conversiones\n",
        "    print(f\"\\n{'=' * 20}\")\n",
        "    print(f\"Im√°genes .jpeg convertidas: {converted_count['jpeg']}\")\n",
        "    print(f\"Im√°genes .png convertidas: {converted_count['png']}\")\n",
        "    print(f\"Total archivos procesados: {total_files_processed}\")\n",
        "    if total_files_processed == 0:\n",
        "        print(\"No se encontraron im√°genes .png o .jpeg.\")\n",
        "\n",
        "    return converted_count\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    convert_only_png_jpeg_to_jpg_replace(DATASET_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cbZoQCe3TmB"
      },
      "source": [
        "### ***Redimenzionamiento de imagenes a 224***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qv3eCNbjr5fJ"
      },
      "source": [
        "Se redimensionaron todas las im√°genes a 224 x 224 p√≠xeles, ya que la mayor√≠a se encontraba en dimensiones como 256 x 256 u otras variantes. Esta estandarizaci√≥n es necesaria para asegurar la compatibilidad con el modelo ResNet, que requiere una entrada fija de dicha dimensi√≥n."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "l5o92UfBUFIX"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Recolectando im√°genes: 160it [00:00, 279.71it/s]\n",
            "Redimensionando im√°genes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 162916/162916 [02:51<00:00, 949.76it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "====================\n",
            "Im√°genes redimensionadas: 162916\n",
            "Errores: 0\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Configuraci√≥n\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset\"\n",
        "OUTPUT_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset_resized\"\n",
        "TARGET_SIZE = (224, 224)\n",
        "MAX_WORKERS = 16\n",
        "\n",
        "def collect_image_paths(input_dir):\n",
        "    \"\"\"Recolecta rutas de im√°genes .jpg.\"\"\"\n",
        "    file_paths = []\n",
        "    # Recorre directorios y recolecta im√°genes .jpg\n",
        "    for root, _, files in tqdm(os.walk(input_dir), desc=\"Recolectando im√°genes\"):\n",
        "        for file in files:\n",
        "            if file.lower().endswith('.jpg'):\n",
        "                file_paths.append(os.path.join(root, file))\n",
        "    return file_paths\n",
        "\n",
        "def resize_image(file_path, output_dir, target_size):\n",
        "    \"\"\"Redimensiona una imagen .jpg y la guarda en el directorio de salida.\"\"\"\n",
        "    try:\n",
        "        # Crea subdirectorio de salida manteniendo la estructura\n",
        "        relative_path = os.path.relpath(os.path.dirname(file_path), DATASET_PATH)\n",
        "        output_subdir = os.path.join(output_dir, relative_path)\n",
        "        os.makedirs(output_subdir, exist_ok=True)\n",
        "        output_path = os.path.join(output_subdir, os.path.basename(file_path))\n",
        "\n",
        "        # Abre, convierte a RGB si es necesario, redimensiona y guarda\n",
        "        with Image.open(file_path) as img:\n",
        "            if img.mode != 'RGB':\n",
        "                img = img.convert('RGB')\n",
        "            img_resized = img.resize(target_size, Image.LANCZOS)\n",
        "            img_resized.save(output_path, 'JPEG', quality=95)\n",
        "        return file_path, output_path, None\n",
        "    except Exception as e:\n",
        "        return file_path, None, str(e)\n",
        "\n",
        "def resize_images(input_dir, output_dir, target_size, max_workers=MAX_WORKERS):\n",
        "    \"\"\"Redimensiona im√°genes .jpg en paralelo y genera informe.\"\"\"\n",
        "    file_paths = collect_image_paths(input_dir)\n",
        "    resized_count = 0\n",
        "    errors = []\n",
        "\n",
        "    # Procesa im√°genes en paralelo\n",
        "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
        "        future_to_file = {executor.submit(resize_image, path, output_dir, target_size): path for path in file_paths}\n",
        "        for future in tqdm(as_completed(future_to_file), total=len(file_paths), desc=\"Redimensionando im√°genes\"):\n",
        "            input_path, output_path, error = future.result()\n",
        "            if error:\n",
        "                errors.append((input_path, error))\n",
        "            else:\n",
        "                resized_count += 1\n",
        "\n",
        "    # Imprime resumen\n",
        "    print(f\"\\n{'=' * 20}\")\n",
        "    print(f\"Im√°genes redimensionadas: {resized_count}\")\n",
        "    print(f\"Errores: {len(errors)}\")\n",
        "    if errors:\n",
        "        print(\"\\nArchivos con errores:\")\n",
        "        for path, error in errors:\n",
        "            print(f\"  {path}: {error}\")\n",
        "    if resized_count == 0:\n",
        "        print(\"No se encontraron im√°genes .jpg.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    resize_images(DATASET_PATH, OUTPUT_PATH, TARGET_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7ovtr_IXo5p"
      },
      "source": [
        "### ***Balanceo de clases por cada planta y estado***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CM8UgMp9X1zZ",
        "outputId": "d4e2ea61-e843-48e5-9c14-9497793ffc3b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Balanceando plantas: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 14/14 [00:05<00:00,  2.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "====================\n",
            "Total im√°genes balanceadas: 162916\n",
            "Clases procesadas: 114\n",
            "Pesos guardados en: C:\\Users\\Arys\\Desktop\\Proyecto - 2\\balanced_weights\\plant_weights.csv\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Configuraci√≥n\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset_resized\"\n",
        "OUTPUT_WEIGHTS_DIR = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\balanced_weights\"\n",
        "OUTPUT_WEIGHTS = os.path.join(OUTPUT_WEIGHTS_DIR, \"plant_weights.csv\")\n",
        "os.makedirs(OUTPUT_WEIGHTS_DIR, exist_ok=True)\n",
        "\n",
        "def apply_plant_balancing(class_counts):\n",
        "    \"\"\"Aplica balanceo por planta con ponderaci√≥n inversa.\"\"\"\n",
        "    # Extrae plantas √∫nicas\n",
        "    plants = set('_'.join(cls.split('_')[1:2]) for cls in class_counts['Class'])\n",
        "    balanced_data = []\n",
        "\n",
        "    # Procesa cada planta\n",
        "    for plant in tqdm(plants, desc=\"Balanceando plantas\"):\n",
        "        # Filtra clases de la planta actual\n",
        "        plant_classes = [cls for cls in class_counts['Class'] if f\"_{plant}_\" in cls]\n",
        "        plant_data = class_counts[class_counts['Class'].isin(plant_classes)].copy()\n",
        "\n",
        "        if plant_data.empty:\n",
        "            continue\n",
        "\n",
        "        # Calcula pesos inversos para balanceo\n",
        "        total_images = plant_data['Count'].sum()\n",
        "        if total_images == 0:\n",
        "            continue\n",
        "        plant_data['Weight'] = total_images / plant_data['Count']\n",
        "        weight_sum = plant_data['Weight'].sum()\n",
        "        plant_data['Weight'] = plant_data['Weight'] / weight_sum\n",
        "\n",
        "        # Genera lista de im√°genes por clase\n",
        "        for _, row in plant_data.iterrows():\n",
        "            img_parts = row['Class'].split('_')\n",
        "            img_type = img_parts[0]\n",
        "            plant_name = img_parts[1]\n",
        "            state = '_'.join(img_parts[2:])\n",
        "            state_path = os.path.join(DATASET_PATH, img_type, plant_name, state)\n",
        "\n",
        "            if os.path.exists(state_path):\n",
        "                images = [f for f in os.listdir(state_path) if f.lower().endswith('.jpg')]\n",
        "                for img in images[:min(len(images), row['Count'])]:\n",
        "                    balanced_data.append([row['Class'], img, row['Weight']])\n",
        "\n",
        "    # Guarda datos balanceados en CSV\n",
        "    if balanced_data:\n",
        "        balanced_df = pd.DataFrame(balanced_data, columns=['Class', 'Image', 'Weight'])\n",
        "        balanced_df.to_csv(OUTPUT_WEIGHTS, index=False)\n",
        "        print(f\"\\n{'=' * 20}\")\n",
        "        print(f\"Total im√°genes balanceadas: {len(balanced_df)}\")\n",
        "        print(f\"Clases procesadas: {len(balanced_df['Class'].unique())}\")\n",
        "        print(f\"Pesos guardados en: {OUTPUT_WEIGHTS}\")\n",
        "    else:\n",
        "        print(\"Error: No se generaron datos balanceados. Verifica las rutas y el CSV.\")\n",
        "\n",
        "# Carga conteos y aplica balanceo\n",
        "if __name__ == \"__main__\":\n",
        "    class_counts = pd.read_csv(r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\class_counts.csv\")\n",
        "    apply_plant_balancing(class_counts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5E_lv8lcR_w"
      },
      "source": [
        "### ***Cargamos los pesos***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPPQDfSTcPNw",
        "outputId": "6a7b2beb-dc9e-474e-95b4-13b230916d67"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Configurando DataLoader: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.08it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "====================\n",
            "Im√°genes cargadas: 162916\n",
            "Clases √∫nicas: 114\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "from torchvision import transforms\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Configuraci√≥n\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset_resized\"\n",
        "WEIGHTS_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\balanced_weights\\plant_weights.csv\"\n",
        "BATCH_SIZE = 32\n",
        "NUM_WORKERS = 4\n",
        "\n",
        "# Transformaciones para entrenamiento\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "class PlantDataset(Dataset):\n",
        "    \"\"\"Carga im√°genes .jpg con pesos para balanceo.\"\"\"\n",
        "    def __init__(self, weights_df, root_dir, transform=None):\n",
        "        self.data = weights_df\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.class_to_idx = {cls: idx for idx, cls in enumerate(weights_df['Class'].unique())}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"Obtiene imagen, etiqueta y peso.\"\"\"\n",
        "        row = self.data.iloc[idx]\n",
        "        img_parts = row['Class'].split('_')\n",
        "        img_path = f\"{self.root_dir}/{img_parts[0]}/{img_parts[1]}/{'_'.join(img_parts[2:])}/{row['Image']}\"\n",
        "\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        label = self.class_to_idx[row['Class']]\n",
        "        weight = row['Weight']\n",
        "        return image, label, weight\n",
        "\n",
        "def create_weighted_dataloader(weights_path, root_dir, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS):\n",
        "    \"\"\"Crea DataLoader con muestreo ponderado.\"\"\"\n",
        "    # Carga datos balanceados\n",
        "    weights_df = pd.read_csv(weights_path)\n",
        "    \n",
        "    # Crea dataset con barra de progreso\n",
        "    dataset = PlantDataset(weights_df, root_dir, transform=train_transforms)\n",
        "    \n",
        "    # Configura WeightedRandomSampler\n",
        "    weights = torch.tensor(weights_df['Weight'].values, dtype=torch.float)\n",
        "    sampler = WeightedRandomSampler(weights, num_samples=len(weights), replacement=True)\n",
        "\n",
        "    # Crea DataLoader\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, sampler=sampler, num_workers=num_workers)\n",
        "    \n",
        "    # Imprime resumen\n",
        "    print(f\"\\n{'=' * 20}\")\n",
        "    print(f\"Im√°genes cargadas: {len(dataset)}\")\n",
        "    print(f\"Clases √∫nicas: {len(dataset.class_to_idx)}\")\n",
        "    \n",
        "    return dataloader\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Configura DataLoader con barra de progreso\n",
        "    with tqdm(total=1, desc=\"Configurando DataLoader\") as pbar:\n",
        "        dataloader = create_weighted_dataloader(WEIGHTS_PATH, DATASET_PATH)\n",
        "        pbar.update(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUfIwJFGdDLZ"
      },
      "source": [
        "## ***Divisi√≥n del dataset***\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3uYFljCudRNv",
        "outputId": "90692c31-2670-4d28-a939-79c445336484"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Clases encontradas: 114\n",
            "\n",
            "====================\n",
            "Total im√°genes: 162916\n",
            "Entrenamiento: 114041 im√°genes (114 clases)\n",
            "Validaci√≥n: 24437 im√°genes (114 clases)\n",
            "Prueba: 24438 im√°genes (114 clases)\n",
            "CSVs guardados en: C:\\Users\\Arys\\Desktop\\Proyecto - 2\\balanced_weights\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Configuraci√≥n\n",
        "WEIGHTS_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\balanced_weights\\plant_weights.csv\"\n",
        "OUTPUT_WEIGHTS_DIR = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\balanced_weights\"\n",
        "TRAIN_WEIGHTS = os.path.join(OUTPUT_WEIGHTS_DIR, \"train_weights.csv\")\n",
        "VAL_WEIGHTS = os.path.join(OUTPUT_WEIGHTS_DIR, \"val_weights.csv\")\n",
        "TEST_WEIGHTS = os.path.join(OUTPUT_WEIGHTS_DIR, \"test_weights.csv\")\n",
        "os.makedirs(OUTPUT_WEIGHTS_DIR, exist_ok=True)\n",
        "\n",
        "def split_dataset(weights_path, train_ratio=0.7, val_ratio=0.15):\n",
        "    \"\"\"Divide el dataset en conjuntos de entrenamiento, validaci√≥n y prueba.\"\"\"\n",
        "    if not os.path.exists(weights_path):\n",
        "        raise FileNotFoundError(f\"No se encontr√≥ {weights_path}\")\n",
        "    \n",
        "    df = pd.read_csv(weights_path)\n",
        "    if not all(col in df.columns for col in ['Class', 'Image', 'Weight']):\n",
        "        raise ValueError(\"El CSV debe contener 'Class', 'Image' y 'Weight'\")\n",
        "    \n",
        "    if len(df) < 10:  # Validaci√≥n m√≠nima\n",
        "        raise ValueError(\"El dataset es demasiado peque√±o para dividir\")\n",
        "    \n",
        "    num_classes = len(df['Class'].unique())\n",
        "    print(f\"Clases encontradas: {num_classes}\")\n",
        "    \n",
        "    # Divide en entrenamiento y resto (validaci√≥n + prueba)\n",
        "    train_df, temp_df = train_test_split(\n",
        "        df, train_size=train_ratio, stratify=df['Class'], random_state=42\n",
        "    )\n",
        "    val_size = val_ratio / (1 - train_ratio)\n",
        "    val_df, test_df = train_test_split(\n",
        "        temp_df, train_size=val_size, stratify=temp_df['Class'], random_state=42\n",
        "    )\n",
        "    \n",
        "    # Guarda los conjuntos\n",
        "    train_df.to_csv(TRAIN_WEIGHTS, index=False)\n",
        "    val_df.to_csv(VAL_WEIGHTS, index=False)\n",
        "    test_df.to_csv(TEST_WEIGHTS, index=False)\n",
        "    \n",
        "    print(f\"\\n{'=' * 20}\")\n",
        "    print(f\"Total im√°genes: {len(df)}\")\n",
        "    print(f\"Entrenamiento: {len(train_df)} im√°genes ({len(train_df['Class'].unique())} clases)\")\n",
        "    print(f\"Validaci√≥n: {len(val_df)} im√°genes ({len(val_df['Class'].unique())} clases)\")\n",
        "    print(f\"Prueba: {len(test_df)} im√°genes ({len(test_df['Class'].unique())} clases)\")\n",
        "    print(f\"CSVs guardados en: {OUTPUT_WEIGHTS_DIR}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        split_dataset(WEIGHTS_PATH)\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {str(e)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7e_As1MAdY6m"
      },
      "source": [
        "## ***Entrenamiento del modelo***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBgUGEe_ddwa",
        "outputId": "3f7fcf00-d5df-4bcd-cd0b-b55b08346556"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                       "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cargado C:\\Users\\Arys\\Desktop\\Proyecto - 2\\balanced_weights\\train_weights.csv: 114041 im√°genes, 114 clases\n",
            "Cargado C:\\Users\\Arys\\Desktop\\Proyecto - 2\\balanced_weights\\val_weights.csv: 24437 im√°genes, 114 clases\n",
            "Cargado C:\\Users\\Arys\\Desktop\\Proyecto - 2\\balanced_weights\\test_weights.csv: 24438 im√°genes, 114 clases\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Entrenando √©poca 1/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1782/1782 [14:12<00:00,  2.09it/s]\n",
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "√âpoca 1: P√©rdida Entrenamiento: 0.5696, Precisi√≥n Entrenamiento: 84.06%\n",
            "Precisi√≥n Validaci√≥n: 79.73%\n",
            "Mejor modelo guardado en: C:\\Users\\Arys\\Desktop\\Proyecto - 2\\normal_model.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Entrenando √©poca 2/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1782/1782 [14:41<00:00,  2.02it/s]\n",
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "√âpoca 2: P√©rdida Entrenamiento: 0.2960, Precisi√≥n Entrenamiento: 90.78%\n",
            "Precisi√≥n Validaci√≥n: 84.75%\n",
            "Mejor modelo guardado en: C:\\Users\\Arys\\Desktop\\Proyecto - 2\\normal_model.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Entrenando √©poca 3/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1782/1782 [13:43<00:00,  2.16it/s]\n",
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "√âpoca 3: P√©rdida Entrenamiento: 0.2565, Precisi√≥n Entrenamiento: 91.88%\n",
            "Precisi√≥n Validaci√≥n: 87.87%\n",
            "Mejor modelo guardado en: C:\\Users\\Arys\\Desktop\\Proyecto - 2\\normal_model.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Entrenando √©poca 4/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1782/1782 [13:26<00:00,  2.21it/s]\n",
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "√âpoca 4: P√©rdida Entrenamiento: 0.2243, Precisi√≥n Entrenamiento: 92.82%\n",
            "Precisi√≥n Validaci√≥n: 88.47%\n",
            "Mejor modelo guardado en: C:\\Users\\Arys\\Desktop\\Proyecto - 2\\normal_model.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Entrenando √©poca 5/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1782/1782 [13:02<00:00,  2.28it/s]\n",
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "√âpoca 5: P√©rdida Entrenamiento: 0.2126, Precisi√≥n Entrenamiento: 93.16%\n",
            "Precisi√≥n Validaci√≥n: 89.50%\n",
            "Mejor modelo guardado en: C:\\Users\\Arys\\Desktop\\Proyecto - 2\\normal_model.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Entrenando √©poca 6/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1782/1782 [13:02<00:00,  2.28it/s]\n",
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "√âpoca 6: P√©rdida Entrenamiento: 0.1913, Precisi√≥n Entrenamiento: 93.81%\n",
            "Precisi√≥n Validaci√≥n: 82.50%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Entrenando √©poca 7/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1782/1782 [13:02<00:00,  2.28it/s]\n",
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "√âpoca 7: P√©rdida Entrenamiento: 0.1832, Precisi√≥n Entrenamiento: 94.06%\n",
            "Precisi√≥n Validaci√≥n: 90.17%\n",
            "Mejor modelo guardado en: C:\\Users\\Arys\\Desktop\\Proyecto - 2\\normal_model.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Entrenando √©poca 8/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1782/1782 [13:55<00:00,  2.13it/s]\n",
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "√âpoca 8: P√©rdida Entrenamiento: 0.1696, Precisi√≥n Entrenamiento: 94.43%\n",
            "Precisi√≥n Validaci√≥n: 91.06%\n",
            "Mejor modelo guardado en: C:\\Users\\Arys\\Desktop\\Proyecto - 2\\normal_model.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Entrenando √©poca 9/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1782/1782 [13:53<00:00,  2.14it/s]\n",
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "√âpoca 9: P√©rdida Entrenamiento: 0.1636, Precisi√≥n Entrenamiento: 94.52%\n",
            "Precisi√≥n Validaci√≥n: 93.45%\n",
            "Mejor modelo guardado en: C:\\Users\\Arys\\Desktop\\Proyecto - 2\\normal_model.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Entrenando √©poca 10/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1782/1782 [13:52<00:00,  2.14it/s]\n",
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "√âpoca 10: P√©rdida Entrenamiento: 0.1564, Precisi√≥n Entrenamiento: 94.78%\n",
            "Precisi√≥n Validaci√≥n: 92.07%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Entrenando √©poca 11/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1782/1782 [15:45<00:00,  1.88it/s]\n",
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "√âpoca 11: P√©rdida Entrenamiento: 0.1505, Precisi√≥n Entrenamiento: 95.08%\n",
            "Precisi√≥n Validaci√≥n: 91.06%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Entrenando √©poca 12/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1782/1782 [16:57<00:00,  1.75it/s]\n",
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "√âpoca 12: P√©rdida Entrenamiento: 0.1493, Precisi√≥n Entrenamiento: 95.03%\n",
            "Precisi√≥n Validaci√≥n: 91.74%\n",
            "Parando temprano en √©poca 12\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                      "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "====================\n",
            "Precisi√≥n en prueba: 91.85%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "from torchvision import models, transforms\n",
        "from torchvision.models import ResNet18_Weights\n",
        "from tqdm import tqdm\n",
        "\n",
        "# =================== CONFIGURACI√ìN ===================\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset_resized\"\n",
        "WEIGHTS_DIR = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\balanced_weights\"\n",
        "TRAIN_WEIGHTS = os.path.join(WEIGHTS_DIR, \"train_weights.csv\")\n",
        "VAL_WEIGHTS = os.path.join(WEIGHTS_DIR, \"val_weights.csv\")\n",
        "TEST_WEIGHTS = os.path.join(WEIGHTS_DIR, \"test_weights.csv\")\n",
        "MODEL_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\normal_model.pth\"\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# =================== TRANSFORMACIONES ===================\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.RandomRotation(20),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "    transforms.RandomAffine(degrees=0, translate=(0.05, 0.05)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# =================== DATASET PERSONALIZADO ===================\n",
        "class PlantDataset(Dataset):\n",
        "    def __init__(self, weights_df, root_dir, transform=None, class_to_idx=None):\n",
        "        self.data = weights_df\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.class_to_idx = class_to_idx\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.data.iloc[idx]\n",
        "        img_parts = row['Class'].split('_')\n",
        "        img_path = f\"{self.root_dir}/{img_parts[0]}/{img_parts[1]}/{'_'.join(img_parts[2:])}/{row['Image']}\"\n",
        "        try:\n",
        "            image = Image.open(img_path).convert('RGB')\n",
        "            if self.transform:\n",
        "                image = self.transform(image)\n",
        "            label = self.class_to_idx[row['Class']]\n",
        "            return image, label\n",
        "        except Exception as e:\n",
        "            print(f\"Error al cargar {img_path}: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "# =================== DATALOADER ===================\n",
        "def create_dataloader(weights_path, root_dir, transform, class_to_idx, batch_size=64, use_sampler=True):\n",
        "    if not os.path.exists(weights_path):\n",
        "        raise FileNotFoundError(f\"No se encontr√≥ {weights_path}\")\n",
        "    weights_df = pd.read_csv(weights_path)\n",
        "    if not all(col in weights_df.columns for col in ['Class', 'Image', 'Weight']):\n",
        "        raise ValueError(f\"El CSV debe contener 'Class', 'Image' y 'Weight'\")\n",
        "    \n",
        "    dataset = PlantDataset(weights_df, root_dir, transform=transform, class_to_idx=class_to_idx)\n",
        "    sampler = None\n",
        "    if use_sampler:\n",
        "        weights = torch.tensor(weights_df['Weight'].values, dtype=torch.float)\n",
        "        sampler = WeightedRandomSampler(weights, num_samples=len(weights), replacement=True)\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, sampler=sampler, shuffle=not use_sampler)\n",
        "    print(f\"Cargado {weights_path}: {len(dataset)} im√°genes, {len(class_to_idx)} clases\")\n",
        "    return dataloader\n",
        "\n",
        "# =================== ENTRENAMIENTO ===================\n",
        "def train_model(train_loader, val_loader, num_epochs=20, early_stop_patience=3):\n",
        "    model = models.resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
        "    num_classes = len(train_loader.dataset.class_to_idx)\n",
        "    model.fc = nn.Sequential(\n",
        "        nn.Dropout(0.3),\n",
        "        nn.Linear(model.fc.in_features, num_classes)\n",
        "    )\n",
        "    model = model.to(DEVICE)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=0.0005)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2)\n",
        "\n",
        "    best_acc = 0.0\n",
        "    epochs_without_improvement = 0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for images, labels in tqdm(train_loader, desc=f\"Entrenando √©poca {epoch+1}/{num_epochs}\", leave=True):\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        train_loss = running_loss / len(train_loader)\n",
        "        train_acc = 100 * correct / total\n",
        "\n",
        "        # VALIDACI√ìN\n",
        "        model.eval()\n",
        "        val_correct = 0\n",
        "        val_total = 0\n",
        "        with torch.no_grad():\n",
        "            for images, labels in tqdm(val_loader, desc=\"Validando\", leave=False):\n",
        "                images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "                outputs = model(images)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                val_total += labels.size(0)\n",
        "                val_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        val_acc = 100 * val_correct / val_total\n",
        "        scheduler.step(val_acc)\n",
        "\n",
        "        print(f\"\\n√âpoca {epoch+1}: P√©rdida Entrenamiento: {train_loss:.4f}, Precisi√≥n Entrenamiento: {train_acc:.2f}%\")\n",
        "        print(f\"Precisi√≥n Validaci√≥n: {val_acc:.2f}%\")\n",
        "\n",
        "        # EARLY STOPPING Y SAVE MODEL\n",
        "        if val_acc > best_acc:\n",
        "            best_acc = val_acc\n",
        "            epochs_without_improvement = 0\n",
        "            try:\n",
        "                torch.save(model.state_dict(), MODEL_PATH)\n",
        "                print(f\"Mejor modelo guardado en: {MODEL_PATH}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error al guardar el modelo: {str(e)}\")\n",
        "        else:\n",
        "            epochs_without_improvement += 1\n",
        "\n",
        "        if epochs_without_improvement >= early_stop_patience:\n",
        "            print(f\"Parando temprano en √©poca {epoch+1}\")\n",
        "            break\n",
        "\n",
        "    return model\n",
        "\n",
        "# =================== EVALUACI√ìN ===================\n",
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in tqdm(test_loader, desc=\"Evaluando en prueba\", leave=False):\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    test_acc = 100 * correct / total\n",
        "    print(f\"\\n{'=' * 20}\")\n",
        "    print(f\"Precisi√≥n en prueba: {test_acc:.2f}%\")\n",
        "    return test_acc\n",
        "\n",
        "# =================== MAIN ===================\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        # Verificar CSVs\n",
        "        for path in [TRAIN_WEIGHTS, VAL_WEIGHTS, TEST_WEIGHTS]:\n",
        "            if not os.path.exists(path):\n",
        "                raise FileNotFoundError(f\"No se encontr√≥ {path}\")\n",
        "        \n",
        "        # Crear mapeo global de clases\n",
        "        train_df = pd.read_csv(TRAIN_WEIGHTS)\n",
        "        all_classes = sorted(train_df['Class'].unique())\n",
        "        class_to_idx = {cls: idx for idx, cls in enumerate(all_classes)}\n",
        "\n",
        "        with tqdm(total=3, desc=\"Configurando DataLoaders\", leave=False) as pbar:\n",
        "            train_loader = create_dataloader(TRAIN_WEIGHTS, DATASET_PATH, train_transforms, class_to_idx, use_sampler=True)\n",
        "            pbar.update(1)\n",
        "            val_loader = create_dataloader(VAL_WEIGHTS, DATASET_PATH, val_transforms, class_to_idx, use_sampler=False)\n",
        "            pbar.update(1)\n",
        "            test_loader = create_dataloader(TEST_WEIGHTS, DATASET_PATH, val_transforms, class_to_idx, use_sampler=False)\n",
        "            pbar.update(1)\n",
        "\n",
        "        model = train_model(train_loader, val_loader)\n",
        "        evaluate_model(model, test_loader)\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {str(e)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ***Pruebas con camara***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Arys\\Desktop\\Proyecto - 2\\venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Arys\\Desktop\\Proyecto - 2\\venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicciones en tiempo real. Presiona 'q' para guardar imagen, 'Esc' para salir.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Capturando desde c√°mara:   0%|          | 0/1 [03:19<?, ?it/s]\n"
          ]
        },
        {
          "ename": "error",
          "evalue": "OpenCV(4.12.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window_w32.cpp:1261: error: (-27:Null pointer) NULL window: 'Umbral' in function 'cvDestroyWindow'\n",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31merror\u001b[39m                                     Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 183\u001b[39m\n\u001b[32m    180\u001b[39m             cv2.destroyWindow(\u001b[33m\"\u001b[39m\u001b[33mUmbral\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m     \u001b[43mcapture_and_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 180\u001b[39m, in \u001b[36mcapture_and_predict\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    178\u001b[39m cv2.destroyAllWindows()\n\u001b[32m    179\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m DEBUG:\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m     \u001b[43mcv2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdestroyWindow\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mUmbral\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "\u001b[31merror\u001b[39m: OpenCV(4.12.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window_w32.cpp:1261: error: (-27:Null pointer) NULL window: 'Umbral' in function 'cvDestroyWindow'\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from PIL import Image\n",
        "from torchvision import models, transforms\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ================= CONFIGURACI√ìN =================\n",
        "MODEL_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\normal_model.pth\"\n",
        "WEIGHTS_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\balanced_weights\\train_weights.csv\"\n",
        "CAPTURED_IMAGES_DIR = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\captured_images\"\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "DEBUG = True  # Activa la depuraci√≥n para ver la imagen umbralizada\n",
        "\n",
        "os.makedirs(CAPTURED_IMAGES_DIR, exist_ok=True)\n",
        "\n",
        "# ================ TRANSFORMACI√ìN =================\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# ================ CARGAR MODELO ==================\n",
        "def load_model_and_classes(model_path, weights_path):\n",
        "    \"\"\"Carga el modelo y el mapeo de clases.\"\"\"\n",
        "    weights_df = pd.read_csv(weights_path)\n",
        "    all_classes = sorted(weights_df['Class'].unique())\n",
        "    class_to_idx = {cls: idx for idx, cls in enumerate(all_classes)}\n",
        "    idx_to_class = {idx: cls for cls, idx in class_to_idx.items()}\n",
        "    \n",
        "    model = models.resnet18(pretrained=False)\n",
        "    model.fc = nn.Sequential(\n",
        "        nn.Dropout(0.3),\n",
        "        nn.Linear(model.fc.in_features, len(class_to_idx))\n",
        "    )\n",
        "    model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
        "    model = model.to(DEVICE)\n",
        "    model.eval()\n",
        "    return model, idx_to_class\n",
        "\n",
        "def normalize_brightness(frame):\n",
        "    \"\"\"Normaliza el brillo de la imagen.\"\"\"\n",
        "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
        "    hsv[:, :, 2] = cv2.normalize(hsv[:, :, 2], None, 0, 255, cv2.NORM_MINMAX)\n",
        "    return cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
        "\n",
        "def detect_leaf(frame, min_area=500):\n",
        "    \"\"\"Detecta una hoja con umbral adaptativo y devuelve el recuadro con contornos mejorados.\"\"\"\n",
        "    # Normaliza el brillo\n",
        "    frame = normalize_brightness(frame)\n",
        "    \n",
        "    # Convierte a escala de grises y aplica desenfoque\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "    \n",
        "    # Aplica umbral adaptativo (mantenemos el original que te gusta)\n",
        "    thresh = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
        "                                   cv2.THRESH_BINARY_INV, 21, 5)\n",
        "    \n",
        "    # Ligero refinamiento morfol√≥gico para mejorar contornos sin cambiar la esencia\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
        "    cleaned = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel, iterations=1)\n",
        "    \n",
        "    # Muestra la imagen umbralizada para depuraci√≥n (si DEBUG=True)\n",
        "    if DEBUG:\n",
        "        cv2.imshow(\"Umbral\", cleaned)\n",
        "    \n",
        "    # Encuentra contornos\n",
        "    contours, _ = cv2.findContours(cleaned, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    \n",
        "    if contours:\n",
        "        # Selecciona el contorno m√°s grande\n",
        "        largest_contour = max(contours, key=cv2.contourArea)\n",
        "        area = cv2.contourArea(largest_contour)\n",
        "        if area > min_area:\n",
        "            x, y, w, h = cv2.boundingRect(largest_contour)\n",
        "            if w > 30 and h > 30 and w < frame.shape[1] * 0.9 and h < frame.shape[0] * 0.9:\n",
        "                # Dibuja el contorno en la imagen original\n",
        "                cv2.drawContours(frame, [largest_contour], -1, (0, 255, 0), 2)\n",
        "                return (x, y, x+w, y+h), frame[y:y+h, x:x+w]\n",
        "    \n",
        "    return None, frame\n",
        "\n",
        "def predict_image(image, model, idx_to_class, transform):\n",
        "    \"\"\"Predice la clase de una imagen y devuelve la confianza.\"\"\"\n",
        "    image = transform(image).unsqueeze(0).to(DEVICE)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(image)\n",
        "        probs = torch.softmax(outputs, dim=1)\n",
        "        confidence, predicted = torch.max(probs, 1)\n",
        "    return idx_to_class[predicted.item()], confidence.item()\n",
        "\n",
        "def capture_and_predict():\n",
        "    \"\"\"Captura im√°genes, detecta una hoja y predice en tiempo real.\"\"\"\n",
        "    model, idx_to_class = load_model_and_classes(MODEL_PATH, WEIGHTS_PATH)\n",
        "    cap = cv2.VideoCapture(0)\n",
        "    if not cap.isOpened():\n",
        "        print(\"Error: No se pudo abrir la c√°mara.\")\n",
        "        return\n",
        "\n",
        "    # Reducir la resoluci√≥n de la c√°mara para mejorar FPS\n",
        "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
        "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
        "\n",
        "    print(\"Predicciones en tiempo real. Presiona 'q' para guardar imagen, 'Esc' para salir.\")\n",
        "    \n",
        "    # Variables para estabilizaci√≥n\n",
        "    last_bbox = None\n",
        "    last_predicted_class = \"Buscando hoja...\"\n",
        "    last_confidence = 0.0\n",
        "    stable_count = 0\n",
        "    STABLE_THRESHOLD = 3  # N√∫mero de frames consecutivos para considerar una detecci√≥n estable\n",
        "    \n",
        "    with tqdm(total=1, desc=\"Capturando desde c√°mara\", leave=True) as pbar:\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                print(\"Error: No se pudo leer el frame.\")\n",
        "                break\n",
        "\n",
        "            # Detecta una hoja\n",
        "            bbox, roi = detect_leaf(frame, min_area=500)\n",
        "            predicted_class = last_predicted_class\n",
        "            confidence = last_confidence\n",
        "\n",
        "            if bbox:\n",
        "                # Compara con la detecci√≥n anterior para estabilizar\n",
        "                if last_bbox and abs(bbox[0] - last_bbox[0]) < 50 and abs(bbox[1] - last_bbox[1]) < 50:\n",
        "                    stable_count += 1\n",
        "                else:\n",
        "                    stable_count = 1\n",
        "                    last_bbox = bbox\n",
        "                \n",
        "                if stable_count >= STABLE_THRESHOLD:\n",
        "                    x1, y1, x2, y2 = bbox\n",
        "                    roi_pil = Image.fromarray(cv2.cvtColor(roi, cv2.COLOR_BGR2RGB))\n",
        "                    predicted_class, confidence = predict_image(roi_pil, model, idx_to_class, test_transforms)\n",
        "                    last_predicted_class = predicted_class\n",
        "                    last_confidence = confidence\n",
        "                    # Dibuja el rect√°ngulo y la predicci√≥n\n",
        "                    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "                    cv2.putText(frame, f\"Clase: {predicted_class}\", (x1, y1-10), \n",
        "                                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
        "                    cv2.putText(frame, f\"Confianza: {confidence*100:.2f}%\", (x1, y1-30), \n",
        "                                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)\n",
        "            else:\n",
        "                stable_count = 0\n",
        "                last_bbox = None\n",
        "                predicted_class = \"Buscando hoja...\"\n",
        "                confidence = 0.0\n",
        "                last_predicted_class = predicted_class\n",
        "                last_confidence = confidence\n",
        "\n",
        "            # Muestra la predicci√≥n en la parte superior\n",
        "            cv2.putText(frame, f\"Pred: {predicted_class}\", (10, 30), \n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
        "            cv2.putText(frame, f\"Conf: {confidence*100:.2f}%\", (10, 60), \n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)\n",
        "            cv2.imshow(\"C√°mara\", frame)\n",
        "\n",
        "            key = cv2.waitKey(30)  # 30ms (~33 FPS) para un feed m√°s fluido\n",
        "            if key == ord('q') and bbox:  # Solo guarda si se detecta una hoja\n",
        "                roi_pil = Image.fromarray(cv2.cvtColor(roi, cv2.COLOR_BGR2RGB))\n",
        "                save_path = os.path.join(CAPTURED_IMAGES_DIR, \n",
        "                                       f\"captured_{predicted_class}_{confidence*100:.2f}_{int(time.time())}.jpg\")\n",
        "                roi_pil.save(save_path)\n",
        "                print(f\"Imagen guardada: {save_path}\")\n",
        "                pbar.update(0)\n",
        "            elif key == 27:  # Esc\n",
        "                break\n",
        "\n",
        "        cap.release()\n",
        "        cv2.destroyAllWindows()\n",
        "        if DEBUG:\n",
        "            cv2.destroyWindow(\"Umbral\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    capture_and_predict()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ***Generaci√≥n del dataset augmentado y Carga de pesos***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Recolectando im√°genes: 160it [00:00, 252.37it/s]\n",
            "Aumentando im√°genes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 162916/162916 [1:11:09<00:00, 38.15it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "====================\n",
            "Im√°genes totales (originales + aumentadas): 977496\n",
            "Clases √∫nicas: 114\n",
            "Pesos guardados en: C:\\Users\\Arys\\Desktop\\Proyecto - 2\\augmented_weights\\augmented_plant_weights.csv\n",
            "Errores: 0\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms.functional import to_pil_image\n",
        "from tqdm import tqdm\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "\n",
        "# Configuraci√≥n\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset_resized\"\n",
        "AUGMENTED_OUTPUT_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset_augmented\"\n",
        "AUGMENTED_WEIGHTS = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\augmented_weights\\augmented_plant_weights.csv\"\n",
        "AUGMENTATIONS_PER_IMAGE = 5\n",
        "TARGET_SIZE = (224, 224)\n",
        "MAX_WORKERS = 16\n",
        "\n",
        "# Transformaciones para aumento de datos\n",
        "augment_transforms = transforms.Compose([\n",
        "    transforms.ToTensor(),  # Convertir imagen PIL a tensor\n",
        "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomVerticalFlip(p=0.5),\n",
        "    transforms.RandomRotation(20),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "    transforms.RandomAffine(degrees=0, translate=(0.05, 0.05)),\n",
        "])\n",
        "\n",
        "def collect_image_paths(input_dir):\n",
        "    \"\"\"Recolecta rutas de im√°genes .jpg.\"\"\"\n",
        "    file_paths = []\n",
        "    for root, _, files in tqdm(os.walk(input_dir), desc=\"Recolectando im√°genes\"):\n",
        "        for file in files:\n",
        "            if file.lower().endswith('.jpg'):\n",
        "                file_paths.append(os.path.join(root, file))\n",
        "    return file_paths\n",
        "\n",
        "def augment_and_save_image(file_path, output_dir, augmentations_per_image):\n",
        "    \"\"\"Genera im√°genes aumentadas y las guarda.\"\"\"\n",
        "    results = []\n",
        "    try:\n",
        "        # Obtener la ruta relativa y la clase\n",
        "        relative_path = os.path.relpath(os.path.dirname(file_path), DATASET_PATH)\n",
        "        output_subdir = os.path.join(output_dir, relative_path)\n",
        "        os.makedirs(output_subdir, exist_ok=True)\n",
        "        \n",
        "        # Generar nombre de clase (incluyendo prefijo: color, grayscale, segmented)\n",
        "        img_class_parts = relative_path.replace('\\\\', '/').split('/')\n",
        "        if len(img_class_parts) < 2:  # Asegurarse de que hay al menos tipo (color/grayscale/segmented) y planta\n",
        "            return [(file_path, None, None, None, \"Ruta relativa inv√°lida\")]\n",
        "        img_class = '_'.join(img_class_parts)  # Ejemplo: color_Apple_Apple_scab\n",
        "        \n",
        "        with Image.open(file_path) as img:\n",
        "            img = img.convert('RGB')\n",
        "            base_name = os.path.splitext(os.path.basename(file_path))[0]\n",
        "            \n",
        "            # Guardar imagen original\n",
        "            output_path = os.path.join(output_subdir, f\"{base_name}.jpg\")\n",
        "            try:\n",
        "                img.resize(TARGET_SIZE, Image.LANCZOS).save(output_path, 'JPEG', quality=95)\n",
        "                results.append((file_path, output_path, img_class, 1.0, None))\n",
        "            except Exception as e:\n",
        "                results.append((file_path, None, img_class, None, f\"Error al guardar imagen original: {str(e)}\"))\n",
        "            \n",
        "            # Generar im√°genes aumentadas\n",
        "            for i in range(augmentations_per_image):\n",
        "                try:\n",
        "                    aug_img = augment_transforms(img)  # Aplica transformaciones (img se convierte a tensor)\n",
        "                    aug_img_pil = to_pil_image(aug_img)  # Convierte tensor a PIL\n",
        "                    aug_path = os.path.join(output_subdir, f\"{base_name}_aug_{i}.jpg\")\n",
        "                    aug_img_pil.save(aug_path, 'JPEG', quality=95)  # Guardar con PIL\n",
        "                    results.append((file_path, aug_path, img_class, 0.5, None))  # Peso menor para aumentadas\n",
        "                except Exception as e:\n",
        "                    results.append((file_path, None, img_class, None, f\"Error al generar imagen aumentada {i}: {str(e)}\"))\n",
        "                \n",
        "        return results\n",
        "    except Exception as e:\n",
        "        return [(file_path, None, None, None, f\"Error general: {str(e)}\")]\n",
        "\n",
        "def augment_dataset(input_dir, output_dir, augmentations_per_image):\n",
        "    \"\"\"Aumenta el dataset y genera CSV con pesos.\"\"\"\n",
        "    os.makedirs(os.path.dirname(AUGMENTED_WEIGHTS), exist_ok=True)\n",
        "    file_paths = collect_image_paths(input_dir)\n",
        "    all_results = []\n",
        "    \n",
        "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "        future_to_file = {executor.submit(augment_and_save_image, path, output_dir, augmentations_per_image): path for path in file_paths}\n",
        "        for future in tqdm(as_completed(future_to_file), total=len(file_paths), desc=\"Aumentando im√°genes\"):\n",
        "            all_results.extend(future.result())\n",
        "    \n",
        "    # Separar resultados v√°lidos y errores\n",
        "    valid_results = [r for r in all_results if r[1] is not None and r[2] is not None]\n",
        "    errors = [r for r in all_results if r[4] is not None]\n",
        "    \n",
        "    # Crear DataFrame\n",
        "    data = [(r[2], os.path.basename(r[1]), r[3]) for r in valid_results]\n",
        "    if not data:\n",
        "        print(f\"Error: No se generaron im√°genes v√°lidas. Total errores: {len(errors)}\")\n",
        "        print(\"\\nArchivos con errores:\")\n",
        "        for _, _, _, _, error in errors:\n",
        "            print(f\"  {error}\")\n",
        "        return\n",
        "    \n",
        "    df = pd.DataFrame(data, columns=['Class', 'Image', 'Weight'])\n",
        "    \n",
        "    # Calcular pesos inversos por clase\n",
        "    class_counts = df['Class'].value_counts()\n",
        "    total_images = len(df)\n",
        "    df['Weight'] = df['Class'].apply(lambda x: total_images / class_counts[x])\n",
        "    weight_sum = df['Weight'].sum()\n",
        "    df['Weight'] = df['Weight'] / weight_sum\n",
        "    \n",
        "    df.to_csv(AUGMENTED_WEIGHTS, index=False)\n",
        "    \n",
        "    # Resumen\n",
        "    print(f\"\\n{'=' * 20}\")\n",
        "    print(f\"Im√°genes totales (originales + aumentadas): {len(df)}\")\n",
        "    print(f\"Clases √∫nicas: {len(df['Class'].unique())}\")\n",
        "    print(f\"Pesos guardados en: {AUGMENTED_WEIGHTS}\")\n",
        "    print(f\"Errores: {len(errors)}\")\n",
        "    if errors:\n",
        "        print(\"\\nArchivos con errores:\")\n",
        "        for _, _, _, _, error in errors:\n",
        "            print(f\"  {error}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    augment_dataset(DATASET_PATH, AUGMENTED_OUTPUT_PATH, AUGMENTATIONS_PER_IMAGE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ***Divisi√≥n del dataset augmentado***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Arys\\AppData\\Local\\Temp\\ipykernel_23488\\2653019098.py:26: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  df = df.groupby('Class', group_keys=False).apply(lambda x: x.sample(frac=sample_fraction, random_state=42)).reset_index(drop=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Se ha muestreado el 30.0% del dataset para pruebas\n",
            "Clases encontradas: 114\n",
            "\n",
            "====================\n",
            "Total im√°genes: 293258\n",
            "Entrenamiento: 205280 im√°genes (114 clases)\n",
            "Validaci√≥n: 43988 im√°genes (114 clases)\n",
            "Prueba: 43990 im√°genes (114 clases)\n",
            "CSVs guardados en: C:\\Users\\Arys\\Desktop\\Proyecto - 2\\augmented_weights\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Configuraci√≥n\n",
        "AUGMENTED_WEIGHTS = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\augmented_weights\\augmented_plant_weights.csv\"\n",
        "OUTPUT_WEIGHTS_DIR = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\augmented_weights\"\n",
        "TRAIN_WEIGHTS = os.path.join(OUTPUT_WEIGHTS_DIR, \"aug_train_weights.csv\")\n",
        "VAL_WEIGHTS = os.path.join(OUTPUT_WEIGHTS_DIR, \"aug_val_weights.csv\")\n",
        "TEST_WEIGHTS = os.path.join(OUTPUT_WEIGHTS_DIR, \"aug_test_weights.csv\")\n",
        "os.makedirs(OUTPUT_WEIGHTS_DIR, exist_ok=True)\n",
        "\n",
        "def split_augmented_dataset(weights_path, train_ratio=0.7, val_ratio=0.15, sample_fraction=None):\n",
        "    \"\"\"Divide el dataset aumentado en entrenamiento, validaci√≥n y prueba.\"\"\"\n",
        "    if not os.path.exists(weights_path):\n",
        "        raise FileNotFoundError(f\"No se encontr√≥ {weights_path}\")\n",
        "\n",
        "    df = pd.read_csv(weights_path)\n",
        "    if not all(col in df.columns for col in ['Class', 'Image', 'Weight']):\n",
        "        raise ValueError(\"El CSV debe contener 'Class', 'Image' y 'Weight'\")\n",
        "\n",
        "    if len(df) < 10:\n",
        "        raise ValueError(\"El dataset es demasiado peque√±o para dividir\")\n",
        "\n",
        "    if sample_fraction is not None and 0 < sample_fraction < 1:\n",
        "        df = df.groupby('Class', group_keys=False).apply(lambda x: x.sample(frac=sample_fraction, random_state=42)).reset_index(drop=True)\n",
        "        print(f\"Se ha muestreado el {sample_fraction * 100:.1f}% del dataset para pruebas\")\n",
        "\n",
        "    num_classes = len(df['Class'].unique())\n",
        "    print(f\"Clases encontradas: {num_classes}\")\n",
        "\n",
        "    # Divide en entrenamiento y resto (validaci√≥n + prueba)\n",
        "    train_df, temp_df = train_test_split(\n",
        "        df, train_size=train_ratio, stratify=df['Class'], random_state=42\n",
        "    )\n",
        "    val_size = val_ratio / (1 - train_ratio)\n",
        "    val_df, test_df = train_test_split(\n",
        "        temp_df, train_size=val_size, stratify=temp_df['Class'], random_state=42\n",
        "    )\n",
        "\n",
        "    # Guarda los conjuntos\n",
        "    train_df.to_csv(TRAIN_WEIGHTS, index=False)\n",
        "    val_df.to_csv(VAL_WEIGHTS, index=False)\n",
        "    test_df.to_csv(TEST_WEIGHTS, index=False)\n",
        "\n",
        "    print(f\"\\n{'=' * 20}\")\n",
        "    print(f\"Total im√°genes: {len(df)}\")\n",
        "    print(f\"Entrenamiento: {len(train_df)} im√°genes ({len(train_df['Class'].unique())} clases)\")\n",
        "    print(f\"Validaci√≥n: {len(val_df)} im√°genes ({len(val_df['Class'].unique())} clases)\")\n",
        "    print(f\"Prueba: {len(test_df)} im√°genes ({len(test_df['Class'].unique())} clases)\")\n",
        "    print(f\"CSVs guardados en: {OUTPUT_WEIGHTS_DIR}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        # Usa sample_fraction=0.05 para trabajar solo con el 5% del dataset\n",
        "        split_augmented_dataset(AUGMENTED_WEIGHTS, sample_fraction=0.30)\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {str(e)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ***Entrenamiento del modelo con imagenes augmentadas y originales***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Entrenando √©poca 1/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6415/6415 [44:34<00:00,  2.40it/s]  \n",
            "Validando: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1375/1375 [09:22<00:00,  2.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "√âpoca 1: P√©rdida Entrenamiento: 0.8958, Precisi√≥n Entrenamiento: 72.66%\n",
            "Precisi√≥n Validaci√≥n: 90.49%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Entrenando √©poca 2/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6415/6415 [34:27<00:00,  3.10it/s]  \n",
            "Validando: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1375/1375 [02:26<00:00,  9.39it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "√âpoca 2: P√©rdida Entrenamiento: 0.5359, Precisi√≥n Entrenamiento: 82.55%\n",
            "Precisi√≥n Validaci√≥n: 91.58%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Entrenando √©poca 3/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6415/6415 [30:26<00:00,  3.51it/s]\n",
            "Validando: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1375/1375 [02:34<00:00,  8.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "√âpoca 3: P√©rdida Entrenamiento: 0.4505, Precisi√≥n Entrenamiento: 85.12%\n",
            "Precisi√≥n Validaci√≥n: 93.74%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Entrenando √©poca 4/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6415/6415 [29:26<00:00,  3.63it/s]\n",
            "Validando: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1375/1375 [02:22<00:00,  9.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "√âpoca 4: P√©rdida Entrenamiento: 0.3990, Precisi√≥n Entrenamiento: 86.76%\n",
            "Precisi√≥n Validaci√≥n: 94.64%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Entrenando √©poca 5/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6415/6415 [29:55<00:00,  3.57it/s]\n",
            "Validando: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1375/1375 [02:47<00:00,  8.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "√âpoca 5: P√©rdida Entrenamiento: 0.3641, Precisi√≥n Entrenamiento: 87.75%\n",
            "Precisi√≥n Validaci√≥n: 94.97%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Entrenando √©poca 6/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6415/6415 [30:46<00:00,  3.47it/s]\n",
            "Validando: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1375/1375 [02:33<00:00,  8.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "√âpoca 6: P√©rdida Entrenamiento: 0.3392, Precisi√≥n Entrenamiento: 88.53%\n",
            "Precisi√≥n Validaci√≥n: 94.46%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Entrenando √©poca 7/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6415/6415 [32:57<00:00,  3.24it/s]  \n",
            "Validando: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1375/1375 [03:32<00:00,  6.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "√âpoca 7: P√©rdida Entrenamiento: 0.3191, Precisi√≥n Entrenamiento: 89.12%\n",
            "Precisi√≥n Validaci√≥n: 95.76%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Entrenando √©poca 8/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6415/6415 [29:03<00:00,  3.68it/s] \n",
            "Validando: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1375/1375 [02:29<00:00,  9.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "√âpoca 8: P√©rdida Entrenamiento: 0.3041, Precisi√≥n Entrenamiento: 89.67%\n",
            "Precisi√≥n Validaci√≥n: 95.96%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Entrenando √©poca 9/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6415/6415 [28:40<00:00,  3.73it/s]  \n",
            "Validando: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1375/1375 [03:05<00:00,  7.41it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "√âpoca 9: P√©rdida Entrenamiento: 0.2879, Precisi√≥n Entrenamiento: 90.16%\n",
            "Precisi√≥n Validaci√≥n: 95.09%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Entrenando √©poca 10/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6415/6415 [32:55<00:00,  3.25it/s]  \n",
            "Validando: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1375/1375 [03:05<00:00,  7.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "√âpoca 10: P√©rdida Entrenamiento: 0.2782, Precisi√≥n Entrenamiento: 90.45%\n",
            "Precisi√≥n Validaci√≥n: 96.10%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Entrenando √©poca 11/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6415/6415 [29:49<00:00,  3.59it/s]  \n",
            "Validando: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1375/1375 [03:11<00:00,  7.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "√âpoca 11: P√©rdida Entrenamiento: 0.2723, Precisi√≥n Entrenamiento: 90.66%\n",
            "Precisi√≥n Validaci√≥n: 95.89%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Entrenando √©poca 12/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6415/6415 [32:07<00:00,  3.33it/s]  \n",
            "Validando: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1375/1375 [02:45<00:00,  8.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "√âpoca 12: P√©rdida Entrenamiento: 0.2605, Precisi√≥n Entrenamiento: 90.99%\n",
            "Precisi√≥n Validaci√≥n: 96.62%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Entrenando √©poca 13/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6415/6415 [30:30<00:00,  3.50it/s] \n",
            "Validando: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1375/1375 [03:20<00:00,  6.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "√âpoca 13: P√©rdida Entrenamiento: 0.2562, Precisi√≥n Entrenamiento: 91.22%\n",
            "Precisi√≥n Validaci√≥n: 95.99%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Entrenando √©poca 14/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6415/6415 [29:52<00:00,  3.58it/s]  \n",
            "Validando: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1375/1375 [02:38<00:00,  8.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "√âpoca 14: P√©rdida Entrenamiento: 0.2506, Precisi√≥n Entrenamiento: 91.36%\n",
            "Precisi√≥n Validaci√≥n: 95.70%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Entrenando √©poca 15/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6415/6415 [28:22<00:00,  3.77it/s]  \n",
            "Validando: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1375/1375 [02:40<00:00,  8.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "√âpoca 15: P√©rdida Entrenamiento: 0.2422, Precisi√≥n Entrenamiento: 91.56%\n",
            "Precisi√≥n Validaci√≥n: 96.50%\n",
            "Parando temprano en √©poca 15\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluando en prueba: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1375/1375 [08:41<00:00,  2.64it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "====================\n",
            "Precisi√≥n en prueba: 96.38%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "from torchvision import models, transforms\n",
        "from torchvision.models import ResNet18_Weights\n",
        "from tqdm import tqdm\n",
        "\n",
        "# =================== CONFIGURACI√ìN ===================\n",
        "DATASET_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\plantvillage-dataset_augmented\"\n",
        "WEIGHTS_DIR = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\augmented_weights\"\n",
        "TRAIN_WEIGHTS = os.path.join(WEIGHTS_DIR, \"aug_train_weights.csv\")\n",
        "VAL_WEIGHTS = os.path.join(WEIGHTS_DIR, \"aug_val_weights.csv\")\n",
        "TEST_WEIGHTS = os.path.join(WEIGHTS_DIR, \"aug_test_weights.csv\")\n",
        "MODEL_DIR = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\models\"\n",
        "os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "MODEL_PATH = os.path.join(MODEL_DIR, \"augmented_model.pth\")\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "BATCH_SIZE = 32\n",
        "NUM_WORKERS = 0\n",
        "NUM_EPOCHS = 20\n",
        "EARLY_STOP_PATIENCE = 3\n",
        "METRICS_LOG = os.path.join(MODEL_DIR, \"training_metrics.csv\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.RandomRotation(20),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "    transforms.RandomAffine(degrees=0, translate=(0.05, 0.05)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "class PlantDataset(Dataset):\n",
        "    def __init__(self, weights_df, root_dir, transform=None, class_to_idx=None):\n",
        "        self.data = weights_df\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.class_to_idx = class_to_idx\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.data.iloc[idx]\n",
        "        img_parts = row['Class'].split('_')\n",
        "        img_path = f\"{self.root_dir}/{img_parts[0]}/{img_parts[1]}/{'_'.join(img_parts[2:])}/{row['Image']}\"\n",
        "        try:\n",
        "            image = Image.open(img_path).convert('RGB')\n",
        "            if self.transform:\n",
        "                image = self.transform(image)\n",
        "            label = self.class_to_idx[row['Class']]\n",
        "            return image, label\n",
        "        except Exception as e:\n",
        "            print(f\"Error al cargar {img_path}: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "def create_dataloader(weights_path, root_dir, transform, class_to_idx, batch_size=BATCH_SIZE, use_sampler=True):\n",
        "    weights_df = pd.read_csv(weights_path)\n",
        "    dataset = PlantDataset(weights_df, root_dir, transform=transform, class_to_idx=class_to_idx)\n",
        "    sampler = WeightedRandomSampler(torch.tensor(weights_df['Weight'].values, dtype=torch.float), len(weights_df), replacement=True) if use_sampler else None\n",
        "    return DataLoader(dataset, batch_size=batch_size, sampler=sampler, shuffle=not use_sampler, num_workers=NUM_WORKERS, pin_memory=torch.cuda.is_available())\n",
        "\n",
        "def train_model(train_loader, val_loader, start_epoch=1, num_epochs=NUM_EPOCHS, early_stop_patience=EARLY_STOP_PATIENCE):\n",
        "    model = models.resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
        "    num_classes = len(train_loader.dataset.class_to_idx)\n",
        "    model.fc = nn.Sequential(nn.Dropout(0.3), nn.Linear(model.fc.in_features, num_classes))\n",
        "    model = model.to(DEVICE)\n",
        "\n",
        "    checkpoint_path = os.path.join(MODEL_DIR, f\"model_epoch_{start_epoch - 1}.pth\")\n",
        "    if os.path.exists(checkpoint_path):\n",
        "        model.load_state_dict(torch.load(checkpoint_path))\n",
        "        print(f\"Modelo cargado desde {checkpoint_path}\")\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=0.0005)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2)\n",
        "\n",
        "    best_acc = 0.0\n",
        "    epochs_without_improvement = 0\n",
        "\n",
        "    if start_epoch == 1 and os.path.exists(METRICS_LOG):\n",
        "        os.remove(METRICS_LOG)\n",
        "\n",
        "    for epoch in range(start_epoch, num_epochs + 1):\n",
        "        model.train()\n",
        "        running_loss, correct, total = 0.0, 0, 0\n",
        "\n",
        "        for images, labels in tqdm(train_loader, desc=f\"Entrenando √©poca {epoch}/{num_epochs}\"):\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        train_loss = running_loss / len(train_loader)\n",
        "        train_acc = 100 * correct / total\n",
        "\n",
        "        model.eval()\n",
        "        val_correct, val_total = 0, 0\n",
        "        with torch.no_grad():\n",
        "            for images, labels in tqdm(val_loader, desc=\"Validando\"):\n",
        "                images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "                outputs = model(images)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                val_total += labels.size(0)\n",
        "                val_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        val_acc = 100 * val_correct / val_total\n",
        "        scheduler.step(val_acc)\n",
        "\n",
        "        print(f\"\\n√âpoca {epoch}: P√©rdida Entrenamiento: {train_loss:.4f}, Precisi√≥n Entrenamiento: {train_acc:.2f}%\")\n",
        "        print(f\"Precisi√≥n Validaci√≥n: {val_acc:.2f}%\")\n",
        "\n",
        "        torch.save(model.state_dict(), os.path.join(MODEL_DIR, f\"model_epoch_{epoch}.pth\"))\n",
        "        if val_acc > best_acc:\n",
        "            best_acc = val_acc\n",
        "            torch.save(model.state_dict(), MODEL_PATH)\n",
        "            epochs_without_improvement = 0\n",
        "        else:\n",
        "            epochs_without_improvement += 1\n",
        "\n",
        "        with open(METRICS_LOG, \"a\") as f:\n",
        "            if epoch == start_epoch:\n",
        "                f.write(\"Epoch,TrainLoss,TrainAcc,ValAcc\\n\")\n",
        "            f.write(f\"{epoch},{train_loss:.4f},{train_acc:.2f},{val_acc:.2f}\\n\")\n",
        "\n",
        "        if epochs_without_improvement >= early_stop_patience:\n",
        "            print(f\"Parando temprano en √©poca {epoch}\")\n",
        "            break\n",
        "    return model\n",
        "\n",
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in tqdm(test_loader, desc=\"Evaluando en prueba\"):\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print(f\"\\n{'='*20}\\nPrecisi√≥n en prueba: {100 * correct / total:.2f}%\")\n",
        "    return 100 * correct / total\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    train_df = pd.read_csv(TRAIN_WEIGHTS)\n",
        "    class_to_idx = {cls: idx for idx, cls in enumerate(sorted(train_df['Class'].unique()))}\n",
        "\n",
        "    train_loader = create_dataloader(TRAIN_WEIGHTS, DATASET_PATH, train_transforms, class_to_idx)\n",
        "    val_loader = create_dataloader(VAL_WEIGHTS, DATASET_PATH, val_transforms, class_to_idx, use_sampler=False)\n",
        "    test_loader = create_dataloader(TEST_WEIGHTS, DATASET_PATH, val_transforms, class_to_idx, use_sampler=False)\n",
        "\n",
        "    # Cambia aqu√≠ si quieres reanudar desde cierta √©poca\n",
        "    model = train_model(train_loader, val_loader, start_epoch=1)\n",
        "    evaluate_model(model, test_loader)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ***Predicci√≥n con c√°mara (modelo augmentado)***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Presiona 'q' para salir, 's' para guardar imagen.\n"
          ]
        },
        {
          "ename": "error",
          "evalue": "OpenCV(4.12.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window_w32.cpp:1261: error: (-27:Null pointer) NULL window: 'Umbral Blanco y Negro' in function 'cvDestroyWindow'\n",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31merror\u001b[39m                                     Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 122\u001b[39m\n\u001b[32m    120\u001b[39m cap.release()\n\u001b[32m    121\u001b[39m cv2.destroyAllWindows()\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m \u001b[43mcv2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdestroyWindow\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mUmbral Blanco y Negro\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "\u001b[31merror\u001b[39m: OpenCV(4.12.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window_w32.cpp:1261: error: (-27:Null pointer) NULL window: 'Umbral Blanco y Negro' in function 'cvDestroyWindow'\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models\n",
        "from torchvision.models import ResNet18_Weights\n",
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import textwrap\n",
        "\n",
        "# ================= CONFIGURACI√ìN =================\n",
        "MODEL_PATH = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\models\\augmented_model.pth\"\n",
        "CLASSES_CSV = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\augmented_weights\\aug_train_weights.csv\"\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "CAPTURED_IMAGES_DIR = r\"C:\\Users\\Arys\\Desktop\\Proyecto - 2\\captured_images\"\n",
        "os.makedirs(CAPTURED_IMAGES_DIR, exist_ok=True)\n",
        "\n",
        "# ================ CLASES =================\n",
        "train_df = pd.read_csv(CLASSES_CSV)\n",
        "classes = sorted(train_df['Class'].unique())\n",
        "class_to_idx = {cls: idx for idx, cls in enumerate(classes)}\n",
        "idx_to_class = {idx: cls for cls, idx in class_to_idx.items()}\n",
        "\n",
        "# ================ TRANSFORMACIONES =================\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ColorJitter(brightness=0.4, contrast=0.4),  # Aumentado para manejar vistas variables\n",
        "    transforms.RandomRotation(180),  # Para manejar perspectivas (arriba/abajo)\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# ================ CARGAR MODELO =================\n",
        "model = models.resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
        "model.fc = nn.Sequential(\n",
        "    nn.Dropout(0.3),\n",
        "    nn.Linear(model.fc.in_features, len(classes))\n",
        ")\n",
        "model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
        "model = model.to(DEVICE)\n",
        "model.eval()\n",
        "\n",
        "# ================ CAPTURA DE VIDEO =================\n",
        "cap = cv2.VideoCapture(0)\n",
        "cv2.namedWindow(\"Detecci√≥n en tiempo real\", cv2.WINDOW_NORMAL)\n",
        "cv2.resizeWindow(\"Detecci√≥n en tiempo real\", 900, 600)\n",
        "cv2.namedWindow(\"Umbral Blanco y Negro\", cv2.WINDOW_NORMAL)\n",
        "cv2.resizeWindow(\"Umbral Blanco y Negro\", 300, 300)\n",
        "\n",
        "print(\"Presiona 'q' para salir, 's' para guardar imagen.\")\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        print(\"No se pudo capturar imagen.\")\n",
        "        break\n",
        "\n",
        "    # Detecci√≥n de hoja usando color verde ampliado\n",
        "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
        "    lower_green = np.array([15, 20, 20])  # Rango m√°s amplio para \"peach\"\n",
        "    upper_green = np.array([100, 255, 255])\n",
        "    mask = cv2.inRange(hsv, lower_green, upper_green)\n",
        "    blurred = cv2.GaussianBlur(mask, (9, 9), 0)\n",
        "    _, thresh_green = cv2.threshold(blurred, 80, 255, cv2.THRESH_BINARY)\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (9, 9))\n",
        "    cleaned = cv2.morphologyEx(thresh_green, cv2.MORPH_CLOSE, kernel, iterations=4)\n",
        "\n",
        "    # Umbral blanco y negro para depuraci√≥n\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    _, thresh_bw = cv2.threshold(gray, 70, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "\n",
        "    contours, _ = cv2.findContours(cleaned, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    bbox = None\n",
        "    roi = frame\n",
        "    if contours:\n",
        "        largest_contour = max(contours, key=cv2.contourArea)\n",
        "        area = cv2.contourArea(largest_contour)\n",
        "        if area > 300:  # Reducido para detectar hojas individuales\n",
        "            x, y, w, h = cv2.boundingRect(largest_contour)\n",
        "            if w > 30 and h > 30 and w < frame.shape[1] * 0.95 and h < frame.shape[0] * 0.95:\n",
        "                cv2.drawContours(frame, [largest_contour], -1, (0, 255, 0), 2)\n",
        "                bbox = (x, y, x + w, y + h)\n",
        "                roi = frame[y:y+h, x:x+w]\n",
        "                cv2.putText(frame, f\"√Årea: {area:.0f}\", (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
        "\n",
        "    # Preprocesamiento y predicci√≥n\n",
        "    rgb_image = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)\n",
        "    pil_image = Image.fromarray(rgb_image)\n",
        "    input_tensor = transform(pil_image).unsqueeze(0).to(DEVICE)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_tensor)\n",
        "        probs = torch.softmax(outputs, dim=1)\n",
        "        confidence, predicted = torch.max(probs, 1)\n",
        "        label = idx_to_class[predicted.item()] if confidence.item() > 0.6 else \"Desconocido\"\n",
        "\n",
        "    # Mostrar texto\n",
        "    wrapped_text = textwrap.wrap(label, width=40)\n",
        "    y = 30\n",
        "    for line in wrapped_text:\n",
        "        cv2.putText(frame, line, (10, y), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
        "        y += 25\n",
        "    cv2.putText(frame, f\"Conf: {confidence.item()*100:.2f}%\", (10, y), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)\n",
        "\n",
        "    # Mostrar ventanas\n",
        "    cv2.imshow(\"Detecci√≥n en tiempo real\", frame)\n",
        "    cv2.imshow(\"Umbral Blanco y Negro\", thresh_bw)\n",
        "\n",
        "    # Salir o guardar\n",
        "    key = cv2.waitKey(50) & 0xFF\n",
        "    if key == ord('q'):\n",
        "        break\n",
        "    elif key == ord('s') and bbox:\n",
        "        roi_pil = Image.fromarray(rgb_image)\n",
        "        save_path = os.path.join(CAPTURED_IMAGES_DIR, f\"captured_{label}_{confidence.item()*100:.2f}_{int(time.time())}.jpg\")\n",
        "        roi_pil.save(save_path)\n",
        "        print(f\"Imagen guardada: {save_path}\")\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n",
        "cv2.destroyWindow(\"Umbral Blanco y Negro\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "llms2",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
